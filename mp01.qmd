---
title: "STA 9750 Mini-Project #01: Netflix Analysis"
author: "Eduardo Alarcon"
format: 
  html:
    code-fold: true
    code-summary: "Show code"
execute:
  message: false
  warning: false
---

```{r setup}
library(dplyr)
library(lubridate)
library(readr)
library(scales)
library(tidyverse)
library(knitr)
library(ggplot2)
library(tibble)
library(htmltools)
library(janitor)
```

<br>

```{r}

```

```{r}
#| include: false 

if(!dir.exists(file.path("data", "mp01"))){ dir.create(file.path("data", "mp01"), showWarnings=FALSE, recursive=TRUE) }
GLOBAL_TOP_10_FILENAME <- file.path("data", "mp01", "global_top10_alltime.csv")
if(!file.exists(GLOBAL_TOP_10_FILENAME)){ download.file("https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv", destfile=GLOBAL_TOP_10_FILENAME) }
COUNTRY_TOP_10_FILENAME <- file.path("data", "mp01", "country_top10_alltime.csv")
if(!file.exists(COUNTRY_TOP_10_FILENAME)){ download.file("https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv", destfile=COUNTRY_TOP_10_FILENAME) }

if(!require("tidyverse")) install.packages("tidyverse")

GLOBAL_TOP_10 <- read_tsv(GLOBAL_TOP_10_FILENAME)
str(GLOBAL_TOP_10)
glimpse(GLOBAL_TOP_10)

GLOBAL_TOP_10 <- GLOBAL_TOP_10 %>%
  mutate(season_title = if_else(season_title == "N/A", NA, season_title))
glimpse(GLOBAL_TOP_10)

COUNTRY_TOP_10 <- read_tsv(COUNTRY_TOP_10_FILENAME, na = "N/A")
glimpse(COUNTRY_TOP_10)
str(COUNTRY_TOP_10)

n_distinct(COUNTRY_TOP_10$country_name)

GLOBAL_TOP_10 %>%
filter(category == "Films (Non-English)") %>%
group_by(show_title) %>%
summarise(max_cumulweeks = max(cumulative_weeks_in_top_10, na.rm = TRUE)) %>%
arrange(desc(max_cumulweeks)) %>%
slice(1)

library(stringr)
library(DT)

format_titles <- function(df){
    colnames(df) <- str_replace_all(colnames(df), "_", " ") |> str_to_title()
    df
}

GLOBAL_TOP_10 |> 
head(n=20) |>
datatable(options=list(searching=FALSE, info=FALSE))

GLOBAL_TOP_10 |> 
format_titles() |>
head(n=20) |>
datatable(options=list(searching=FALSE, info=FALSE)) |>
formatRound(c('Weekly Hours Viewed', 'Weekly Views'))

```

## Task 4

The following questions address Task 4. Please click on the "Show Code" for an detailed approach on how I obtained my results.

<br>

1. How many different countries does Netflix operate in? (You can use the viewing history as a proxy for countries in which Netflix operates.)

```{r}
#| output: false
n_distinct(COUNTRY_TOP_10$country_name)
``` 
**Answer:** Netflix operates in ```r n_distinct(COUNTRY_TOP_10$country_name)``` different countries based on the viewing history data.

<br>

2. Which non-English-language film has spent the most cumulative weeks in the global top 10? How many weeks did it spend?

```{r}
Q2_RESULT <- GLOBAL_TOP_10 %>%
filter(category == "Films (Non-English)") %>%
group_by(show_title) %>%
summarise(`Maximum Cumulative Weeks` = max(cumulative_weeks_in_top_10, na.rm = TRUE)) %>%
arrange(desc(`Maximum Cumulative Weeks`)) %>%
slice(1)

film_name_2 <- Q2_RESULT$show_title
weeks_count_2 <- Q2_RESULT[[2]]

Q2_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The non-English-language film `r film_name_2` spent the most cumulative weeks in the Global Top 10, with `r weeks_count_2` weeks.

<br>

3.	What is the longest film (English or non-English) to have ever appeared in the Netflix global Top 10? How long is it in minutes?
```{r}
Q3_RESULT <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "Films (English)")) %>%
  filter(!is.na(runtime)) %>%   
  group_by(show_title) %>%
  summarise(max_runtime = max(runtime)) %>%   
  arrange(desc(max_runtime)) %>%
  slice(1) %>%
  mutate(max_runtime_minutes = round(60 * max_runtime))

film_name_3 <- Q3_RESULT$show_title
run_time_3 <- Q3_RESULT[[3]]

Q3_RESULT %>%
select(-max_runtime) %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The longest English or non-English film to have ever topped in the Netflix Global Top 10 is `r film_name_3`, with a length of `r run_time_3` minutes.

<br>

4. For each of the four categories, what program has the most total hours of global viewership?

```{r}
Q4_RESULT <- GLOBAL_TOP_10 %>%
group_by(category, show_title) %>%
summarise(total_hours_global_viewership = sum(weekly_hours_viewed, na.rm = TRUE), .groups = "drop") %>%
group_by(category) %>%
slice_max(total_hours_global_viewership, n = 1) %>%
arrange(desc(total_hours_global_viewership)) %>%
mutate(total_hours_global_viewership = comma(total_hours_global_viewership))

Q4_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** The above table highlights calculations that sum all seasons together (i.e.,franchise-level data). In other words, Stranger Things and Squid Game reflect the combined global viewership across all of their respective seasons.

<br>

5.	Which TV show had the longest run in a countryâ€™s Top 10? How long was this run and in what country did it occur?

```{r}

Q5_RESULT <- COUNTRY_TOP_10 %>%
filter(category == "TV") %>%
filter(!is.na(season_title)) %>%
group_by(country_name, show_title) %>%
summarise(max_cumulative_weeks = max(cumulative_weeks_in_top_10), .groups = "drop") %>%
arrange(desc(max_cumulative_weeks)) %>%
slice(1)

Q5_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Money Heist had the longest run in Pakistan, with 127 weeks in Netflix's Country Top 10 list. 

<br>

6. Netflix provides over 200 weeks of service history for all but one country in our data set. Which country is this and when did Netflix cease operations in that country?

```{r}

Q6_RESULT <- COUNTRY_TOP_10 %>%
group_by(country_name) %>%
summarise(total_weeks_of_data = n_distinct(week),final_week = max(week, na.rm = TRUE)) %>%
filter(total_weeks_of_data < 200) %>%
arrange(total_weeks_of_data)

Q6_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** Netflix could not provide over 200 weeks of service for Russia, as it ceased operations during the week of February 27, 2022, resulting in 35 weeks of data in the Country Top 10 list.

<br>

7. What is the total viewership of the TV show Squid Game? Note that there are three seasons total and we are looking for the total number of hours watched across all seasons.

```{r}
Q7_RESULT_SEASONS <- GLOBAL_TOP_10 %>%
filter(show_title == "Squid Game") %>%
filter(!is.na(season_title)) %>%
group_by(season_title) %>%
summarise(sum_hours = sum(weekly_hours_viewed, na.rm = TRUE)) %>%
mutate(hours_watched = comma(sum_hours))

Q7_RESULT_SEASONS_SUM <- Q7_RESULT_SEASONS %>%
summarise(
season_title = "Total Hours Watched Across All Seasons",
sum_hours_1 = sum(sum_hours),
hours_watched = comma(sum_hours_1))

Q7_RESULT_FINAL <- bind_rows(Q7_RESULT_SEASONS, Q7_RESULT_SEASONS_SUM) %>%
select(season_title, hours_watched)

Q7_RESULT_FINAL %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Across all three seasons, Squid Game had a total of 5,048,300,000 hours of global viewership. 

<br>

8. The movie Red Notice has a runtime of 1 hour and 58 minutes. Approximately how many views did it receive in 2021?

```{r}

library(dplyr)
library(lubridate)
library(scales)
library(DT)
library(tibble)

Q8_ROWS <- GLOBAL_TOP_10 %>%
  mutate(week = as.Date(week)) %>%
  filter(show_title == "Red Notice", year(week) == 2021)

if (nrow(Q8_ROWS) == 0) {
  Q8_RESULT <- tibble(
    `Total Hours Viewed (2021)` = "N/A",
    `Approximate Views` = "N/A"
  )
} else {
Q8_RESULT <- Q8_ROWS %>%
summarise(
total_hours_2021 = sum(weekly_hours_viewed, na.rm = TRUE),
runtime_hours = 1 + 58/60,  # 1h 58m
approximate_views = total_hours_2021 / runtime_hours) %>%
mutate(`Total Hours Viewed (2021)` = comma(total_hours_2021), `Approximate Views` = comma(round(approximate_views))) %>%
select(`Total Hours Viewed (2021)`, `Approximate Views`)
}

Q8_RESULT %>%
datatable(options = list( searching = FALSE, info = FALSE, paging = FALSE,
columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** Based on the total number of hours viewed in 2021, Red Notice has approximately, 201,732,203 global views.

<br>

9. Part A: How many Films reached Number 1 in the US but did not originally debut there? 


```{r}

COUNTRY_TOP_10_US_ONLY <- COUNTRY_TOP_10 %>%
  filter(country_iso2 == "US", category == "Films") %>%
  mutate(week = as.Date(week))

US_FILMS_REACH1 <- COUNTRY_TOP_10_US_ONLY %>%
  group_by(show_title) %>%
  summarise(best_rank = min(weekly_rank, na.rm = TRUE), .groups = "drop") %>%
  filter(best_rank == 1)

US_DEBUT <- COUNTRY_TOP_10_US_ONLY %>%
  group_by(show_title) %>%
  arrange(week, .by_group = TRUE) %>%    
  slice(1L) %>%                         
  ungroup() %>%
  transmute(show_title, debut_week = week, debut_rank = weekly_rank)

Q9_RESULT_PT1 <- US_FILMS_REACH1 %>%
  inner_join(US_DEBUT, by = "show_title") %>%
  filter(debut_rank > 1) %>%
  summarise(number_of_films = n())

```

<br>

**Answer:** A total of ```r Q9_RESULT_PT1``` films in the US reached to Number 1 after debuting at a lower ranking. 

<br>

9. Part B: What is the most recent film to pull this off?

```{r}

Q9_RESULT_PT2 <- COUNTRY_TOP_10 %>%
filter(country_iso2 == "US", category == "Films") %>%
mutate(week = as.Date(week)) %>%
group_by(show_title) %>%
summarise(
debut_week = min(week),
debut_rank = weekly_rank[which.min(week)],
best_rank  = min(weekly_rank, na.rm = TRUE),
.groups = "drop") %>%
filter(best_rank == 1, debut_rank > 1) %>%
inner_join(COUNTRY_TOP_10 %>%
filter(country_iso2 == "US", category == "Films") %>%
mutate(week = as.Date(week)) %>%
select(show_title, week, weekly_rank), by = "show_title") %>%
filter(weekly_rank == 1) %>%
slice_max(order_by = week, n = 1, with_ties = FALSE) %>%
transmute(`Most Recent Film` = show_title, `Date Reached #1` = week)


Q9_RESULT_PT2 %>%
datatable(
  options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The most recent film to accomplish this was KPop Demon Hunters, which reached Number 1 during the week of September 14, 2025. 

<br>

10. Which TV show/season hit the top 10 in the most countries in its debut week? In how many countries did it chart?

```{r}

COUNTRY_TOP_10_DEBUT <- COUNTRY_TOP_10 %>%
filter(category == "TV") %>%
group_by(show_title, season_title, country_name) %>%
summarise(
debut_week = min(week, na.rm = TRUE),
debut_rank = weekly_rank[which.min(week)][1],
.groups = "drop"
) %>%
arrange(debut_week)

Q10_RESULT <- COUNTRY_TOP_10_DEBUT %>% 
group_by(show_title, season_title, debut_week) %>% 
summarise(country_appearance = n_distinct(country_name), .groups = "drop") %>% 
arrange(desc(country_appearance)) %>% 
slice(1) %>%
rename(`Show Title` = show_title, `Season Title` = season_title, `Debut Week` = debut_week, `Number of Countries Charted` = country_appearance)

Q10_RESULT %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Emily in Paris (Season 2) charted in 94 countries during its debut week in December 26, 2021. 

<br>

## Task 5: 
## Press Release 1: The Perks of Being a Stranger

Netflix's foray into original programming is yielding massive dividends, as unafraid viewers willingly spend their time (and money) alongside billions of "Strangers" year after year. For Netflix, this translates into viewership that has surpassed the billion mark. The Stranger Things series has garnered 2.5 billion viewers since its premiere in 2016. During its fourth season, it stayed a remarkable 19 weeks in Netflix's Global Top 10 list, spending seven of those weeks resting comfortably at number one. Moreover, the series averaged about 13 weeks in the global top 10 across 93 countries, while Pakistan and Ukraine led the charge at 24 total weeks in the Global top 10.

Compared to other original Netflix titles, Stranger Things dominates in total global hours viewed at nearly 3 billion hours. One contender, Wednesday, has a solid stronghold in approximate viewership at close to 3.8 billion; however, Stranger Things still reigns supreme in total hours viewed, leaving other rivals, such as The Witcher, The Sandman, Locke & Key, and Shadow and Bone, with dust in their viewers' eyes.

With the upcoming release of its fifth and final season, Stranger Things is on a trajectory to continue shattering global records for Netflix. As a solid revenue machine, it is unlikely this season will mark the end of the series. As consummate content consumers, it's highly probable that Netflix will continue to feed the insatiable appetite of its subscribers. If time has taught us anything, we should not be surprised to expect Netflix to conjure spinoffs, prequels, and movie adaptations of this series, as the last thing it would want, is for its subscribers to become strangers to the platform.

<br>

```{r}

# =========================
# Helper(s)
# =========================
# Robust season-number extraction:
# - pulls any number from season_title
# - defaults to 1 if none
# - clamps to 1..4
extract_season_num <- function(x) {
  n <- parse_number(coalesce(x, ""))
  n <- ifelse(is.na(n), 1L, as.integer(n))
  pmin(pmax(n, 1L), 4L)
}

# Average episode minutes by season (edit if needed)
episode_minutes <- tibble(
  season_num = 1:4,
  `*Average Episode Minutes` = c(47, 60, 60, 87)
)

# =========================
# Normalize seasons
# =========================
COUNTRY_ST <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  mutate(
    season_num   = extract_season_num(season_title),
    season_label = paste0("Stranger Things: S", season_num)
  )

GLOBAL_ST <- GLOBAL_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  mutate(
    season_num   = extract_season_num(season_title),
    season_label = paste0("Stranger Things: S", season_num)
  )

# =========================
# Season-level metrics
# =========================
# From COUNTRY: Countries Reached, Country-Weeks
ST_COUNTRIES_BY_SEASON <- COUNTRY_ST %>%
  group_by(season_num, season_label, country_name) %>%
  summarise(weeks_in_top10 = n_distinct(week), .groups = "drop_last") %>%
  summarise(
    `Countries Reached`       = n_distinct(country_name),
    `Country-Weeks in Top 10` = sum(weeks_in_top10, na.rm = TRUE),
    .groups = "drop"
  )

# From GLOBAL: Global Weeks, Total Global Hours
ST_GLOBAL_BY_SEASON <- GLOBAL_ST %>%
  group_by(season_num, season_label) %>%
  summarise(
    `Global Weeks in Top 10` = n_distinct(week),
    `Total Global Hours`     = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  )

# From GLOBAL: Global Weeks at #1
ST_GLOBAL_NUM1 <- GLOBAL_ST %>%
  filter(weekly_rank == 1) %>%
  group_by(season_num, season_label) %>%
  summarise(`Global Weeks at #1` = n_distinct(week), .groups = "drop")

# =========================
# Combine + compute approx. viewership
# =========================
ST_IMPACT_COMBINED <- ST_GLOBAL_BY_SEASON %>%
  left_join(ST_COUNTRIES_BY_SEASON, by = c("season_num", "season_label")) %>%
  left_join(ST_GLOBAL_NUM1,        by = c("season_num", "season_label")) %>%
  left_join(episode_minutes,       by = "season_num") %>%
  mutate(
    approx_views = `Total Global Hours` / (`*Average Episode Minutes` / 60),
    season_label = factor(season_label, levels = paste0("Stranger Things: S", 1:4))
  ) %>%
  arrange(season_num) %>%
  transmute(
    Season = season_label,
    `Total Global Hours Viewed` = `Total Global Hours`,
    `Approx. Viewership`        = approx_views,
    `*Average Episode Minutes`  = `*Average Episode Minutes`,
    `Global Weeks in Top 10`,
    `Global Weeks at #1`,
    `Countries Reached`,
    `Country-Weeks in Top 10`
  )

# =========================
# Totals row (sum weeks, incl. #1), max for Countries Reached
# =========================
totals_row <- ST_IMPACT_COMBINED %>%
  summarise(
    Season                      = "Totals",
    `Total Global Hours Viewed` = sum(`Total Global Hours Viewed`, na.rm = TRUE),
    `Approx. Viewership`        = sum(`Approx. Viewership`, na.rm = TRUE),
    `*Average Episode Minutes`  = NA_real_,
    `Global Weeks in Top 10`    = sum(`Global Weeks in Top 10`, na.rm = TRUE),
    `Global Weeks at #1`        = sum(`Global Weeks at #1`, na.rm = TRUE),
    `Countries Reached`         = max(`Countries Reached`, na.rm = TRUE),
    `Country-Weeks in Top 10`   = sum(`Country-Weeks in Top 10`, na.rm = TRUE)
  )

ST_IMPACT_FINAL <- bind_rows(ST_IMPACT_COMBINED, totals_row) %>%
  mutate(
    across(
      c(`*Average Episode Minutes`,
        `Global Weeks in Top 10`,
        `Global Weeks at #1`,
        `Countries Reached`,
        `Country-Weeks in Top 10`),
      ~ replace_na(., 0)
    ),
    `Total Global Hours Viewed` = comma(`Total Global Hours Viewed`),
    `Approx. Viewership`        = comma(round(`Approx. Viewership`)),
    `Global Weeks in Top 10`    = comma(`Global Weeks in Top 10`),
    `Global Weeks at #1`        = comma(`Global Weeks at #1`),
    `Countries Reached`         = comma(`Countries Reached`),
    `Country-Weeks in Top 10`   = comma(`Country-Weeks in Top 10`)
  )

# =========================
# Display
# =========================
datatable(
  ST_IMPACT_FINAL,
  caption = "Stranger Things â€” Combined Global Impact by Season (Scale â€¢ Longevity â€¢ Multinational Reach â€¢ #1 Weeks)",
  options = list(
    searching = FALSE, paging = FALSE, info = FALSE,
    columnDefs = list(list(className = 'dt-left', targets = "_all"))
  ),
  rownames = FALSE
)

```

<br>

*Average minutes derived from the following sources:

*[Wikipedia's List of Stranger Things Episodes](https://en.wikipedia.org/wiki/List_of_Stranger_Things_episodes)*

*[Netflix's Official Tudum Blog](https://www.netflix.com/tudum/articles/stranger-things-season-4-episode-length)*

<br>

```{r}

# 1) Summary for bottom caption
summary_artifact <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  group_by(country_name) %>%
  summarise(total_weeks_in_top_10 = n_distinct(week), .groups = "drop") %>%
  summarise(
    total_countries = n(),
    avg_weeks = round(mean(total_weeks_in_top_10), 1),
    .groups = "drop"
  )

# 2) Leaderboard (Top 20 available; Top 5 shown by default)
ST_TOP_COUNTRIES_WEEKS <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  group_by(country_name) %>%
  summarise(`Weeks in Top 10` = n_distinct(week), .groups = "drop") %>%
  arrange(desc(`Weeks in Top 10`)) %>%
  slice_head(n = 20) %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Country = country_name, `Weeks in Top 10`)

top3 <- ST_TOP_COUNTRIES_WEEKS$Country[ST_TOP_COUNTRIES_WEEKS$Rank <= 3]

# 3) Bottom caption (footnote-style)
cap_bottom <- htmltools::tags$caption(
  style = "caption-side: bottom; text-align:center; color:#666; font-size:0.9em; padding-top:6px;",
  htmltools::HTML(sprintf(
    "Global reach: <b>%s</b> countries &nbsp;&middot;&nbsp; Avg per-country Top-10 weeks: <b>%s</b>",
    summary_artifact$total_countries, summary_artifact$avg_weeks
  ))
)

# 4) Render table (no in-cell bar; bold Top 3)
DT::datatable(
  ST_TOP_COUNTRIES_WEEKS,
  caption   = cap_bottom,
  escape    = FALSE,
  rownames  = FALSE,
  options   = list(
    pageLength = 5,
    lengthMenu = list(c(5,10,15,20), c('Top 5','Top 10','Top 15','Top 20')),
    searching  = TRUE,
    info       = FALSE,
    order      = list(list(0, 'asc')),
    columnDefs = list(list(className = 'dt-left', targets = "_all"))
  )
) %>%
  DT::formatStyle(
    'Country',
    fontWeight = DT::styleEqual(top3, rep('bold', length(top3)))
  )

```

<br>

```{r}

# 1) Average episode runtimes (minutes)
#    Sources you provided:
#    - Stranger Things: 63.5 (avg of 47, 60, 60, 87 from your table screenshot)
#    - Wednesday: 45 (Addams Family Fandom)
#    - The Witcher: 60 (epguides)
#    - The Sandman: 51 (TVMaze)
#    - Locke & Key: 50 (Fandom range ~40â€“56 â†’ midpoint 50)
#    - Shadow and Bone: 60 (epguides)
# ---------------------------
RUNTIME_REF <- tribble(
  ~show_title,        ~avg_episode_minutes,
  "Stranger Things",  63.5,
  "Wednesday",        45,
  "The Witcher",      60,
  "The Sandman",      51,
  "Locke & Key",      50,
  "Shadow and Bone",  60
)

# Keep only these six shows (English-language Netflix Originals)
TARGET_SHOWS <- RUNTIME_REF$show_title

# ---------------------------
# 2) Summarize global performance across ALL seasons
# ---------------------------
SHOW_SUMMARY <- GLOBAL_TOP_10 %>%
  filter(
    category == "TV (English)",
    show_title %in% TARGET_SHOWS
  ) %>%
  mutate(
    # prevent blanks from inflating season counts
    season_title = na_if(season_title, "")
  ) %>%
  group_by(show_title) %>%
  summarise(
    `Number of Seasons`  = n_distinct(season_title, na.rm = TRUE),
    `Total Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # join average runtimes (minutes)
  left_join(RUNTIME_REF, by = "show_title") %>%
  # runtime-adjusted approximate viewership
  mutate(
    `Approximate Viewership` = round(`Total Hours Viewed` / (avg_episode_minutes / 60))
  ) %>%
  # pretty formatting for large numbers
  mutate(
    `Total Hours Viewed`     = comma(`Total Hours Viewed`),
    `Approximate Viewership` = comma(`Approximate Viewership`)
  ) %>%
  # final columns / headers
  select(
    `Show Title` = show_title,
    `Number of Seasons`,
    `Total Hours Viewed`,
    `*Average Episode Minutes` = avg_episode_minutes,
    `Approximate Viewership`
  ) %>%
  # sort by (numeric) total hours
  arrange(desc(parse_number(`Total Hours Viewed`)))

# ---------------------------
# 3) Display
# ---------------------------
datatable(
  SHOW_SUMMARY,
  caption = "Global Performance of Selected English Netflix Originals (Sci-Fi/Fantasy/Supernatural, All Seasons)",
  options = list(
    pageLength = 10,
    searching = FALSE,
    paging = FALSE,
    info = FALSE,
    columnDefs = list(list(className = 'dt-left', targets = "_all")) # <-- left justify all text
  ),
  rownames = FALSE
) %>%
  formatRound("*Average Episode Minutes", digits = 1)

```

*Note, Stranger Things average runtime caculated from the values presented in an earlier table.

The following links contain sources justifying these average per episode runtimes.

*[Wednesday Average Runtime](https://addamsfamily.fandom.com/wiki/Wednesday_(series))*

*[The Witcher Average Runtime](https://epguides.com/Witcher/)*

*[The Sandman](https://www.tvmaze.com/shows/42827/the-sandman)*

*[Locke & Key Average Runtime](https://lockekey.fandom.com/wiki/Season_One)*

*[Shadow and Bone](https://epguides.com/ShadowandBone/)*

<br>

## Task 6: Press Release 2
## Hindi Hits Go Global: 2 Million Netflix Subscribers, 463 Million Viewing Hours

Netflix is demonstrating growing global demand for its Hindi-language programming, with a portfolio of titles generating over 463 million hours of streamed content worldwide. These programs have established Netflix as a premier destination for Hindi entertainment, catering to audiences across India and beyond.

Standout titles such as Heeramandi: The Diamond Bazaar, Animal, and The Great Indian Kapil Show have collectively drawn substantial views from global audiences, highlighting their success on global Top 10 weekly charts. Among its broader catalog, Netflix offers 363 India-focused titles that did not appear in the US market yet achieved global Top 10 status. These titles represent nearly 50% of India's unique content offerings, demonstrating the international appeal of region-specific programming.

Based on viewing patterns and global engagement data, Netflix estimates approximately 2 million subscribers actively engage with Hindi content, representing India's significant presence in Hindi programming consumption. This figure encompasses viewers who regularly consume top-performing Hindi titles that have achieved worldwide recognition.

Beyond India, the broader South Asian streaming market exhibits dynamic growth patterns since 2021, with Pakistan leading regional expansion at 10.3% year-over-year growth in unique Top 10 programming. While Bangladesh and Sri Lanka exhibit positive trends, India has maintained steady engagement, achieving 1.5% growth. Collectively, these four markets offer over 1,400 programs, indicating a well-established, regional presence.

Given the global appeal of South Asian content, Netflix is well-positioned to expand its cross-border offerings through Urdu-language programming, leveraging the language's widespread use across India and Pakistan. This strategic approach aims to serve Urdu-speaking viewers across the region while fostering opportunities for cultural inclusion through shared storytelling.

Netflix's established presence across South Asia, including its strong performance in Hindi content and expanding regional offerings, positions the platform to seize the momentum in streaming growth while continuing to engage its global audiences with rich, South Asian storytelling.

<br>

```{r}

requested_titles <- c(
  "Haseen Dillruba",
  "Sooryavanshi",
  "Animal",
  "Laapataa Ladies",
  "Mimi",
  "Bhool Bhulaiyaa 2",
  "The Railway Men - The Untold Story Of Bhopal 1984",
  "Khakee: The Bihar Chapter",
  "Maamla Legal Hai",
  "The Great Indian Kapil Show",
  "Heeramandi: The Diamond Bazaar",
  "Tribhuvan Mishra CA Topper",
  "IC 814: The Kandahar Hijack",
  "Mismatched",
  "Dabba Cartel"
)

# ---- Create a table for manually provided runtimes ----
manual_runtimes <- tibble::tribble(
  ~show_title,                   ~manual_runtime_hr,
  "Haseen Dillruba",             136 / 60,
  "Sooryavanshi",                145 / 60,
  "Mimi",                        132 / 60,
  "Bhool Bhulaiyaa 2",           143 / 60,
  "Khakee: The Bihar Chapter",   357 / 60
)

# ---- Data Processing ----

# All of the following calculations are still required to create the summary table
india_titles <- COUNTRY_TOP_10 %>%
  filter(country_name == "India") %>%
  distinct(show_title, category)

us_titles <- COUNTRY_TOP_10 %>%
  filter(country_name == "United States") %>%
  distinct(show_title)

india_not_us <- india_titles %>%
  anti_join(us_titles, by = "show_title")

charted_globally <- GLOBAL_TOP_10 %>% distinct(show_title)

target_pool <- india_not_us %>%
  semi_join(charted_globally, by = "show_title") %>%
  filter(show_title %in% requested_titles)

season_counts <- bind_rows(
  COUNTRY_TOP_10 %>% select(show_title, season_title),
  GLOBAL_TOP_10  %>% select(show_title, season_title)
) %>%
  filter(show_title %in% target_pool$show_title) %>%
  mutate(
    season_title = trimws(season_title),
    season_title = dplyr::na_if(season_title, "")
  ) %>%
  group_by(show_title) %>%
  summarise(distinct_seasons = dplyr::n_distinct(season_title, na.rm = TRUE), .groups = "drop")

india_metric <- COUNTRY_TOP_10 %>%
  filter(country_name == "India", show_title %in% target_pool$show_title) %>%
  group_by(show_title) %>%
  summarise(
    india_max_cum_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE),
    category_mode = {
      cats <- na.omit(category)
      if (length(cats) == 0) NA_character_ else names(sort(table(cats), decreasing = TRUE))[1]
    },
    .groups = "drop"
  )

global_metrics <- GLOBAL_TOP_10 %>%
  filter(show_title %in% target_pool$show_title) %>%
  left_join(manual_runtimes, by = "show_title") %>%
  mutate(
    runtime = coalesce(runtime, manual_runtime_hr)
  ) %>%
  group_by(show_title) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    total_weekly_views = sum(weekly_views, na.rm = TRUE),
    avg_runtime        = mean(runtime, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    total_views_est = case_when(
      !is.na(total_weekly_views) & total_weekly_views > 0 ~ total_weekly_views,
      is.finite(avg_runtime) & !is.na(avg_runtime) & avg_runtime > 0 ~ total_hours_viewed / avg_runtime,
      TRUE ~ NA_real_
    )
  )

final_raw <- india_metric %>%
  left_join(global_metrics, by = "show_title") %>%
  left_join(season_counts,  by = "show_title") %>%
  mutate(
    content_type = case_when(
      str_detect(ifelse(is.na(category_mode), "", category_mode), regex("^TV",   ignore_case = TRUE)) ~ "TV Show",
      str_detect(ifelse(is.na(category_mode), "", category_mode), regex("^Film", ignore_case = TRUE)) ~ "Film",
      TRUE ~ ifelse(is.na(category_mode), "Unknown", category_mode)
    ),
    distinct_seasons = ifelse(is.na(distinct_seasons), 0L, distinct_seasons),
    avg_runtime_min  = ifelse(!is.na(avg_runtime) & is.finite(avg_runtime), round(avg_runtime * 60, 0), NA_real_)
  )

# ---- The detailed table is no longer displayed ----
# print("--- Detailed Analysis Table ---")
# datatable(
#   final_tbl %>%
#     mutate(
#       `Global: Total Hours Viewed` = ifelse(!is.na(`Global: Total Hours Viewed`), comma(round(`Global: Total Hours Viewed`, -4)), "N/A"),
#       `Global: Total Views (Est.)` = ifelse(!is.na(`Global: Total Views (Est.)`),  comma(round(`Global: Total Views (Est.)`, -4)),  "N/A")
#     ),
#   options = list(
#     searching = FALSE,
#     paging = TRUE,
#     info = TRUE,
#     pageLength = 3,
#     columnDefs = list(
#       list(className = 'dt-left',   targets = 0),
#       list(className = 'dt-center', targets = 1:6)
#     )
#   ),
#   caption = "Requested Titles - India-not-US, but Global Top 10"
# )


# ===================================================================
# Part 2: Summary Table (Final Output)
# ===================================================================

# ---- Create the summary table using the 'final_raw' object ----
summary_tbl <- final_raw %>%
  filter(content_type %in% c("Film", "TV Show")) %>%
  group_by(content_type) %>%
  summarise(
    total_hours_viewed = sum(total_hours_viewed, na.rm = TRUE),
    total_views_est = sum(total_views_est, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  adorn_totals("row") %>%
  rename(
    `Content Type` = content_type,
    `Global: Total Hours Viewed` = total_hours_viewed,
    `Global: Total Views (Est.)` = total_views_est
  )

# ---- Display the final summary table ----
datatable(
  summary_tbl %>%
    mutate(
      `Global: Total Hours Viewed` = ifelse(!is.na(`Global: Total Hours Viewed`), comma(round(`Global: Total Hours Viewed`, -4)), "N/A"),
      `Global: Total Views (Est.)` = ifelse(!is.na(`Global: Total Views (Est.)`),  comma(round(`Global: Total Views (Est.)`, -4)),  "N/A")
    ),
  options = list(
    searching = FALSE,
    paging = FALSE,
    info = FALSE
  ),
  caption = "Summary by Total Hours Viewed and Estimated Total Views, Hindi-Only Programs"
)

```

<br>

```{r}

# ---- Requested titles only ----
requested_titles <- c(
  "Haseen Dillruba",
  "Sooryavanshi",
  "Animal",
  "Laapataa Ladies",
  "Mimi",
  "Bhool Bhulaiyaa 2",
  "The Railway Men - The Untold Story Of Bhopal 1984",
  "Khakee: The Bihar Chapter",
  "Maamla Legal Hai",
  "The Great Indian Kapil Show",
  "Heeramandi: The Diamond Bazaar",
  "Tribhuvan Mishra CA Topper",
  "IC 814: The Kandahar Hijack",
  "Mismatched",
  "Dabba Cartel"
)

# ---- Create a table for manually provided runtimes ----
# Runtimes are converted from minutes to hours (as required for the calculation)
manual_runtimes <- tibble::tribble(
  ~show_title,                   ~manual_runtime_hr,
  "Haseen Dillruba",             136 / 60,
  "Sooryavanshi",                145 / 60,
  "Mimi",                        132 / 60,
  "Bhool Bhulaiyaa 2",           143 / 60,
  "Khakee: The Bihar Chapter",   357 / 60
)

# ---- Data Processing ----

# 1. Get titles that appeared in India but NOT in the US
india_titles <- COUNTRY_TOP_10 %>%
  filter(country_name == "India") %>%
  distinct(show_title, category)

us_titles <- COUNTRY_TOP_10 %>%
  filter(country_name == "United States") %>%
  distinct(show_title)

india_not_us <- india_titles %>%
  anti_join(us_titles, by = "show_title")

# 2. Filter for titles that also charted globally from the requested list
charted_globally <- GLOBAL_TOP_10 %>% distinct(show_title)

target_pool <- india_not_us %>%
  semi_join(charted_globally, by = "show_title") %>%
  filter(show_title %in% requested_titles)

# 3. Get distinct season counts for the target shows
season_counts <- bind_rows(
  COUNTRY_TOP_10 %>% select(show_title, season_title),
  GLOBAL_TOP_10  %>% select(show_title, season_title)
) %>%
  filter(show_title %in% target_pool$show_title) %>%
  mutate(
    season_title = trimws(season_title),
    season_title = dplyr::na_if(season_title, "")
  ) %>%
  group_by(show_title) %>%
  summarise(distinct_seasons = dplyr::n_distinct(season_title, na.rm = TRUE), .groups = "drop")

# 4. Get India-specific metrics
india_metric <- COUNTRY_TOP_10 %>%
  filter(country_name == "India", show_title %in% target_pool$show_title) %>%
  group_by(show_title) %>%
  summarise(
    india_max_cum_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE),
    category_mode = {
      cats <- na.omit(category)
      if (length(cats) == 0) NA_character_ else names(sort(table(cats), decreasing = TRUE))[1]
    },
    .groups = "drop"
  )

# 5. Global metrics
global_metrics <- GLOBAL_TOP_10 %>%
  filter(show_title %in% target_pool$show_title) %>%
  left_join(manual_runtimes, by = "show_title") %>%
  mutate(
    runtime = coalesce(runtime, manual_runtime_hr)
  ) %>%
  group_by(show_title) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    total_weekly_views = sum(weekly_views, na.rm = TRUE),
    avg_runtime        = mean(runtime, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    total_views_est = case_when(
      !is.na(total_weekly_views) & total_weekly_views > 0 ~ total_weekly_views,
      is.finite(avg_runtime) & !is.na(avg_runtime) & avg_runtime > 0 ~ total_hours_viewed / avg_runtime,
      TRUE ~ NA_real_
    )
  )

# 6. Combine all metrics into a final raw table
final_raw <- india_metric %>%
  left_join(global_metrics, by = "show_title") %>%
  left_join(season_counts,  by = "show_title") %>%
  mutate(
    content_type = case_when(
      str_detect(ifelse(is.na(category_mode), "", category_mode), regex("^TV",   ignore_case = TRUE)) ~ "TV Show",
      str_detect(ifelse(is.na(category_mode), "", category_mode), regex("^Film", ignore_case = TRUE)) ~ "Film",
      TRUE ~ ifelse(is.na(category_mode), "Unknown", category_mode)
    ),
    distinct_seasons = ifelse(is.na(distinct_seasons), 0L, distinct_seasons),
    avg_runtime_min  = ifelse(!is.na(avg_runtime) & is.finite(avg_runtime), round(avg_runtime * 60, 0), NA_real_)
  )

# 7. Final selection, renaming, and sorting
final_tbl <- final_raw %>%
  arrange(desc(total_hours_viewed), desc(total_views_est), desc(india_max_cum_weeks)) %>%
  select(
    `Show Title` = show_title,
    `Content Type` = content_type,
    `Distinct Seasons` = distinct_seasons,
    `India: Max Cumulative Weeks` = india_max_cum_weeks,
    `Global: Total Hours Viewed` = total_hours_viewed,
    `Global: Total Views (Est.)` = total_views_est,
    `Global: Avg Runtime (min)` = avg_runtime_min
  )

# ---- Display the final table (MODIFIED SECTION) ----
datatable(
  final_tbl %>%
    mutate(
      `Global: Total Hours Viewed` = ifelse(!is.na(`Global: Total Hours Viewed`), comma(round(`Global: Total Hours Viewed`, -4)), "N/A"),
      `Global: Total Views (Est.)` = ifelse(!is.na(`Global: Total Views (Est.)`),  comma(round(`Global: Total Views (Est.)`, -4)),  "N/A")
    ),
  options = list(
    # --- THESE OPTIONS HAVE BEEN CHANGED ---
    searching = FALSE,
    paging = TRUE,      # Enable paging
    info = TRUE,        # Show the "Showing X of Y" text
    pageLength = 3,     # Set the initial page length to 3
    # ---
    columnDefs = list(
      list(className = 'dt-left',   targets = 0),
      list(className = 'dt-center', targets = 1:6)
    )
  ),
  caption = "Selected Programs, India-Only (Not US), in Global Top 10"
)

```

<br>

```{r}

india_exclusive_from_us <- COUNTRY_TOP_10 %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE)

india_only_list <- COUNTRY_TOP_10 %>%
  filter(country_name == "India") %>%
  semi_join(india_exclusive_from_us, by = c("show_title", "season_title")) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil")) %>%
  distinct(show_title, season_title, category) %>%
  mutate(content_type = case_when(
    str_detect(category, "Films") ~ "Films",
    str_detect(category, "TV") ~ "TV Shows",
    TRUE ~ "Other"
  )) %>%
  arrange(content_type, show_title, season_title)

india_only_breakdown <- india_only_list %>%
  count(content_type, name = "distinct_shows") %>%
  mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

india_only_breakdown %>%
  rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

total_india_only <- sum(india_only_breakdown$distinct_shows)
cat("Total distinct viewing options in India that do NOT 
  appear in US (excluding Telugu/Tamil language viewing options):", total_india_only)

```

<br>

```{r}

# ============================================
# EXISTING CODE (unchanged)
# ============================================

india_exclusive_combinations <- COUNTRY_TOP_10 %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil"))

global_appearing_breakdown <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  distinct(show_title, season_title, category) %>%
  mutate(content_type = case_when(
    str_detect(category, "Films") ~ "Films",
    str_detect(category, "TV") ~ "TV Shows",
    TRUE ~ "Other"
  )) %>%
  count(content_type, name = "distinct_shows") %>%
  mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

films_metrics <- GLOBAL_TOP_10 %>%
  filter(category == "Films (Non-English)") %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))

tv_metrics <- GLOBAL_TOP_10 %>%
  filter(category == "TV (Non-English)") %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))

shows_in_global_count <- sum(global_appearing_breakdown$distinct_shows)
total_combinations <- nrow(india_exclusive_combinations)
global_penetration <- round((shows_in_global_count / total_combinations) * 100, 1)

INDIA_EXCLUSIVE_SUMMARY <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    avg_weeks_in_top_10 = mean(cumulative_weeks_in_top_10, na.rm = TRUE),
    max_weeks_in_top_10 = max(cumulative_weeks_in_top_10, na.rm = TRUE)
  ) %>%
  mutate(
    total_hours_formatted = comma(total_hours_viewed),
    avg_weeks_formatted = round(avg_weeks_in_top_10, 1)
  )

# ============================================
# NEW CODE: SUBSCRIBER ESTIMATION
# ============================================

# Step 1: Calculate runtime and views
runtime_and_views <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  group_by(category) %>%
  summarise(
    total_hours = sum(weekly_hours_viewed, na.rm = TRUE),
    avg_runtime = mean(runtime, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    total_views = total_hours / avg_runtime
  )

# Step 2: Get number of weeks in dataset
num_weeks <- GLOBAL_TOP_10 %>% distinct(week) %>% nrow()

# Step 3: Calculate total views and views per week
total_views <- sum(runtime_and_views$total_views)
views_per_week_global <- total_views / num_weeks

# Step 4: KEY ASSUMPTIONS - Document these clearly!
INDIA_SHARE_OF_GLOBAL <- 0.25  # 25% of global Non-English views come from India
VIEWS_PER_SUBSCRIBER_PER_WEEK <- 2.0  # Hindi top 10 shows per subscriber per week

# Rationale for assumptions:
# - India share: Based on India's population, Netflix penetration, and content engagement
# - Views per subscriber: These are GLOBAL hit shows, higher than typical Hindi content
#   (Industry avg: 3-4 top 10 shows/week total; Hindi ~28% of catalog; but these are hits)

# Step 5: Calculate estimated subscribers
india_views_per_week <- views_per_week_global * INDIA_SHARE_OF_GLOBAL
estimated_hindi_subscribers <- india_views_per_week / VIEWS_PER_SUBSCRIBER_PER_WEEK

# Step 6: Create sensitivity scenarios
sensitivity_scenarios <- data.frame(
  Scenario = c("Conservative", "Moderate", "Aggressive"),
  India_Share = c(0.20, 0.25, 0.30),
  Views_Per_Sub = c(1.5, 2.0, 2.5)
) %>%
  mutate(
    India_Views_Per_Week = views_per_week_global * India_Share,
    Estimated_Subscribers = India_Views_Per_Week / Views_Per_Sub,
    Formatted_Subscribers = comma(round(Estimated_Subscribers))
  )

# ============================================
# UPDATED SUMMARY TABLE WITH SUBSCRIBER ROW
# ============================================

GLOBAL_REACH_SUMMARY <- data.frame(
  Metric = c(
    "Total Show and Season Combinations", 
    "Total Hours Viewed - Non-English Films", 
    "Total Hours Viewed - Non-English TV",
    "Combined Hours Viewed (Non-English)", 
    "Average Weeks in Global Top 10", 
    "Maximum Weeks in Global Top 10", 
    "Non-English Combinations in Global Charts", 
    "Non-English Global Chart Penetration Rate",
    "Estimated Hindi-Engaged Subscribers",
    "  Assumption: India Share of Global Views",
    "  Assumption: Views per Subscriber per Week"
  ),
  Value = c(
    total_combinations,
    comma(films_metrics$total_hours), 
    comma(tv_metrics$total_hours),
    INDIA_EXCLUSIVE_SUMMARY$total_hours_formatted,
    paste0(INDIA_EXCLUSIVE_SUMMARY$avg_weeks_formatted, " weeks"),
    paste0(INDIA_EXCLUSIVE_SUMMARY$max_weeks_in_top_10, " weeks"),
    paste0(shows_in_global_count, " of ", total_combinations, " combinations"),
    paste0(global_penetration, "%"),
    comma(round(estimated_hindi_subscribers)),
    paste0(INDIA_SHARE_OF_GLOBAL * 100, "%"),
    paste0(VIEWS_PER_SUBSCRIBER_PER_WEEK, " shows")
  )
)

# ============================================
# DISPLAY RESULTS
# ============================================

cat("India-exclusive NON-ENGLISH, (proxy for Hindi; excludes Telugu/Tamil) 
    that achieved global top 10 status:\n\n")

global_appearing_breakdown %>%
  rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

cat("\nTotal NON-ENGLISH (proxy for Hindi; excludes Telugu/Tamil) 
program offerings appearing in global charts:", shows_in_global_count, "of", total_combinations, "\n\n")

GLOBAL_REACH_SUMMARY %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE))

```

<br>

```{r}

# Define South Asian countries
south_asian_countries <- c("India", "Pakistan", "Bangladesh", "Sri Lanka")

# Calculate unique programs by year for each country
yearly_unique_programs <- COUNTRY_TOP_10 %>%
  filter(country_name %in% south_asian_countries) %>%
  mutate(
    year_period = case_when(
      week >= as.Date("2021-07-04") & week < as.Date("2022-07-04") ~ "2021-2022",
      week >= as.Date("2022-07-04") & week < as.Date("2023-07-04") ~ "2022-2023", 
      week >= as.Date("2023-07-04") & week < as.Date("2024-07-04") ~ "2023-2024",
      week >= as.Date("2024-07-04") & week <= as.Date("2025-07-05") ~ "2024-2025",
      TRUE ~ "Outside Period"
    )
  ) %>%
  filter(year_period != "Outside Period") %>%
  mutate(unique_program = paste(show_title, ifelse(is.na(season_title), "NA_SEASON", season_title), sep = " || ")) %>%
  group_by(country_name, year_period) %>%
  summarise(unique_programs_count = n_distinct(unique_program), .groups = "drop") %>%
  arrange(country_name, year_period)

# Calculate total growth (first year to last year)
growth_summary <- yearly_unique_programs %>%
  group_by(country_name) %>%
  arrange(year_period) %>%
  summarise(
    first_year = first(unique_programs_count),
    last_year = last(unique_programs_count),
    total_growth = round(((last_year - first_year) / first_year) * 100, 1),
    .groups = "drop"
  ) %>%
  mutate(total_growth_formatted = paste0(ifelse(total_growth > 0, "+", ""), total_growth, "%"))

# Create the presentation table
SOUTH_ASIA_GROWTH_TABLE <- yearly_unique_programs %>%
  select(country_name, year_period, unique_programs_count) %>%
  pivot_wider(
    names_from = year_period,
    values_from = unique_programs_count
  ) %>%
  left_join(growth_summary %>% select(country_name, total_growth_formatted), by = "country_name") %>%
  rename(
    Country = country_name,
    `2021-22` = `2021-2022`,
    `2022-23` = `2022-2023`,
    `2023-24` = `2023-2024`,
    `2024-25` = `2024-2025`,
    `Total Growth` = total_growth_formatted
  )

# Display only the interactive table
SOUTH_ASIA_GROWTH_TABLE %>%
  datatable(
    options = list(
      searching = FALSE, 
      info = FALSE, 
      paging = FALSE,
      columnDefs = list(
        list(className = 'dt-center', targets = 1:5),
        list(className = 'dt-left', targets = 0)
      )
    ),
    caption = "Netflix Top 10 Program Growth in South Asia (2021-2025)"
  )

```

<br>

## Task 7: Press Release 3 
## Billion-Hour Nostalgia: Telenovelas Dominate Netflix

<br>

Four classic telenovelas have collectively generated 1.2 billion global viewing hours on Netflix, demonstrating the enduring power of Spanish-language storytelling across Latin America and beyond.

CafÃ© con Aroma de Mujer, which debuted in 1994, leads with 813 million viewing hours, while Yo soy Betty, La Fea (1999) has amassed 297 million hours. Released in 2012, Pablo Escobar, el PatrÃ³n del Mal demonstrates exceptional longevity, maintaining 102 cumulative weeks in the top 10 across Colombia, El Salvador, Honduras, Nicaragua, and Venezuela, highlighting the cross-border appeal of Spanish-language content. These telenovelas demonstrate how archival content continues to captivate new audiences in the streaming era, appealing to viewers' nostalgia while introducing these stories to younger generations.

Netflix's content portfolio strikes a balance between classic content and original programming. Elite, a Netflix Original series launched in 2018, has generated 568 million hours across eight seasons, reaching all 17 Latin American markets, a feat also accomplished by Pablo Escobar. Through this dual content strategy, subscribers have options that cater to their preferences, with Netflix leveraging proven classics while developing contemporary series.

With 670 million Spanish speakers across Latin America, Netflix's combination of archival and original content positions the platform to serve diverse generational tastes while expanding its regional subscriber base.

<br>

```{r}

SPANISH_LATAMER <- c(
  "Argentina","Bolivia","Chile","Colombia","Costa Rica","Dominican Republic",
  "Ecuador","El Salvador","Guatemala","Honduras","Mexico","Nicaragua",
  "Panama","Paraguay","Peru","Uruguay","Venezuela"
)

COUNTRY_TOP_10 <- COUNTRY_TOP_10 %>%
  mutate(
    show_title = coalesce(show_title, "N/A"),
    season_title = coalesce(season_title, "N/A"))

LATAMER_TOP <- COUNTRY_TOP_10 %>%
  filter(country_name %in% SPANISH_LATAMER) %>%
  group_by(country_name, show_title, season_title) %>%
  summarise(max_cumulative = max(cumulative_weeks_in_top_10, na.rm = TRUE), .groups = "drop") %>%
  group_by(country_name) %>%
  slice_max(order_by = max_cumulative, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(country_name) %>%
  rename(
    Country = country_name,
    `Show Title` = show_title,
    `Season Title` = season_title,
    `Cumulative Weeks in Top 10` = max_cumulative
  )

datatable(
LATAMER_TOP,
caption = "Spanish-speaking Latin American Countries: Top Show/Season by Cumulative Weeks in Top 10",
  options = list(pageLength = 20, searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
)

```

<br>

```{r}

TOP_PROGRAMS <- tribble(
  ~show_title,                         ~season_title,                              ~avg_runtime_hrs,
  "CafÃ© con aroma de mujer",           "CafÃ© con aroma de mujer: Season 1",          43/60,  
  "Pablo Escobar, el patrÃ³n del mal",  "Pablo Escobar, el patrÃ³n del mal: Season 1", 45/60, 
  "PasiÃ³n de Gavilanes",               "PasiÃ³n de Gavilanes: Season 1",              44/60,  
  "Yo soy Betty, la fea",              "Yo soy Betty, la fea: Season 1",             30/60   
)

GLOBAL_CLEAN <- GLOBAL_TOP_10 %>%
  mutate(
    show_title   = coalesce(show_title, ""),
    season_title = coalesce(season_title, "")
  )

TOTALS_GLOBAL <- GLOBAL_CLEAN %>%
  inner_join(TOP_PROGRAMS, by = c("show_title", "season_title")) %>%
  group_by(category, show_title, season_title, avg_runtime_hrs) %>%
  summarise(
    `Total Weekly Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    `Approx Global Views` = round(`Total Weekly Hours Viewed` / avg_runtime_hrs)
  ) %>%
  transmute(
    Category        = category,
    `Show Title`    = show_title,
    `Season Title`  = season_title,
    `Total Weekly Hours Viewed`,
    `Avg Runtime (hrs)` = avg_runtime_hrs,
    `Approx Global Views`
  )

tot_row <- tibble(
  Category               = "TOTAL",
  `Show Title`           = "â€”",
  `Season Title`         = "â€”",
  `Total Weekly Hours Viewed` = sum(TOTALS_GLOBAL$`Total Weekly Hours Viewed`, na.rm = TRUE),
  `Avg Runtime (hrs)`    = NA_real_,
  `Approx Global Views`  = sum(TOTALS_GLOBAL$`Approx Global Views`, na.rm = TRUE)
)

final_tbl <- bind_rows(TOTALS_GLOBAL, tot_row)

datatable(
  final_tbl,
  caption = "Global Hours & Runtime-Adjusted Approximate Views (Cross-referenced from TSVs)",
  options = list(pageLength = 10, searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
) %>%
  formatCurrency(
    c("Total Weekly Hours Viewed", "Approx Global Views"),
    currency = "", digits = 0, mark = ","
  ) %>%
  formatRound("Avg Runtime (hrs)", digits = 2)

grand_total_hours <- sum(TOTALS_GLOBAL$`Total Weekly Hours Viewed`, na.rm = TRUE)
grand_total_views <- sum(TOTALS_GLOBAL$`Approx Global Views`, na.rm = TRUE)

cat("Grand Total Weekly Hours Viewed:", comma(grand_total_hours), "\n")
cat("Grand Total Approx Global Views:", comma(grand_total_views), "\n")
```

Hours are global for the listed titles as the country TSV does not contain this information.

<br>

*Note, average runtime values are approximations. The sources below provide details highlighting program runtime across episodes and seasons.

*[Netflixâ€™s Average Episode Runtime for Pablo Escobar: El PatrÃ³n del Mal](https://www.netflix.com/title/80035684?utm_source=chatgpt.com)*

*[Wikipediaâ€™s Average Episode Runtime for PasiÃ³n de Gavilanes](https://en.wikipedia.org/wiki/Pasi%C3%B3n_de_Gavilanes?utm_source=chatgpt.com)*

*[tvdbâ€™s Average Episode Runtime for CafÃ© con Aroma de Mujer](https://thetvdb.com/series/cafe-con-aroma-de-mujer-2021#general)*

*[IMDBâ€™s Average Episode Runtime for Yo Soy Betty, La Fea](https://www.imdb.com/title/tt0233127/?utm_source=chatgpt.com)*

<br>

```{r}

# --- Config: runtime assumption for Elite (TVMaze avg ~50 min) ---
elite_runtime <- 50/60  # hours

# --- Spanish-speaking LATAM (exclude Brazil) ---
latam_spanish <- c(
  "Argentina","Bolivia","Chile","Colombia","Costa Rica","Dominican Republic",
  "Ecuador","El Salvador","Guatemala","Honduras","Mexico","Nicaragua",
  "Panama","Paraguay","Peru","Uruguay","Venezuela"
)

# --- Count distinct LATAM countries where Elite charted (from COUNTRY_TOP_10) ---
elite_latam_country_count <- COUNTRY_TOP_10 %>%
  mutate(show_title = coalesce(show_title, "")) %>%
  filter(show_title == "Elite", country_name %in% latam_spanish) %>%
  summarise(n_countries = n_distinct(country_name), .groups = "drop") %>%
  pull(n_countries) %>%
  { if (length(.) == 0 || is.na(.)) 0 else . }  # safety if no rows

# --- Global totals + runtime-adjusted views (from GLOBAL_TOP_10) ---
elite_total <- GLOBAL_TOP_10 %>%
  mutate(show_title = coalesce(show_title, "")) %>%
  filter(show_title == "Elite") %>%
  summarise(
    `Total Weekly Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    Category                          = "TV (Non-English)",
    `Show Title`                      = "Elite",
    `Season Title`                    = "All Seasons (8)",
    `Avg Runtime (hrs)`               = elite_runtime,
    `Approx Global Views`             = round(`Total Weekly Hours Viewed` / elite_runtime),
    `Number of LATAM Countries Reached` = elite_latam_country_count,
    `Total Weekly Hours Viewed`       = comma(`Total Weekly Hours Viewed`),
    `Approx Global Views`             = comma(`Approx Global Views`)
  ) %>%
  select(
    Category, `Show Title`, `Season Title`,
    `Total Weekly Hours Viewed`, `Avg Runtime (hrs)`, `Approx Global Views`,
    `Number of LATAM Countries Reached`
  )

# --- Render ---
datatable(
  elite_total,
  caption = "Global Hours & Runtime-Adjusted Approximate Views (Cross-referenced from TSVs)",
  options = list(searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
) %>%
  formatRound("Avg Runtime (hrs)", digits = 2)

```

<br>


*[TVMaze's Average Episode Runtime for Elite](https://www.tvmaze.com/shows/37854/elite?utm_source=chatgpt.com)*
