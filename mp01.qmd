---
title: "STA 9750 Mini-Project #01: Netflix Analysis"
author: "Eduardo Alarcon"
format: 
  html:
    code-fold: true
    code-summary: "Show code"
execute:
  message: false
  warning: false
---

```{r setup}
library(dplyr)
library(lubridate)
library(readr)
library(scales)
library(tidyverse)
library(knitr)
library(ggplot2)
```

```{r}
#| include: false 

if(!dir.exists(file.path("data", "mp01"))){ dir.create(file.path("data", "mp01"), showWarnings=FALSE, recursive=TRUE) }
GLOBAL_TOP_10_FILENAME <- file.path("data", "mp01", "global_top10_alltime.csv")
if(!file.exists(GLOBAL_TOP_10_FILENAME)){ download.file("https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv", destfile=GLOBAL_TOP_10_FILENAME) }
COUNTRY_TOP_10_FILENAME <- file.path("data", "mp01", "country_top10_alltime.csv")
if(!file.exists(COUNTRY_TOP_10_FILENAME)){ download.file("https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv", destfile=COUNTRY_TOP_10_FILENAME) }

if(!require("tidyverse")) install.packages("tidyverse")

GLOBAL_TOP_10 <- read_tsv(GLOBAL_TOP_10_FILENAME)
str(GLOBAL_TOP_10)
glimpse(GLOBAL_TOP_10)

GLOBAL_TOP_10 <- GLOBAL_TOP_10 %>%
  mutate(season_title = if_else(season_title == "N/A", NA, season_title))
glimpse(GLOBAL_TOP_10)

COUNTRY_TOP_10 <- read_tsv(COUNTRY_TOP_10_FILENAME, na = "N/A")
glimpse(COUNTRY_TOP_10)
str(COUNTRY_TOP_10)

n_distinct(COUNTRY_TOP_10$country_name)

GLOBAL_TOP_10 %>%
filter(category == "Films (Non-English)") %>%
group_by(show_title) %>%
summarise(max_cumulweeks = max(cumulative_weeks_in_top_10, na.rm = TRUE)) %>%
arrange(desc(max_cumulweeks)) %>%
slice(1)

library(stringr)
library(DT)

format_titles <- function(df){
    colnames(df) <- str_replace_all(colnames(df), "_", " ") |> str_to_title()
    df
}

GLOBAL_TOP_10 |> 
head(n=20) |>
datatable(options=list(searching=FALSE, info=FALSE))

GLOBAL_TOP_10 |> 
format_titles() |>
head(n=20) |>
datatable(options=list(searching=FALSE, info=FALSE)) |>
formatRound(c('Weekly Hours Viewed', 'Weekly Views'))

```

## Task 4

The following questions address Task 4. Please click on the "Show Code" for an detailed approach on how I obtained my results.

<br>

1. How many different countries does Netflix operate in? (You can use the viewing history as a proxy for countries in which Netflix operates.)

```{r}
#| output: false
n_distinct(COUNTRY_TOP_10$country_name)
``` 
**Answer:** Netflix operates in ```r n_distinct(COUNTRY_TOP_10$country_name)``` different countries based on the viewing history data.

<br>

2. Which non-English-language film has spent the most cumulative weeks in the global top 10? How many weeks did it spend?

```{r}
Q2_RESULT <- GLOBAL_TOP_10 %>%
filter(category == "Films (Non-English)") %>%
group_by(show_title) %>%
summarise(`Maximum Cumulative Weeks` = max(cumulative_weeks_in_top_10, na.rm = TRUE)) %>%
arrange(desc(`Maximum Cumulative Weeks`)) %>%
slice(1)

film_name_2 <- Q2_RESULT$show_title
weeks_count_2 <- Q2_RESULT[[2]]

Q2_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The non-English-language film `r film_name_2` spent the most cumulative weeks in the Global Top 10, with `r weeks_count_2` weeks.

<br>

3.	What is the longest film (English or non-English) to have ever appeared in the Netflix global Top 10? How long is it in minutes?
```{r}
Q3_RESULT <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "Films (English)")) %>%
  filter(!is.na(runtime)) %>%   
  group_by(show_title) %>%
  summarise(max_runtime = max(runtime)) %>%   
  arrange(desc(max_runtime)) %>%
  slice(1) %>%
  mutate(max_runtime_minutes = round(60 * max_runtime))

film_name_3 <- Q3_RESULT$show_title
run_time_3 <- Q3_RESULT[[3]]

Q3_RESULT %>%
select(-max_runtime) %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The longest English or non-English film to have ever topped in the Netflix Global Top 10 is `r film_name_3`, with a length of `r run_time_3` minutes.

<br>

4. For each of the four categories, what program has the most total hours of global viewership?

```{r}
Q4_RESULT <- GLOBAL_TOP_10 %>%
group_by(category, show_title) %>%
summarise(total_hours_global_viewership = sum(weekly_hours_viewed, na.rm = TRUE), .groups = "drop") %>%
group_by(category) %>%
slice_max(total_hours_global_viewership, n = 1) %>%
arrange(desc(total_hours_global_viewership)) %>%
mutate(total_hours_global_viewership = comma(total_hours_global_viewership))

Q4_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** The above table highlights calculations that sum all seasons together (i.e.,franchise-level data). In other words, Stranger Things and Squid Game reflect the combined global viewership across all of their respective seasons.

<br>

5.	Which TV show had the longest run in a country’s Top 10? How long was this run and in what country did it occur?

```{r}

Q5_RESULT <- COUNTRY_TOP_10 %>%
filter(category == "TV") %>%
filter(!is.na(season_title)) %>%
group_by(country_name, show_title) %>%
summarise(max_cumulative_weeks = max(cumulative_weeks_in_top_10), .groups = "drop") %>%
arrange(desc(max_cumulative_weeks)) %>%
slice(1)

Q5_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Money Heist had the longest run in Pakistan, with 127 weeks in Netflix's Country Top 10 list. 

<br>

6. Netflix provides over 200 weeks of service history for all but one country in our data set. Which country is this and when did Netflix cease operations in that country?

```{r}

Q6_RESULT <- COUNTRY_TOP_10 %>%
group_by(country_name) %>%
summarise(total_weeks_of_data = n_distinct(week),final_week = max(week, na.rm = TRUE)) %>%
filter(total_weeks_of_data < 200) %>%
arrange(total_weeks_of_data)

Q6_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** Netflix could not provide over 200 weeks of service for Russia, as it ceased operations during the week of February 27, 2022, resulting in 35 weeks of data in the Country Top 10 list.

<br>

7. What is the total viewership of the TV show Squid Game? Note that there are three seasons total and we are looking for the total number of hours watched across all seasons.

```{r}
Q7_RESULT_SEASONS <- GLOBAL_TOP_10 %>%
filter(show_title == "Squid Game") %>%
filter(!is.na(season_title)) %>%
group_by(season_title) %>%
summarise(sum_hours = sum(weekly_hours_viewed, na.rm = TRUE)) %>%
mutate(hours_watched = comma(sum_hours))

Q7_RESULT_SEASONS_SUM <- Q7_RESULT_SEASONS %>%
summarise(
season_title = "Total Hours Watched Across All Seasons",
sum_hours_1 = sum(sum_hours),
hours_watched = comma(sum_hours_1))

Q7_RESULT_FINAL <- bind_rows(Q7_RESULT_SEASONS, Q7_RESULT_SEASONS_SUM) %>%
select(season_title, hours_watched)

Q7_RESULT_FINAL %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Across all three seasons, Squid Game had a total of 5,048,300,000 hours of global viewership. 

<br>

8. The movie Red Notice has a runtime of 1 hour and 58 minutes. Approximately how many views did it receive in 2021?

```{r}

library(dplyr)
library(lubridate)
library(scales)
library(DT)
library(tibble)

Q8_ROWS <- GLOBAL_TOP_10 %>%
  mutate(week = as.Date(week)) %>%
  filter(show_title == "Red Notice", year(week) == 2021)

if (nrow(Q8_ROWS) == 0) {
  Q8_RESULT <- tibble(
    `Total Hours Viewed (2021)` = "N/A",
    `Approximate Views` = "N/A"
  )
} else {
Q8_RESULT <- Q8_ROWS %>%
summarise(
total_hours_2021 = sum(weekly_hours_viewed, na.rm = TRUE),
runtime_hours = 1 + 58/60,  # 1h 58m
approximate_views = total_hours_2021 / runtime_hours) %>%
mutate(`Total Hours Viewed (2021)` = comma(total_hours_2021), `Approximate Views` = comma(round(approximate_views))) %>%
select(`Total Hours Viewed (2021)`, `Approximate Views`)
}

Q8_RESULT %>%
datatable(options = list( searching = FALSE, info = FALSE, paging = FALSE,
columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** Based on the total number of hours viewed in 2021, Red Notice has approximately, 201,732,203 global views.

<br>

9. Part A: How many Films reached Number 1 in the US but did not originally debut there? 


```{r}

COUNTRY_TOP_10_US_ONLY <- COUNTRY_TOP_10 %>%
  filter(country_iso2 == "US", category == "Films") %>%
  mutate(week = as.Date(week))

US_FILMS_REACH1 <- COUNTRY_TOP_10_US_ONLY %>%
  group_by(show_title) %>%
  summarise(best_rank = min(weekly_rank, na.rm = TRUE), .groups = "drop") %>%
  filter(best_rank == 1)

US_DEBUT <- COUNTRY_TOP_10_US_ONLY %>%
  group_by(show_title) %>%
  arrange(week, .by_group = TRUE) %>%    
  slice(1L) %>%                         
  ungroup() %>%
  transmute(show_title, debut_week = week, debut_rank = weekly_rank)

Q9_RESULT_PT1 <- US_FILMS_REACH1 %>%
  inner_join(US_DEBUT, by = "show_title") %>%
  filter(debut_rank > 1) %>%
  summarise(number_of_films = n())

```

<br>

**Answer:** A total of ```r Q9_RESULT_PT1``` films in the US reached to Number 1 after debuting at a lower ranking. 

<br>

9. Part B: What is the most recent film to pull this off?

```{r}

Q9_RESULT_PT2 <- COUNTRY_TOP_10 %>%
filter(country_iso2 == "US", category == "Films") %>%
mutate(week = as.Date(week)) %>%
group_by(show_title) %>%
summarise(
debut_week = min(week),
debut_rank = weekly_rank[which.min(week)],
best_rank  = min(weekly_rank, na.rm = TRUE),
.groups = "drop") %>%
filter(best_rank == 1, debut_rank > 1) %>%
inner_join(COUNTRY_TOP_10 %>%
filter(country_iso2 == "US", category == "Films") %>%
mutate(week = as.Date(week)) %>%
select(show_title, week, weekly_rank), by = "show_title") %>%
filter(weekly_rank == 1) %>%
slice_max(order_by = week, n = 1, with_ties = FALSE) %>%
transmute(`Most Recent Film` = show_title, `Date Reached #1` = week)


Q9_RESULT_PT2 %>%
datatable(
  options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The most recent film to accomplish this was KPop Demon Hunters, which reached Number 1 during the week of September 14, 2025. 

<br>

10. Which TV show/season hit the top 10 in the most countries in its debut week? In how many countries did it chart?

```{r}

COUNTRY_TOP_10_DEBUT <- COUNTRY_TOP_10 %>%
filter(category == "TV") %>%
group_by(show_title, season_title, country_name) %>%
summarise(
debut_week = min(week, na.rm = TRUE),
debut_rank = weekly_rank[which.min(week)][1],
.groups = "drop"
) %>%
arrange(debut_week)

Q10_RESULT <- COUNTRY_TOP_10_DEBUT %>% 
group_by(show_title, season_title, debut_week) %>% 
summarise(country_appearance = n_distinct(country_name), .groups = "drop") %>% 
arrange(desc(country_appearance)) %>% 
slice(1) %>%
rename(`Show Title` = show_title, `Season Title` = season_title, `Debut Week` = debut_week, `Number of Countries Charted` = country_appearance)

Q10_RESULT %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Emily in Paris (Season 2) charted in 94 countries during its debut week in December 26, 2021. 

<br>

## Task 5: 
## Press Release 1: Stranger Things

The following task involves creating a "Press Release" for the upcoming release of the final season of Stranger Things.  

<br>

```{r}
STRANGE_GLOBAL_VIEWERSHIP <- GLOBAL_TOP_10 %>%
filter(show_title == "Stranger Things") %>%
mutate(season_display = ifelse(is.na(season_title), "Stranger Things: S1", season_title)) %>%
group_by(season_display) %>%
summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE)) %>%
mutate(season_display = case_when(
season_display == "Stranger Things 2" ~ "Stranger Things: S2",
season_display == "Stranger Things 3" ~ "Stranger Things: S3",
season_display == "Stranger Things 4" ~ "Stranger Things: S4", TRUE ~ season_display)) %>%
mutate(avg_episode_minutes = case_when(
season_display == "Stranger Things: S1" ~ 47,
season_display == "Stranger Things: S2" ~ 60,
season_display == "Stranger Things: S3" ~ 60,
season_display == "Stranger Things: S4" ~ 87, TRUE ~ NA_real_),
avg_episode_hours = avg_episode_minutes / 60,
approximate_views = total_hours / avg_episode_hours,
total_hours_viewed = comma(total_hours),
approximate_viewership = comma(round(approximate_views))) %>%
arrange(season_display)

STRANGE_TOTAL_VIEWERSHIP <- STRANGE_GLOBAL_VIEWERSHIP %>%
filter(!is.na(avg_episode_minutes)) %>%
summarise(
season_display = "Totals",
total_hours = sum(total_hours),
total_views = sum(approximate_views, na.rm = TRUE),
avg_episode_minutes = NA_real_,
total_hours_viewed = comma(total_hours),
approximate_viewership = comma(round(total_views)))

STRANGE_VIEWERSHIP_SYNTH <- bind_rows(
STRANGE_GLOBAL_VIEWERSHIP %>% select(season_display, total_hours_viewed, avg_episode_minutes, approximate_viewership),
STRANGE_TOTAL_VIEWERSHIP %>% select(season_display, total_hours_viewed, avg_episode_minutes, approximate_viewership)
) %>%
rename( Season = season_display, `*Average Episode Minutes` = avg_episode_minutes)

STRANGE_VIEWERSHIP_SYNTH %>%
format_titles() %>%
datatable(
options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

*Average minutes derived from the following sources:

*[Wikipedia's List of Stranger Things Episodes](https://en.wikipedia.org/wiki/List_of_Stranger_Things_episodes)*

*[Netflix's Official Tudum Blog](https://www.netflix.com/tudum/articles/stranger-things-season-4-episode-length)*

```{r}

STRANGE_POPULARITY <- GLOBAL_TOP_10 %>%
filter(show_title == "Stranger Things") %>%
mutate(season_display = ifelse(is.na(season_title), "Stranger Things: S1", season_title)) %>%
mutate(season_display = case_when(
season_display == "Stranger Things 2" ~ "Stranger Things: S2",
season_display == "Stranger Things 3" ~ "Stranger Things: S3",
season_display == "Stranger Things 4" ~ "Stranger Things: S4",
TRUE ~ season_display)) %>%
group_by(season_display) %>%
summarise(
weeks_in_top_10 = n_distinct(week),
weeks_at_number_1 = sum(weekly_rank == 1, na.rm = TRUE) ) %>%
arrange(season_display) %>%
rename(Season = season_display)

STRANGE_POPULARITY %>%
format_titles() %>%
datatable(
options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

```{r}
STRANGE_COUNTRY10_SUMMARY <- COUNTRY_TOP_10 %>%
filter(show_title == "Stranger Things") %>%
mutate(season_display = ifelse(is.na(season_title), "Stranger Things: S1", season_title)) %>%
group_by(country_name) %>%
summarise(total_weeks_in_top_10 = n_distinct(week)) %>%
summarise(
`Total Countries` = n(),
`Average Weeks in Top 10` = round(mean(total_weeks_in_top_10), 1))

STRANGE_COUNTRY10_SUMMARY %>%
datatable(
options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

```{r}
ST_TOP_COUNTRIES_WEEKS <- COUNTRY_TOP_10 %>%
filter(show_title == "Stranger Things") %>%
mutate(season_display = ifelse(is.na(season_title), "Stranger Things: S1", season_title)) %>%
group_by(country_name) %>%
summarise(total_weeks_in_top_10 = n_distinct(week)) %>%
arrange(desc(total_weeks_in_top_10)) %>%
slice(1:10) %>%
rename(Country = country_name)

ST_TOP_COUNTRIES_WEEKS %>%
format_titles() %>%
datatable(
options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

## Task 6:
## Press Release 2: Commercial Success in India

<br>

```{r}

INDIA_SHOWS_LIST <- COUNTRY_TOP_10 %>%
filter(country_name == "India") %>%
distinct(show_title, season_title, category) %>%
mutate(content_type = case_when(
str_detect(category, "Films") ~ "Films",
str_detect(category, "TV") ~ "TV Shows",TRUE ~ "Other")) %>%
arrange(content_type, show_title, season_title)

INDIA_TOTAL_PROGRAMS <- INDIA_SHOWS_LIST %>%
count(content_type, name = "distinct_shows") %>%
mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

INDIA_TOTAL_PROGRAMS %>%
rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

total_shows <- sum(INDIA_TOTAL_PROGRAMS$distinct_shows)
cat("Total distinct viewing options in India:", total_shows)
```

<br>

```{r}

india_exclusive_from_us <- COUNTRY_TOP_10 %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE)

india_only_list <- COUNTRY_TOP_10 %>%
  filter(country_name == "India") %>%
  semi_join(india_exclusive_from_us, by = c("show_title", "season_title")) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil")) %>%
  distinct(show_title, season_title, category) %>%
  mutate(content_type = case_when(
    str_detect(category, "Films") ~ "Films",
    str_detect(category, "TV") ~ "TV Shows",
    TRUE ~ "Other"
  )) %>%
  arrange(content_type, show_title, season_title)

india_only_breakdown <- india_only_list %>%
  count(content_type, name = "distinct_shows") %>%
  mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

india_only_breakdown %>%
  rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

total_india_only <- sum(india_only_breakdown$distinct_shows)
cat("Total distinct viewing options in India that do NOT 
  appear in US (excluding Telugu/Tamil language viewing options):", total_india_only)

```

<br>

```{r}

india_exclusive_combinations <- COUNTRY_TOP_10 %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil"))

global_appearing_breakdown <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  distinct(show_title, season_title, category) %>%
  mutate(content_type = case_when(
    str_detect(category, "Films") ~ "Films",
    str_detect(category, "TV") ~ "TV Shows",
    TRUE ~ "Other"
  )) %>%
  count(content_type, name = "distinct_shows") %>%
  mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

films_metrics <- GLOBAL_TOP_10 %>%
  filter(category == "Films (Non-English)") %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))

tv_metrics <- GLOBAL_TOP_10 %>%
  filter(category == "TV (Non-English)") %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))

shows_in_global_count <- sum(global_appearing_breakdown$distinct_shows)
total_combinations <- nrow(india_exclusive_combinations)
global_penetration <- round((shows_in_global_count / total_combinations) * 100, 1)

INDIA_EXCLUSIVE_SUMMARY <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    avg_weeks_in_top_10 = mean(cumulative_weeks_in_top_10, na.rm = TRUE),
    max_weeks_in_top_10 = max(cumulative_weeks_in_top_10, na.rm = TRUE)
  ) %>%
  mutate(
    total_hours_formatted = comma(total_hours_viewed),
    avg_weeks_formatted = round(avg_weeks_in_top_10, 1)
  )

GLOBAL_REACH_SUMMARY <- data.frame(
  Metric = c("Total Show+Season Combinations", 
             "Total Hours Viewed - Non-English Films", 
             "Total Hours Viewed - Non-English TV",
             "Combined Hours Viewed (Non-English)", 
             "Average Weeks in Global Top 10", "Maximum Weeks in Global Top 10", 
             "Non-English Combinations in Global Charts", "Non-English Global Chart Penetration Rate"),
  Value = c(
    total_combinations,
    comma(films_metrics$total_hours), 
    comma(tv_metrics$total_hours),
    INDIA_EXCLUSIVE_SUMMARY$total_hours_formatted,
    paste0(INDIA_EXCLUSIVE_SUMMARY$avg_weeks_formatted, " weeks"),
    paste0(INDIA_EXCLUSIVE_SUMMARY$max_weeks_in_top_10, " weeks"),
    paste0(shows_in_global_count, " of ", total_combinations, " combinations"),
    paste0(global_penetration, "%")
  )
)

cat("India-exclusive NON-ENGLISH, (proxy for Hindi; excludes Telugu/Tamil) that achieved global top 10 status:\n")
global_appearing_breakdown %>%
  rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

cat("Total NON-ENGLISH (proxy for Hindi; excludes Telugu/Tamil) appearing in global charts:", shows_in_global_count, "of", total_combinations, "\n\n")

GLOBAL_REACH_SUMMARY %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE))
```


<br>


```{r}

india_exclusive_combinations <- COUNTRY_TOP_10 %>%
  mutate(season_title = coalesce(season_title, "")) %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil"))

INDIA_EXCLUSIVE_METRICS <- GLOBAL_TOP_10 %>%
  mutate(season_title = coalesce(season_title, "")) %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%  
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  group_by(show_title, season_title, category) %>%
  summarise(
    total_weekly_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    avg_runtime_minutes = round(mean(runtime, na.rm = TRUE) * 60, 0),
    total_weekly_views = sum(weekly_views, na.rm = TRUE),
    max_cumulative_weeks_in_top_10 = max(cumulative_weeks_in_top_10, na.rm = TRUE),
    weeks_appeared = n_distinct(week),
    .groups = "drop"
  ) %>%
  mutate(
    content_type = case_when(
      str_detect(category, "Films") ~ "Films",
      str_detect(category, "TV") ~ "TV Shows",
      TRUE ~ "Other"
    ),
    total_hours_formatted = comma(total_weekly_hours_viewed),
    total_views_formatted = comma(total_weekly_views)
  ) %>%
  arrange(desc(total_weekly_hours_viewed)) %>%
  select(show_title, season_title, content_type, total_hours_formatted, avg_runtime_minutes, 
         total_views_formatted, max_cumulative_weeks_in_top_10, weeks_appeared)

INDIA_EXCLUSIVE_METRICS %>%
  format_titles() %>%
  datatable(options = list(searching = TRUE, info = TRUE, paging = TRUE, pageLength = 5, columnDefs = list(list(className = 'dt-left', targets = "_all"))))


```

<br>

```{r}

india_exclusive_combinations <- COUNTRY_TOP_10 %>%
  mutate(season_title = coalesce(season_title, "")) %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us    = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india & !appears_in_us) %>%
  filter(!str_detect(show_title, regex("telugu|tamil", ignore_case = TRUE)))

yearly_hours <- GLOBAL_TOP_10 %>%
  mutate(season_title = coalesce(season_title, ""),
         week = as.Date(week)) %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title","season_title")) %>%
  mutate(week = as.Date(week)) %>%
  mutate(
    year_period = case_when(
      week >= as.Date("2021-07-04") & week < as.Date("2022-07-04") ~ "2021-2022",
      week >= as.Date("2022-07-04") & week < as.Date("2023-07-04") ~ "2022-2023", 
      week >= as.Date("2023-07-04") & week < as.Date("2024-07-04") ~ "2023-2024",
      week >= as.Date("2024-07-04") & week < as.Date("2025-07-04") ~ "2024-2025",
      TRUE ~ "Outside Period"
    )
  ) %>%
  filter(year_period != "Outside Period") %>%
  group_by(year_period) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(year_period) %>%
  mutate(
    total_hours_formatted = comma(total_hours_viewed),
    yoy_change = ifelse(row_number() == 1, NA, 
                       round(((total_hours_viewed - lag(total_hours_viewed)) / lag(total_hours_viewed)) * 100, 1)),
    yoy_change_formatted = ifelse(is.na(yoy_change), "N/A", 
                                 paste0(ifelse(yoy_change > 0, "+", ""), yoy_change, "%"))
  )

yearly_hours <- yearly_hours %>%
  mutate(year_period = factor(year_period,
    levels = c("2021-2022","2022-2023","2023-2024","2024-2025")))

YEARLY_ANALYSIS <- yearly_hours %>%
  select(year_period, total_hours_formatted, yoy_change_formatted) %>%
  rename(
    `Year Period` = year_period,
    `Total Hours Viewed` = total_hours_formatted,
    `Year-over-Year Change` = yoy_change_formatted
  )

cat("India-exclusive NON-ENGLISH (proxy for Hindi; excludes Telugu/Tamil) Content - Yearly Viewing Hours Analysis:\n")
YEARLY_ANALYSIS %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

ggplot(yearly_hours, aes(x = year_period, y = total_hours_viewed, group = 1)) +
  geom_line(color = "steelblue", size = 1.2) +
  geom_point(color = "darkred", size = 3) +
 labs(
    title = "Yearly Viewing Hours for India-Exclusive Non-English Content",
    x = "Year Period",
    y = "Total Hours Viewed", 
    caption = "Source: Netflix Top 10 data (all weeks)"
  ) +
  scale_y_continuous(labels = comma)

first_year <- yearly_hours$total_hours_viewed[1]
last_year  <- yearly_hours$total_hours_viewed[nrow(yearly_hours)]

total_growth <- if (first_year > 0) {
  round(((last_year - first_year) / first_year) * 100, 1)
} else { NA_real_ }

avg_annual_growth <- round(mean(yearly_hours$yoy_change, na.rm = TRUE), 1)

cat("\nGrowth Summary:\n")
cat("Total Growth (2021-2022 to 2024-2025):", total_growth, "%\n")
cat("Average Annual Growth Rate:", avg_annual_growth, "%")

```

<br>

```{r}

# Define South Asian countries (excluding Nepal)
south_asian_countries <- c("India", "Pakistan", "Bangladesh", "Sri Lanka")

# Calculate unique programs by year for each country
yearly_unique_programs <- COUNTRY_TOP_10 %>%
  filter(country_name %in% south_asian_countries) %>%
  mutate(
    year_period = case_when(
      week >= as.Date("2021-07-04") & week < as.Date("2022-07-04") ~ "2021-2022",
      week >= as.Date("2022-07-04") & week < as.Date("2023-07-04") ~ "2022-2023", 
      week >= as.Date("2023-07-04") & week < as.Date("2024-07-04") ~ "2023-2024",
      week >= as.Date("2024-07-04") & week <= as.Date("2025-07-05") ~ "2024-2025",
      TRUE ~ "Outside Period"
    )
  ) %>%
  filter(year_period != "Outside Period") %>%
  mutate(unique_program = paste(show_title, ifelse(is.na(season_title), "NA_SEASON", season_title), sep = " || ")) %>%
  group_by(country_name, year_period) %>%
  summarise(unique_programs_count = n_distinct(unique_program), .groups = "drop") %>%
  arrange(country_name, year_period)

# Calculate year-over-year changes
yearly_programs_with_change <- yearly_unique_programs %>%
  arrange(country_name, year_period) %>%
  group_by(country_name) %>%
  mutate(
    yoy_change = ifelse(row_number() == 1, NA, 
                       round(((unique_programs_count - lag(unique_programs_count)) / lag(unique_programs_count)) * 100, 1)),
    yoy_change_formatted = ifelse(is.na(yoy_change), "N/A", 
                                 paste0(ifelse(yoy_change > 0, "+", ""), yoy_change, "%"))
  ) %>%
  ungroup()

# Create separate tables for counts and changes
counts_table <- yearly_programs_with_change %>%
  select(country_name, year_period, unique_programs_count) %>%
  pivot_wider(names_from = country_name, values_from = unique_programs_count, values_fill = 0) %>%
  arrange(year_period)

changes_table <- yearly_programs_with_change %>%
  select(country_name, year_period, yoy_change_formatted) %>%
  pivot_wider(names_from = country_name, values_from = yoy_change_formatted, values_fill = "N/A") %>%
  arrange(year_period)

# Combine tables with alternating count and change columns
SOUTH_ASIA_DETAILED_ANALYSIS <- counts_table %>%
  rename(`Year Period` = year_period) %>%
  left_join(changes_table %>% rename(`Year Period` = year_period), by = "Year Period", suffix = c("_Count", "_Change")) %>%
  select(`Year Period`, 
         India_Count, India_Change,
         Pakistan_Count, Pakistan_Change,
         Bangladesh_Count, Bangladesh_Change,
         `Sri Lanka_Count`, `Sri Lanka_Change`) %>%
  rename(
    `India Count` = India_Count,
    `India YoY Change` = India_Change,
    `Pakistan Count` = Pakistan_Count,
    `Pakistan YoY Change` = Pakistan_Change,
    `Bangladesh Count` = Bangladesh_Count,
    `Bangladesh YoY Change` = Bangladesh_Change,
    `Sri Lanka Count` = `Sri Lanka_Count`,
    `Sri Lanka YoY Change` = `Sri Lanka_Change`
  )

# Display the main analysis
cat("South Asian Countries - Unique Programs with Separate Rate of Change Columns:\n")
SOUTH_ASIA_DETAILED_ANALYSIS %>%
  datatable(options = list(
    searching = FALSE, 
    info = FALSE, 
    paging = FALSE,
    scrollX = TRUE,
    columnDefs = list(
      list(className = 'dt-left', targets = "_all"),
      list(width = '80px', targets = 1:8)
    )
  ))

# Calculate summary statistics (excluding 2021-2022)
summary_stats <- yearly_programs_with_change %>%
  filter(year_period != "2021-2022") %>%  # Exclude baseline year
  filter(!is.na(yoy_change)) %>%
  group_by(country_name) %>%
  summarise(
    avg_yoy_change = round(mean(yoy_change, na.rm = TRUE), 1),
    total_growth = round(sum(yoy_change, na.rm = TRUE), 1),
    max_single_year_growth = round(max(yoy_change, na.rm = TRUE), 1),
    years_with_data = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(avg_yoy_change))

# Display summary chart

# Display summary chart - Average YoY Change Only
cat("\n\nSummary: Average Year-over-Year Change by Country (Excluding 2021-2022 Baseline):\n")
summary_stats <- yearly_programs_with_change %>%
filter(year_period != "2021-2022") %>%  # Exclude baseline year
filter(!is.na(yoy_change)) %>%
group_by(country_name) %>%
summarise(
avg_yoy_change = round(mean(yoy_change, na.rm = TRUE), 1),
.groups = "drop") %>%
arrange(desc(avg_yoy_change))  # Back to descending order

summary_stats %>%
rename(
Country = country_name,
`Average YoY Change` = avg_yoy_change) %>%
datatable(options = list(
searching = FALSE, 
info = FALSE, 
paging = FALSE,
columnDefs = list(list(className = 'dt-center', targets = "_all"))))

# Identify the top performer
top_country <- summary_stats$country_name[1]
top_avg_growth <- summary_stats$avg_yoy_change[1]

cat("\nHighlight: ", top_country, " shows the greatest average year-over-year growth rate at ", top_avg_growth, "% annually.")

```

<br>

## Task 7:
## Press Release 3: Latin American Trends

<br>

```{r}

# Define Spanish-speaking Latin American countries (exclude Brazil)
spanish_latam <- c(
  "Argentina","Bolivia","Chile","Colombia","Costa Rica","Dominican Republic",
  "Ecuador","El Salvador","Guatemala","Honduras","Mexico","Nicaragua",
  "Panama","Paraguay","Peru","Uruguay","Venezuela"
)

# Ensure NA values handled consistently
COUNTRY_TOP_10 <- COUNTRY_TOP_10 %>%
  mutate(
    show_title = coalesce(show_title, "N/A"),
    season_title = coalesce(season_title, "N/A")
  )

# Identify the single show/season with most cumulative weeks for each country
latam_top <- COUNTRY_TOP_10 %>%
  filter(country_name %in% spanish_latam) %>%
  group_by(country_name, show_title, season_title) %>%
  summarise(max_cumulative = max(cumulative_weeks_in_top_10, na.rm = TRUE), .groups = "drop") %>%
  group_by(country_name) %>%
  slice_max(order_by = max_cumulative, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(country_name) %>%
  rename(
    Country = country_name,
    `Show Title` = show_title,
    `Season Title` = season_title,
    `Cumulative Weeks in Top 10` = max_cumulative
  )

# Display interactive table
datatable(
  latam_top,
  caption = "Spanish-speaking Latin American Countries: Top Show/Season by Cumulative Weeks in Top 10",
  options = list(pageLength = 20, searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
)

```

```{r}
# --- Assumes GLOBAL_TOP_10 is already loaded from all-weeks-global.tsv ---

# 1) Define the exact show/season targets and runtimes (in hours) from external sources
targets <- tribble(
  ~show_title,                         ~season_title,                              ~avg_runtime_hrs,
  "Café con aroma de mujer",           "Café con aroma de mujer: Season 1",        45/60,  # Wikipedia: ~45m
  "Pablo Escobar, el patrón del mal",  "Pablo Escobar, el patrón del mal: Season 1", 45/60, # Netflix: ~45m
  "Pasión de Gavilanes",               "Pasión de Gavilanes: Season 1",            44/60,  # Wikipedia: 42–45m → use 44m
  "Yo soy Betty, la fea",              "Yo soy Betty, la fea: Season 1",           30/60   # IMDb: ~30m
)

# 2) Make sure GLOBAL_TOP_10 has consistent NA handling
g_global <- GLOBAL_TOP_10 %>%
  mutate(
    show_title   = coalesce(show_title, ""),
    season_title = coalesce(season_title, "")
  )

# 3) Pull totals for the four target shows/seasons
totals <- g_global %>%
  inner_join(targets, by = c("show_title", "season_title")) %>%
  group_by(category, show_title, season_title, avg_runtime_hrs) %>%
  summarise(
    `Total Weekly Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    `Approx Global Views` = round(`Total Weekly Hours Viewed` / avg_runtime_hrs)
  ) %>%
  transmute(
    Category        = category,
    `Show Title`    = show_title,
    `Season Title`  = season_title,
    `Total Weekly Hours Viewed`,
    `Avg Runtime (hrs)` = avg_runtime_hrs,
    `Approx Global Views`
  )

# 4) Add TOTAL row
tot_row <- tibble(
  Category               = "TOTAL",
  `Show Title`           = "—",
  `Season Title`         = "—",
  `Total Weekly Hours Viewed` = sum(totals$`Total Weekly Hours Viewed`, na.rm = TRUE),
  `Avg Runtime (hrs)`    = NA_real_,
  `Approx Global Views`  = sum(totals$`Approx Global Views`, na.rm = TRUE)
)

final_tbl <- bind_rows(totals, tot_row)

# 5) Display as interactive datatable
datatable(
  final_tbl,
  caption = "Global Hours & Runtime-Adjusted Approximate Views (Cross-referenced from TSVs)",
  options = list(pageLength = 10, searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
) %>%
  formatCurrency(
    c("Total Weekly Hours Viewed", "Approx Global Views"),
    currency = "", digits = 0, mark = ","
  ) %>%
  formatRound("Avg Runtime (hrs)", digits = 2)

# 6) Print grand totals to console too
grand_total_hours <- sum(totals$`Total Weekly Hours Viewed`, na.rm = TRUE)
grand_total_views <- sum(totals$`Approx Global Views`, na.rm = TRUE)

cat("Grand Total Weekly Hours Viewed:", comma(grand_total_hours), "\n")
cat("Grand Total Approx Global Views:", comma(grand_total_views), "\n")
```

Hours are global for the listed titles as the country TSV does not contain this information.

*[Netflix’s Average Episode Runtime for Pablo Escobar: El Patrón del Mal](https://www.netflix.com/title/80035684?utm_source=chatgpt.com)*

*[Wikipedia’s Average Episode Runtime for Pasión de Gavilanes](https://en.wikipedia.org/wiki/Pasi%C3%B3n_de_Gavilanes?utm_source=chatgpt.com)*

*[tvdb’s Average Episode Runtime for Café con Aroma de Mujer](https://thetvdb.com/series/cafe-con-aroma-de-mujer-2021#general)*

*[IMDB’s Average Episode Runtime for Yo Soy Betty, La Fea](https://www.imdb.com/title/tt0233127/?utm_source=chatgpt.com)*
