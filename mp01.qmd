---
title: "STA 9750 Mini-Project #01: Netflix Analysis"
author: "Eduardo Alarcon"
format: 
  html:
    code-fold: true
    code-summary: "Show code"
execute:
  message: false
  warning: false
---

```{r setup}
library(dplyr)
library(lubridate)
library(readr)
library(scales)
library(tidyverse)
library(knitr)
library(ggplot2)
library(tibble)
library(htmltools)
```

```{r}
#| include: false 

if(!dir.exists(file.path("data", "mp01"))){ dir.create(file.path("data", "mp01"), showWarnings=FALSE, recursive=TRUE) }
GLOBAL_TOP_10_FILENAME <- file.path("data", "mp01", "global_top10_alltime.csv")
if(!file.exists(GLOBAL_TOP_10_FILENAME)){ download.file("https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv", destfile=GLOBAL_TOP_10_FILENAME) }
COUNTRY_TOP_10_FILENAME <- file.path("data", "mp01", "country_top10_alltime.csv")
if(!file.exists(COUNTRY_TOP_10_FILENAME)){ download.file("https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv", destfile=COUNTRY_TOP_10_FILENAME) }

if(!require("tidyverse")) install.packages("tidyverse")

GLOBAL_TOP_10 <- read_tsv(GLOBAL_TOP_10_FILENAME)
str(GLOBAL_TOP_10)
glimpse(GLOBAL_TOP_10)

GLOBAL_TOP_10 <- GLOBAL_TOP_10 %>%
  mutate(season_title = if_else(season_title == "N/A", NA, season_title))
glimpse(GLOBAL_TOP_10)

COUNTRY_TOP_10 <- read_tsv(COUNTRY_TOP_10_FILENAME, na = "N/A")
glimpse(COUNTRY_TOP_10)
str(COUNTRY_TOP_10)

n_distinct(COUNTRY_TOP_10$country_name)

GLOBAL_TOP_10 %>%
filter(category == "Films (Non-English)") %>%
group_by(show_title) %>%
summarise(max_cumulweeks = max(cumulative_weeks_in_top_10, na.rm = TRUE)) %>%
arrange(desc(max_cumulweeks)) %>%
slice(1)

library(stringr)
library(DT)

format_titles <- function(df){
    colnames(df) <- str_replace_all(colnames(df), "_", " ") |> str_to_title()
    df
}

GLOBAL_TOP_10 |> 
head(n=20) |>
datatable(options=list(searching=FALSE, info=FALSE))

GLOBAL_TOP_10 |> 
format_titles() |>
head(n=20) |>
datatable(options=list(searching=FALSE, info=FALSE)) |>
formatRound(c('Weekly Hours Viewed', 'Weekly Views'))

```

## Task 4

The following questions address Task 4. Please click on the "Show Code" for an detailed approach on how I obtained my results.

<br>

1. How many different countries does Netflix operate in? (You can use the viewing history as a proxy for countries in which Netflix operates.)

```{r}
#| output: false
n_distinct(COUNTRY_TOP_10$country_name)
``` 
**Answer:** Netflix operates in ```r n_distinct(COUNTRY_TOP_10$country_name)``` different countries based on the viewing history data.

<br>

2. Which non-English-language film has spent the most cumulative weeks in the global top 10? How many weeks did it spend?

```{r}
Q2_RESULT <- GLOBAL_TOP_10 %>%
filter(category == "Films (Non-English)") %>%
group_by(show_title) %>%
summarise(`Maximum Cumulative Weeks` = max(cumulative_weeks_in_top_10, na.rm = TRUE)) %>%
arrange(desc(`Maximum Cumulative Weeks`)) %>%
slice(1)

film_name_2 <- Q2_RESULT$show_title
weeks_count_2 <- Q2_RESULT[[2]]

Q2_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The non-English-language film `r film_name_2` spent the most cumulative weeks in the Global Top 10, with `r weeks_count_2` weeks.

<br>

3.	What is the longest film (English or non-English) to have ever appeared in the Netflix global Top 10? How long is it in minutes?
```{r}
Q3_RESULT <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "Films (English)")) %>%
  filter(!is.na(runtime)) %>%   
  group_by(show_title) %>%
  summarise(max_runtime = max(runtime)) %>%   
  arrange(desc(max_runtime)) %>%
  slice(1) %>%
  mutate(max_runtime_minutes = round(60 * max_runtime))

film_name_3 <- Q3_RESULT$show_title
run_time_3 <- Q3_RESULT[[3]]

Q3_RESULT %>%
select(-max_runtime) %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The longest English or non-English film to have ever topped in the Netflix Global Top 10 is `r film_name_3`, with a length of `r run_time_3` minutes.

<br>

4. For each of the four categories, what program has the most total hours of global viewership?

```{r}
Q4_RESULT <- GLOBAL_TOP_10 %>%
group_by(category, show_title) %>%
summarise(total_hours_global_viewership = sum(weekly_hours_viewed, na.rm = TRUE), .groups = "drop") %>%
group_by(category) %>%
slice_max(total_hours_global_viewership, n = 1) %>%
arrange(desc(total_hours_global_viewership)) %>%
mutate(total_hours_global_viewership = comma(total_hours_global_viewership))

Q4_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** The above table highlights calculations that sum all seasons together (i.e.,franchise-level data). In other words, Stranger Things and Squid Game reflect the combined global viewership across all of their respective seasons.

<br>

5.	Which TV show had the longest run in a countryâ€™s Top 10? How long was this run and in what country did it occur?

```{r}

Q5_RESULT <- COUNTRY_TOP_10 %>%
filter(category == "TV") %>%
filter(!is.na(season_title)) %>%
group_by(country_name, show_title) %>%
summarise(max_cumulative_weeks = max(cumulative_weeks_in_top_10), .groups = "drop") %>%
arrange(desc(max_cumulative_weeks)) %>%
slice(1)

Q5_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Money Heist had the longest run in Pakistan, with 127 weeks in Netflix's Country Top 10 list. 

<br>

6. Netflix provides over 200 weeks of service history for all but one country in our data set. Which country is this and when did Netflix cease operations in that country?

```{r}

Q6_RESULT <- COUNTRY_TOP_10 %>%
group_by(country_name) %>%
summarise(total_weeks_of_data = n_distinct(week),final_week = max(week, na.rm = TRUE)) %>%
filter(total_weeks_of_data < 200) %>%
arrange(total_weeks_of_data)

Q6_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** Netflix could not provide over 200 weeks of service for Russia, as it ceased operations during the week of February 27, 2022, resulting in 35 weeks of data in the Country Top 10 list.

<br>

7. What is the total viewership of the TV show Squid Game? Note that there are three seasons total and we are looking for the total number of hours watched across all seasons.

```{r}
Q7_RESULT_SEASONS <- GLOBAL_TOP_10 %>%
filter(show_title == "Squid Game") %>%
filter(!is.na(season_title)) %>%
group_by(season_title) %>%
summarise(sum_hours = sum(weekly_hours_viewed, na.rm = TRUE)) %>%
mutate(hours_watched = comma(sum_hours))

Q7_RESULT_SEASONS_SUM <- Q7_RESULT_SEASONS %>%
summarise(
season_title = "Total Hours Watched Across All Seasons",
sum_hours_1 = sum(sum_hours),
hours_watched = comma(sum_hours_1))

Q7_RESULT_FINAL <- bind_rows(Q7_RESULT_SEASONS, Q7_RESULT_SEASONS_SUM) %>%
select(season_title, hours_watched)

Q7_RESULT_FINAL %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Across all three seasons, Squid Game had a total of 5,048,300,000 hours of global viewership. 

<br>

8. The movie Red Notice has a runtime of 1 hour and 58 minutes. Approximately how many views did it receive in 2021?

```{r}

library(dplyr)
library(lubridate)
library(scales)
library(DT)
library(tibble)

Q8_ROWS <- GLOBAL_TOP_10 %>%
  mutate(week = as.Date(week)) %>%
  filter(show_title == "Red Notice", year(week) == 2021)

if (nrow(Q8_ROWS) == 0) {
  Q8_RESULT <- tibble(
    `Total Hours Viewed (2021)` = "N/A",
    `Approximate Views` = "N/A"
  )
} else {
Q8_RESULT <- Q8_ROWS %>%
summarise(
total_hours_2021 = sum(weekly_hours_viewed, na.rm = TRUE),
runtime_hours = 1 + 58/60,  # 1h 58m
approximate_views = total_hours_2021 / runtime_hours) %>%
mutate(`Total Hours Viewed (2021)` = comma(total_hours_2021), `Approximate Views` = comma(round(approximate_views))) %>%
select(`Total Hours Viewed (2021)`, `Approximate Views`)
}

Q8_RESULT %>%
datatable(options = list( searching = FALSE, info = FALSE, paging = FALSE,
columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** Based on the total number of hours viewed in 2021, Red Notice has approximately, 201,732,203 global views.

<br>

9. Part A: How many Films reached Number 1 in the US but did not originally debut there? 


```{r}

COUNTRY_TOP_10_US_ONLY <- COUNTRY_TOP_10 %>%
  filter(country_iso2 == "US", category == "Films") %>%
  mutate(week = as.Date(week))

US_FILMS_REACH1 <- COUNTRY_TOP_10_US_ONLY %>%
  group_by(show_title) %>%
  summarise(best_rank = min(weekly_rank, na.rm = TRUE), .groups = "drop") %>%
  filter(best_rank == 1)

US_DEBUT <- COUNTRY_TOP_10_US_ONLY %>%
  group_by(show_title) %>%
  arrange(week, .by_group = TRUE) %>%    
  slice(1L) %>%                         
  ungroup() %>%
  transmute(show_title, debut_week = week, debut_rank = weekly_rank)

Q9_RESULT_PT1 <- US_FILMS_REACH1 %>%
  inner_join(US_DEBUT, by = "show_title") %>%
  filter(debut_rank > 1) %>%
  summarise(number_of_films = n())

```

<br>

**Answer:** A total of ```r Q9_RESULT_PT1``` films in the US reached to Number 1 after debuting at a lower ranking. 

<br>

9. Part B: What is the most recent film to pull this off?

```{r}

Q9_RESULT_PT2 <- COUNTRY_TOP_10 %>%
filter(country_iso2 == "US", category == "Films") %>%
mutate(week = as.Date(week)) %>%
group_by(show_title) %>%
summarise(
debut_week = min(week),
debut_rank = weekly_rank[which.min(week)],
best_rank  = min(weekly_rank, na.rm = TRUE),
.groups = "drop") %>%
filter(best_rank == 1, debut_rank > 1) %>%
inner_join(COUNTRY_TOP_10 %>%
filter(country_iso2 == "US", category == "Films") %>%
mutate(week = as.Date(week)) %>%
select(show_title, week, weekly_rank), by = "show_title") %>%
filter(weekly_rank == 1) %>%
slice_max(order_by = week, n = 1, with_ties = FALSE) %>%
transmute(`Most Recent Film` = show_title, `Date Reached #1` = week)


Q9_RESULT_PT2 %>%
datatable(
  options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The most recent film to accomplish this was KPop Demon Hunters, which reached Number 1 during the week of September 14, 2025. 

<br>

10. Which TV show/season hit the top 10 in the most countries in its debut week? In how many countries did it chart?

```{r}

COUNTRY_TOP_10_DEBUT <- COUNTRY_TOP_10 %>%
filter(category == "TV") %>%
group_by(show_title, season_title, country_name) %>%
summarise(
debut_week = min(week, na.rm = TRUE),
debut_rank = weekly_rank[which.min(week)][1],
.groups = "drop"
) %>%
arrange(debut_week)

Q10_RESULT <- COUNTRY_TOP_10_DEBUT %>% 
group_by(show_title, season_title, debut_week) %>% 
summarise(country_appearance = n_distinct(country_name), .groups = "drop") %>% 
arrange(desc(country_appearance)) %>% 
slice(1) %>%
rename(`Show Title` = show_title, `Season Title` = season_title, `Debut Week` = debut_week, `Number of Countries Charted` = country_appearance)

Q10_RESULT %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Emily in Paris (Season 2) charted in 94 countries during its debut week in December 26, 2021. 

<br>

## Task 5: 
## Press Release 1: The Perks of Being a Stranger

Netflix's foray into original programming is yielding massive dividends, as unafraid viewers willingly spend their time (and money) alongside billions of "Strangers" year after year. For Netflix, this translates into viewership that has surpassed the billion mark. The Stranger Things series has garnered 2.5 billion viewers since its premiere in 2016. During its fourth season, it stayed a remarkable 19 weeks in Netflix's Global Top 10 list, spending seven of those weeks resting comfortably at number one. Moreover, the series averaged about 13 weeks in the global top 10 across 93 countries, while Pakistan and Ukraine led the charge at 24 total weeks in the Global top 10.

Compared to other original Netflix titles, Stranger Things dominates in total global hours viewed at nearly 3 billion hours. One contender, Wednesday, has a solid stronghold in approximate viewership at close to 3.8 billion; however, Stranger Things still reigns supreme in total hours viewed, leaving other rivals, such as The Witcher, The Sandman, Locke & Key, and Shadow and Bone, with dust in their viewers' eyes.

With the upcoming release of its fifth and final season, Stranger Things is on a trajectory to continue shattering global records for Netflix. As a solid revenue machine, it is unlikely this season will mark the end of the series. As consummate content consumers, it's highly probable that Netflix will continue to feed the insatiable appetite of its subscribers. If time has taught us anything, we should not be surprised to expect Netflix to conjure spinoffs, prequels, and movie adaptations of this series, as the last thing it would want, is for its subscribers to become strangers to the platform.

<br>

```{r}

# =========================
# Helper(s)
# =========================
# Robust season-number extraction:
# - pulls any number from season_title
# - defaults to 1 if none
# - clamps to 1..4
extract_season_num <- function(x) {
  n <- parse_number(coalesce(x, ""))
  n <- ifelse(is.na(n), 1L, as.integer(n))
  pmin(pmax(n, 1L), 4L)
}

# Average episode minutes by season (edit if needed)
episode_minutes <- tibble(
  season_num = 1:4,
  `*Average Episode Minutes` = c(47, 60, 60, 87)
)

# =========================
# Normalize seasons
# =========================
COUNTRY_ST <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  mutate(
    season_num   = extract_season_num(season_title),
    season_label = paste0("Stranger Things: S", season_num)
  )

GLOBAL_ST <- GLOBAL_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  mutate(
    season_num   = extract_season_num(season_title),
    season_label = paste0("Stranger Things: S", season_num)
  )

# =========================
# Season-level metrics
# =========================
# From COUNTRY: Countries Reached, Country-Weeks
ST_COUNTRIES_BY_SEASON <- COUNTRY_ST %>%
  group_by(season_num, season_label, country_name) %>%
  summarise(weeks_in_top10 = n_distinct(week), .groups = "drop_last") %>%
  summarise(
    `Countries Reached`       = n_distinct(country_name),
    `Country-Weeks in Top 10` = sum(weeks_in_top10, na.rm = TRUE),
    .groups = "drop"
  )

# From GLOBAL: Global Weeks, Total Global Hours
ST_GLOBAL_BY_SEASON <- GLOBAL_ST %>%
  group_by(season_num, season_label) %>%
  summarise(
    `Global Weeks in Top 10` = n_distinct(week),
    `Total Global Hours`     = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  )

# From GLOBAL: Global Weeks at #1
ST_GLOBAL_NUM1 <- GLOBAL_ST %>%
  filter(weekly_rank == 1) %>%
  group_by(season_num, season_label) %>%
  summarise(`Global Weeks at #1` = n_distinct(week), .groups = "drop")

# =========================
# Combine + compute approx. viewership
# =========================
ST_IMPACT_COMBINED <- ST_GLOBAL_BY_SEASON %>%
  left_join(ST_COUNTRIES_BY_SEASON, by = c("season_num", "season_label")) %>%
  left_join(ST_GLOBAL_NUM1,        by = c("season_num", "season_label")) %>%
  left_join(episode_minutes,       by = "season_num") %>%
  mutate(
    approx_views = `Total Global Hours` / (`*Average Episode Minutes` / 60),
    season_label = factor(season_label, levels = paste0("Stranger Things: S", 1:4))
  ) %>%
  arrange(season_num) %>%
  transmute(
    Season = season_label,
    `Total Global Hours Viewed` = `Total Global Hours`,
    `Approx. Viewership`        = approx_views,
    `*Average Episode Minutes`  = `*Average Episode Minutes`,
    `Global Weeks in Top 10`,
    `Global Weeks at #1`,
    `Countries Reached`,
    `Country-Weeks in Top 10`
  )

# =========================
# Totals row (sum weeks, incl. #1), max for Countries Reached
# =========================
totals_row <- ST_IMPACT_COMBINED %>%
  summarise(
    Season                      = "Totals",
    `Total Global Hours Viewed` = sum(`Total Global Hours Viewed`, na.rm = TRUE),
    `Approx. Viewership`        = sum(`Approx. Viewership`, na.rm = TRUE),
    `*Average Episode Minutes`  = NA_real_,
    `Global Weeks in Top 10`    = sum(`Global Weeks in Top 10`, na.rm = TRUE),
    `Global Weeks at #1`        = sum(`Global Weeks at #1`, na.rm = TRUE),
    `Countries Reached`         = max(`Countries Reached`, na.rm = TRUE),
    `Country-Weeks in Top 10`   = sum(`Country-Weeks in Top 10`, na.rm = TRUE)
  )

ST_IMPACT_FINAL <- bind_rows(ST_IMPACT_COMBINED, totals_row) %>%
  mutate(
    across(
      c(`*Average Episode Minutes`,
        `Global Weeks in Top 10`,
        `Global Weeks at #1`,
        `Countries Reached`,
        `Country-Weeks in Top 10`),
      ~ replace_na(., 0)
    ),
    `Total Global Hours Viewed` = comma(`Total Global Hours Viewed`),
    `Approx. Viewership`        = comma(round(`Approx. Viewership`)),
    `Global Weeks in Top 10`    = comma(`Global Weeks in Top 10`),
    `Global Weeks at #1`        = comma(`Global Weeks at #1`),
    `Countries Reached`         = comma(`Countries Reached`),
    `Country-Weeks in Top 10`   = comma(`Country-Weeks in Top 10`)
  )

# =========================
# Display
# =========================
datatable(
  ST_IMPACT_FINAL,
  caption = "Stranger Things â€” Combined Global Impact by Season (Scale â€¢ Longevity â€¢ Multinational Reach â€¢ #1 Weeks)",
  options = list(
    searching = FALSE, paging = FALSE, info = FALSE,
    columnDefs = list(list(className = 'dt-left', targets = "_all"))
  ),
  rownames = FALSE
)

```

<br>

*Average minutes derived from the following sources:

*[Wikipedia's List of Stranger Things Episodes](https://en.wikipedia.org/wiki/List_of_Stranger_Things_episodes)*

*[Netflix's Official Tudum Blog](https://www.netflix.com/tudum/articles/stranger-things-season-4-episode-length)*

<br>

```{r}

# 1) Summary for bottom caption
summary_artifact <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  group_by(country_name) %>%
  summarise(total_weeks_in_top_10 = n_distinct(week), .groups = "drop") %>%
  summarise(
    total_countries = n(),
    avg_weeks = round(mean(total_weeks_in_top_10), 1),
    .groups = "drop"
  )

# 2) Leaderboard (Top 20 available; Top 5 shown by default)
ST_TOP_COUNTRIES_WEEKS <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  group_by(country_name) %>%
  summarise(`Weeks in Top 10` = n_distinct(week), .groups = "drop") %>%
  arrange(desc(`Weeks in Top 10`)) %>%
  slice_head(n = 20) %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Country = country_name, `Weeks in Top 10`)

top3 <- ST_TOP_COUNTRIES_WEEKS$Country[ST_TOP_COUNTRIES_WEEKS$Rank <= 3]

# 3) Bottom caption (footnote-style)
cap_bottom <- htmltools::tags$caption(
  style = "caption-side: bottom; text-align:center; color:#666; font-size:0.9em; padding-top:6px;",
  htmltools::HTML(sprintf(
    "Global reach: <b>%s</b> countries &nbsp;&middot;&nbsp; Avg per-country Top-10 weeks: <b>%s</b>",
    summary_artifact$total_countries, summary_artifact$avg_weeks
  ))
)

# 4) Render table (no in-cell bar; bold Top 3)
DT::datatable(
  ST_TOP_COUNTRIES_WEEKS,
  caption   = cap_bottom,
  escape    = FALSE,
  rownames  = FALSE,
  options   = list(
    pageLength = 5,
    lengthMenu = list(c(5,10,15,20), c('Top 5','Top 10','Top 15','Top 20')),
    searching  = TRUE,
    info       = FALSE,
    order      = list(list(0, 'asc')),
    columnDefs = list(list(className = 'dt-left', targets = "_all"))
  )
) %>%
  DT::formatStyle(
    'Country',
    fontWeight = DT::styleEqual(top3, rep('bold', length(top3)))
  )

```

<br>

```{r}

# 1) Average episode runtimes (minutes)
#    Sources you provided:
#    - Stranger Things: 63.5 (avg of 47, 60, 60, 87 from your table screenshot)
#    - Wednesday: 45 (Addams Family Fandom)
#    - The Witcher: 60 (epguides)
#    - The Sandman: 51 (TVMaze)
#    - Locke & Key: 50 (Fandom range ~40â€“56 â†’ midpoint 50)
#    - Shadow and Bone: 60 (epguides)
# ---------------------------
RUNTIME_REF <- tribble(
  ~show_title,        ~avg_episode_minutes,
  "Stranger Things",  63.5,
  "Wednesday",        45,
  "The Witcher",      60,
  "The Sandman",      51,
  "Locke & Key",      50,
  "Shadow and Bone",  60
)

# Keep only these six shows (English-language Netflix Originals)
TARGET_SHOWS <- RUNTIME_REF$show_title

# ---------------------------
# 2) Summarize global performance across ALL seasons
# ---------------------------
SHOW_SUMMARY <- GLOBAL_TOP_10 %>%
  filter(
    category == "TV (English)",
    show_title %in% TARGET_SHOWS
  ) %>%
  mutate(
    # prevent blanks from inflating season counts
    season_title = na_if(season_title, "")
  ) %>%
  group_by(show_title) %>%
  summarise(
    `Number of Seasons`  = n_distinct(season_title, na.rm = TRUE),
    `Total Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # join average runtimes (minutes)
  left_join(RUNTIME_REF, by = "show_title") %>%
  # runtime-adjusted approximate viewership
  mutate(
    `Approximate Viewership` = round(`Total Hours Viewed` / (avg_episode_minutes / 60))
  ) %>%
  # pretty formatting for large numbers
  mutate(
    `Total Hours Viewed`     = comma(`Total Hours Viewed`),
    `Approximate Viewership` = comma(`Approximate Viewership`)
  ) %>%
  # final columns / headers
  select(
    `Show Title` = show_title,
    `Number of Seasons`,
    `Total Hours Viewed`,
    `*Average Episode Minutes` = avg_episode_minutes,
    `Approximate Viewership`
  ) %>%
  # sort by (numeric) total hours
  arrange(desc(parse_number(`Total Hours Viewed`)))

# ---------------------------
# 3) Display
# ---------------------------
datatable(
  SHOW_SUMMARY,
  caption = "Global Performance of Selected English Netflix Originals (Sci-Fi/Fantasy/Supernatural, All Seasons)",
  options = list(
    pageLength = 10,
    searching = FALSE,
    paging = FALSE,
    info = FALSE,
    columnDefs = list(list(className = 'dt-left', targets = "_all")) # <-- left justify all text
  ),
  rownames = FALSE
) %>%
  formatRound("*Average Episode Minutes", digits = 1)

```

*Note, Stranger Things average runtime caculated from the values presented in an earlier table.

The following links contain sources justifying these average per episode runtimes.

*[Wednesday Average Runtime](https://addamsfamily.fandom.com/wiki/Wednesday_(series))*

*[The Witcher Average Runtime](https://epguides.com/Witcher/)*

*[The Sandman](https://www.tvmaze.com/shows/42827/the-sandman)*

*[Locke & Key Average Runtime](https://lockekey.fandom.com/wiki/Season_One)*

*[Shadow and Bone](https://epguides.com/ShadowandBone/)*

<br>

## Task 6:
## Press Release 2: Commercial Success in India

<br>

```{r}

INDIA_SHOWS_LIST <- COUNTRY_TOP_10 %>%
filter(country_name == "India") %>%
distinct(show_title, season_title, category) %>%
mutate(content_type = case_when(
str_detect(category, "Films") ~ "Films",
str_detect(category, "TV") ~ "TV Shows",TRUE ~ "Other")) %>%
arrange(content_type, show_title, season_title)

INDIA_TOTAL_PROGRAMS <- INDIA_SHOWS_LIST %>%
count(content_type, name = "distinct_shows") %>%
mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

INDIA_TOTAL_PROGRAMS %>%
rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

total_shows <- sum(INDIA_TOTAL_PROGRAMS$distinct_shows)
cat("Total distinct viewing options in India:", total_shows)
```

<br>

```{r}

india_exclusive_from_us <- COUNTRY_TOP_10 %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE)

india_only_list <- COUNTRY_TOP_10 %>%
  filter(country_name == "India") %>%
  semi_join(india_exclusive_from_us, by = c("show_title", "season_title")) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil")) %>%
  distinct(show_title, season_title, category) %>%
  mutate(content_type = case_when(
    str_detect(category, "Films") ~ "Films",
    str_detect(category, "TV") ~ "TV Shows",
    TRUE ~ "Other"
  )) %>%
  arrange(content_type, show_title, season_title)

india_only_breakdown <- india_only_list %>%
  count(content_type, name = "distinct_shows") %>%
  mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

india_only_breakdown %>%
  rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

total_india_only <- sum(india_only_breakdown$distinct_shows)
cat("Total distinct viewing options in India that do NOT 
  appear in US (excluding Telugu/Tamil language viewing options):", total_india_only)

```

<br>

```{r}

india_exclusive_combinations <- COUNTRY_TOP_10 %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil"))

global_appearing_breakdown <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  distinct(show_title, season_title, category) %>%
  mutate(content_type = case_when(
    str_detect(category, "Films") ~ "Films",
    str_detect(category, "TV") ~ "TV Shows",
    TRUE ~ "Other"
  )) %>%
  count(content_type, name = "distinct_shows") %>%
  mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

films_metrics <- GLOBAL_TOP_10 %>%
  filter(category == "Films (Non-English)") %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))

tv_metrics <- GLOBAL_TOP_10 %>%
  filter(category == "TV (Non-English)") %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))

shows_in_global_count <- sum(global_appearing_breakdown$distinct_shows)
total_combinations <- nrow(india_exclusive_combinations)
global_penetration <- round((shows_in_global_count / total_combinations) * 100, 1)

INDIA_EXCLUSIVE_SUMMARY <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    avg_weeks_in_top_10 = mean(cumulative_weeks_in_top_10, na.rm = TRUE),
    max_weeks_in_top_10 = max(cumulative_weeks_in_top_10, na.rm = TRUE)
  ) %>%
  mutate(
    total_hours_formatted = comma(total_hours_viewed),
    avg_weeks_formatted = round(avg_weeks_in_top_10, 1)
  )

GLOBAL_REACH_SUMMARY <- data.frame(
  Metric = c("Total Show+Season Combinations", 
             "Total Hours Viewed - Non-English Films", 
             "Total Hours Viewed - Non-English TV",
             "Combined Hours Viewed (Non-English)", 
             "Average Weeks in Global Top 10", "Maximum Weeks in Global Top 10", 
             "Non-English Combinations in Global Charts", "Non-English Global Chart Penetration Rate"),
  Value = c(
    total_combinations,
    comma(films_metrics$total_hours), 
    comma(tv_metrics$total_hours),
    INDIA_EXCLUSIVE_SUMMARY$total_hours_formatted,
    paste0(INDIA_EXCLUSIVE_SUMMARY$avg_weeks_formatted, " weeks"),
    paste0(INDIA_EXCLUSIVE_SUMMARY$max_weeks_in_top_10, " weeks"),
    paste0(shows_in_global_count, " of ", total_combinations, " combinations"),
    paste0(global_penetration, "%")
  )
)

cat("India-exclusive NON-ENGLISH, (proxy for Hindi; excludes Telugu/Tamil) that achieved global top 10 status:\n")
global_appearing_breakdown %>%
  rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

cat("Total NON-ENGLISH (proxy for Hindi; excludes Telugu/Tamil) appearing in global charts:", shows_in_global_count, "of", total_combinations, "\n\n")

GLOBAL_REACH_SUMMARY %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE))
```


<br>


```{r}

india_exclusive_combinations <- COUNTRY_TOP_10 %>%
  mutate(season_title = coalesce(season_title, "")) %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil"))

INDIA_EXCLUSIVE_METRICS <- GLOBAL_TOP_10 %>%
  mutate(season_title = coalesce(season_title, "")) %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%  
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  group_by(show_title, season_title, category) %>%
  summarise(
    total_weekly_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    avg_runtime_minutes = round(mean(runtime, na.rm = TRUE) * 60, 0),
    total_weekly_views = sum(weekly_views, na.rm = TRUE),
    max_cumulative_weeks_in_top_10 = max(cumulative_weeks_in_top_10, na.rm = TRUE),
    weeks_appeared = n_distinct(week),
    .groups = "drop"
  ) %>%
  mutate(
    content_type = case_when(
      str_detect(category, "Films") ~ "Films",
      str_detect(category, "TV") ~ "TV Shows",
      TRUE ~ "Other"
    ),
    total_hours_formatted = comma(total_weekly_hours_viewed),
    total_views_formatted = comma(total_weekly_views)
  ) %>%
  arrange(desc(total_weekly_hours_viewed)) %>%
  select(show_title, season_title, content_type, total_hours_formatted, avg_runtime_minutes, 
         total_views_formatted, max_cumulative_weeks_in_top_10, weeks_appeared)

INDIA_EXCLUSIVE_METRICS %>%
  format_titles() %>%
  datatable(options = list(searching = TRUE, info = TRUE, paging = TRUE, pageLength = 5, columnDefs = list(list(className = 'dt-left', targets = "_all"))))


```

<br>

```{r}

india_exclusive_combinations <- COUNTRY_TOP_10 %>%
  mutate(season_title = coalesce(season_title, "")) %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us    = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india & !appears_in_us) %>%
  filter(!str_detect(show_title, regex("telugu|tamil", ignore_case = TRUE)))

yearly_hours <- GLOBAL_TOP_10 %>%
  mutate(season_title = coalesce(season_title, ""),
         week = as.Date(week)) %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title","season_title")) %>%
  mutate(week = as.Date(week)) %>%
  mutate(
    year_period = case_when(
      week >= as.Date("2021-07-04") & week < as.Date("2022-07-04") ~ "2021-2022",
      week >= as.Date("2022-07-04") & week < as.Date("2023-07-04") ~ "2022-2023", 
      week >= as.Date("2023-07-04") & week < as.Date("2024-07-04") ~ "2023-2024",
      week >= as.Date("2024-07-04") & week < as.Date("2025-07-04") ~ "2024-2025",
      TRUE ~ "Outside Period"
    )
  ) %>%
  filter(year_period != "Outside Period") %>%
  group_by(year_period) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(year_period) %>%
  mutate(
    total_hours_formatted = comma(total_hours_viewed),
    yoy_change = ifelse(row_number() == 1, NA, 
                       round(((total_hours_viewed - lag(total_hours_viewed)) / lag(total_hours_viewed)) * 100, 1)),
    yoy_change_formatted = ifelse(is.na(yoy_change), "N/A", 
                                 paste0(ifelse(yoy_change > 0, "+", ""), yoy_change, "%"))
  )

yearly_hours <- yearly_hours %>%
  mutate(year_period = factor(year_period,
    levels = c("2021-2022","2022-2023","2023-2024","2024-2025")))

YEARLY_ANALYSIS <- yearly_hours %>%
  select(year_period, total_hours_formatted, yoy_change_formatted) %>%
  rename(
    `Year Period` = year_period,
    `Total Hours Viewed` = total_hours_formatted,
    `Year-over-Year Change` = yoy_change_formatted
  )

cat("India-exclusive NON-ENGLISH (proxy for Hindi; excludes Telugu/Tamil) Content - Yearly Viewing Hours Analysis:\n")
YEARLY_ANALYSIS %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

ggplot(yearly_hours, aes(x = year_period, y = total_hours_viewed, group = 1)) +
  geom_line(color = "steelblue", size = 1.2) +
  geom_point(color = "darkred", size = 3) +
 labs(
    title = "Yearly Viewing Hours for India-Exclusive Non-English Content",
    x = "Year Period",
    y = "Total Hours Viewed", 
    caption = "Source: Netflix Top 10 data (all weeks)"
  ) +
  scale_y_continuous(labels = comma)

first_year <- yearly_hours$total_hours_viewed[1]
last_year  <- yearly_hours$total_hours_viewed[nrow(yearly_hours)]

total_growth <- if (first_year > 0) {
  round(((last_year - first_year) / first_year) * 100, 1)
} else { NA_real_ }

avg_annual_growth <- round(mean(yearly_hours$yoy_change, na.rm = TRUE), 1)

cat("\nGrowth Summary:\n")
cat("Total Growth (2021-2022 to 2024-2025):", total_growth, "%\n")
cat("Average Annual Growth Rate:", avg_annual_growth, "%")

```

<br>

```{r}

# Define South Asian countries (excluding Nepal)
south_asian_countries <- c("India", "Pakistan", "Bangladesh", "Sri Lanka")

# Calculate unique programs by year for each country
yearly_unique_programs <- COUNTRY_TOP_10 %>%
  filter(country_name %in% south_asian_countries) %>%
  mutate(
    year_period = case_when(
      week >= as.Date("2021-07-04") & week < as.Date("2022-07-04") ~ "2021-2022",
      week >= as.Date("2022-07-04") & week < as.Date("2023-07-04") ~ "2022-2023", 
      week >= as.Date("2023-07-04") & week < as.Date("2024-07-04") ~ "2023-2024",
      week >= as.Date("2024-07-04") & week <= as.Date("2025-07-05") ~ "2024-2025",
      TRUE ~ "Outside Period"
    )
  ) %>%
  filter(year_period != "Outside Period") %>%
  mutate(unique_program = paste(show_title, ifelse(is.na(season_title), "NA_SEASON", season_title), sep = " || ")) %>%
  group_by(country_name, year_period) %>%
  summarise(unique_programs_count = n_distinct(unique_program), .groups = "drop") %>%
  arrange(country_name, year_period)

# Calculate year-over-year changes
yearly_programs_with_change <- yearly_unique_programs %>%
  arrange(country_name, year_period) %>%
  group_by(country_name) %>%
  mutate(
    yoy_change = ifelse(row_number() == 1, NA, 
                       round(((unique_programs_count - lag(unique_programs_count)) / lag(unique_programs_count)) * 100, 1)),
    yoy_change_formatted = ifelse(is.na(yoy_change), "N/A", 
                                 paste0(ifelse(yoy_change > 0, "+", ""), yoy_change, "%"))
  ) %>%
  ungroup()

# Create separate tables for counts and changes
counts_table <- yearly_programs_with_change %>%
  select(country_name, year_period, unique_programs_count) %>%
  pivot_wider(names_from = country_name, values_from = unique_programs_count, values_fill = 0) %>%
  arrange(year_period)

changes_table <- yearly_programs_with_change %>%
  select(country_name, year_period, yoy_change_formatted) %>%
  pivot_wider(names_from = country_name, values_from = yoy_change_formatted, values_fill = "N/A") %>%
  arrange(year_period)

# Combine tables with alternating count and change columns
SOUTH_ASIA_DETAILED_ANALYSIS <- counts_table %>%
  rename(`Year Period` = year_period) %>%
  left_join(changes_table %>% rename(`Year Period` = year_period), by = "Year Period", suffix = c("_Count", "_Change")) %>%
  select(`Year Period`, 
         India_Count, India_Change,
         Pakistan_Count, Pakistan_Change,
         Bangladesh_Count, Bangladesh_Change,
         `Sri Lanka_Count`, `Sri Lanka_Change`) %>%
  rename(
    `India Count` = India_Count,
    `India YoY Change` = India_Change,
    `Pakistan Count` = Pakistan_Count,
    `Pakistan YoY Change` = Pakistan_Change,
    `Bangladesh Count` = Bangladesh_Count,
    `Bangladesh YoY Change` = Bangladesh_Change,
    `Sri Lanka Count` = `Sri Lanka_Count`,
    `Sri Lanka YoY Change` = `Sri Lanka_Change`
  )

# Display the main analysis
cat("South Asian Countries - Unique Programs with Separate Rate of Change Columns:\n")
SOUTH_ASIA_DETAILED_ANALYSIS %>%
  datatable(options = list(
    searching = FALSE, 
    info = FALSE, 
    paging = FALSE,
    scrollX = TRUE,
    columnDefs = list(
      list(className = 'dt-left', targets = "_all"),
      list(width = '80px', targets = 1:8)
    )
  ))

# Calculate summary statistics (excluding 2021-2022)
summary_stats <- yearly_programs_with_change %>%
  filter(year_period != "2021-2022") %>%  # Exclude baseline year
  filter(!is.na(yoy_change)) %>%
  group_by(country_name) %>%
  summarise(
    avg_yoy_change = round(mean(yoy_change, na.rm = TRUE), 1),
    total_growth = round(sum(yoy_change, na.rm = TRUE), 1),
    max_single_year_growth = round(max(yoy_change, na.rm = TRUE), 1),
    years_with_data = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(avg_yoy_change))

# Display summary chart

# Display summary chart - Average YoY Change Only
cat("\n\nSummary: Average Year-over-Year Change by Country (Excluding 2021-2022 Baseline):\n")
summary_stats <- yearly_programs_with_change %>%
filter(year_period != "2021-2022") %>%  # Exclude baseline year
filter(!is.na(yoy_change)) %>%
group_by(country_name) %>%
summarise(
avg_yoy_change = round(mean(yoy_change, na.rm = TRUE), 1),
.groups = "drop") %>%
arrange(desc(avg_yoy_change))  # Back to descending order

summary_stats %>%
rename(
Country = country_name,
`Average YoY Change` = avg_yoy_change) %>%
datatable(options = list(
searching = FALSE, 
info = FALSE, 
paging = FALSE,
columnDefs = list(list(className = 'dt-center', targets = "_all"))))

# Identify the top performer
top_country <- summary_stats$country_name[1]
top_avg_growth <- summary_stats$avg_yoy_change[1]

cat("\nHighlight: ", top_country, " shows the greatest average year-over-year growth rate at ", top_avg_growth, "% annually.")

```

<br>

## Task 7: Press Release 3 
## Latin America Streams the Chisme: Netflix Keeps Millions Glued to the Screen

<br>

Viewers across Latin America are voting with their eyes. Since 2021, nearly two billion hours of Netflix programming have been streamed in the region, with telenovelas accounting for most of the engagement. Long a staple of Latin American culture, the telenovela, or soap opera, blends love, betrayal, family, and, above all else, the chisme, or gossip, with its power to unite and divide viewing communities.

Netflix has captured this audienceâ€™s attention with classic and rebooted titles such as Yo Soy Betty La Fea and CafÃ© con Aroma de Mujer, which together have contributed more than 1.6 billion viewing hours since arriving on the platform. Notably, Betty premiered in 1999 and CafÃ© dates back to 1994, showing that nostalgia remains powerful in the streaming era, especially in Latin America.

At the same time, Netflix Originals like Elite highlight the companyâ€™s strength in creating sagas that resonate with viewers worldwide. Since its 2018 debut, Elite has reached audiences in 17 Latin American countries, generating over 700 million global viewing hours across its eight seasons. With a regional population of more than 670 million people, the potential for original telenovela content is enormous.

Looking ahead, Netflix could build on this momentum by rebooting a legendary series such as Kassandra. Originally aired in 1992, Kassandra set a Guinness World Record as the most broadcast Spanish-language telenovela, reaching roughly 140 countries and translated into 60 languages. Although Kassandra is currently unavailable on Netflix, a revival could tap into the regionâ€™s demand for nostalgia while attracting new audiences. 

With nearly two billion streaming hours already recorded in Latin America, the demand is undeniable. Netflix can no longer afford to rely on streaming archival content. By reviving iconic shows, Netflix can honor the legacy of telenovelas while fueling future growth in the region. However, it must act quickly before competitors turn the chisme into their own streaming success story.

<br>

```{r}

SPANISH_LATAMER <- c(
  "Argentina","Bolivia","Chile","Colombia","Costa Rica","Dominican Republic",
  "Ecuador","El Salvador","Guatemala","Honduras","Mexico","Nicaragua",
  "Panama","Paraguay","Peru","Uruguay","Venezuela"
)

COUNTRY_TOP_10 <- COUNTRY_TOP_10 %>%
  mutate(
    show_title = coalesce(show_title, "N/A"),
    season_title = coalesce(season_title, "N/A"))

LATAMER_TOP <- COUNTRY_TOP_10 %>%
  filter(country_name %in% SPANISH_LATAMER) %>%
  group_by(country_name, show_title, season_title) %>%
  summarise(max_cumulative = max(cumulative_weeks_in_top_10, na.rm = TRUE), .groups = "drop") %>%
  group_by(country_name) %>%
  slice_max(order_by = max_cumulative, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(country_name) %>%
  rename(
    Country = country_name,
    `Show Title` = show_title,
    `Season Title` = season_title,
    `Cumulative Weeks in Top 10` = max_cumulative
  )

datatable(
LATAMER_TOP,
caption = "Spanish-speaking Latin American Countries: Top Show/Season by Cumulative Weeks in Top 10",
  options = list(pageLength = 20, searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
)

```

<br>

```{r}

TOP_PROGRAMS <- tribble(
  ~show_title,                         ~season_title,                              ~avg_runtime_hrs,
  "CafÃ© con aroma de mujer",           "CafÃ© con aroma de mujer: Season 1",          43/60,  
  "Pablo Escobar, el patrÃ³n del mal",  "Pablo Escobar, el patrÃ³n del mal: Season 1", 45/60, 
  "PasiÃ³n de Gavilanes",               "PasiÃ³n de Gavilanes: Season 1",              44/60,  
  "Yo soy Betty, la fea",              "Yo soy Betty, la fea: Season 1",             30/60   
)

GLOBAL_CLEAN <- GLOBAL_TOP_10 %>%
  mutate(
    show_title   = coalesce(show_title, ""),
    season_title = coalesce(season_title, "")
  )

TOTALS_GLOBAL <- GLOBAL_CLEAN %>%
  inner_join(TOP_PROGRAMS, by = c("show_title", "season_title")) %>%
  group_by(category, show_title, season_title, avg_runtime_hrs) %>%
  summarise(
    `Total Weekly Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    `Approx Global Views` = round(`Total Weekly Hours Viewed` / avg_runtime_hrs)
  ) %>%
  transmute(
    Category        = category,
    `Show Title`    = show_title,
    `Season Title`  = season_title,
    `Total Weekly Hours Viewed`,
    `Avg Runtime (hrs)` = avg_runtime_hrs,
    `Approx Global Views`
  )

tot_row <- tibble(
  Category               = "TOTAL",
  `Show Title`           = "â€”",
  `Season Title`         = "â€”",
  `Total Weekly Hours Viewed` = sum(TOTALS_GLOBAL$`Total Weekly Hours Viewed`, na.rm = TRUE),
  `Avg Runtime (hrs)`    = NA_real_,
  `Approx Global Views`  = sum(TOTALS_GLOBAL$`Approx Global Views`, na.rm = TRUE)
)

final_tbl <- bind_rows(TOTALS_GLOBAL, tot_row)

datatable(
  final_tbl,
  caption = "Global Hours & Runtime-Adjusted Approximate Views (Cross-referenced from TSVs)",
  options = list(pageLength = 10, searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
) %>%
  formatCurrency(
    c("Total Weekly Hours Viewed", "Approx Global Views"),
    currency = "", digits = 0, mark = ","
  ) %>%
  formatRound("Avg Runtime (hrs)", digits = 2)

grand_total_hours <- sum(TOTALS_GLOBAL$`Total Weekly Hours Viewed`, na.rm = TRUE)
grand_total_views <- sum(TOTALS_GLOBAL$`Approx Global Views`, na.rm = TRUE)

cat("Grand Total Weekly Hours Viewed:", comma(grand_total_hours), "\n")
cat("Grand Total Approx Global Views:", comma(grand_total_views), "\n")
```

Hours are global for the listed titles as the country TSV does not contain this information.

<br>

*Note, average runtime values are approximations. The sources below provide details highlighting program runtime across episodes and seasons.

*[Netflixâ€™s Average Episode Runtime for Pablo Escobar: El PatrÃ³n del Mal](https://www.netflix.com/title/80035684?utm_source=chatgpt.com)*

*[Wikipediaâ€™s Average Episode Runtime for PasiÃ³n de Gavilanes](https://en.wikipedia.org/wiki/Pasi%C3%B3n_de_Gavilanes?utm_source=chatgpt.com)*

*[tvdbâ€™s Average Episode Runtime for CafÃ© con Aroma de Mujer](https://thetvdb.com/series/cafe-con-aroma-de-mujer-2021#general)*

*[IMDBâ€™s Average Episode Runtime for Yo Soy Betty, La Fea](https://www.imdb.com/title/tt0233127/?utm_source=chatgpt.com)*

<br>

```{r}

# --- Config: runtime assumption for Elite (TVMaze avg ~50 min) ---
elite_runtime <- 50/60  # hours

# --- Spanish-speaking LATAM (exclude Brazil) ---
latam_spanish <- c(
  "Argentina","Bolivia","Chile","Colombia","Costa Rica","Dominican Republic",
  "Ecuador","El Salvador","Guatemala","Honduras","Mexico","Nicaragua",
  "Panama","Paraguay","Peru","Uruguay","Venezuela"
)

# --- Count distinct LATAM countries where Elite charted (from COUNTRY_TOP_10) ---
elite_latam_country_count <- COUNTRY_TOP_10 %>%
  mutate(show_title = coalesce(show_title, "")) %>%
  filter(show_title == "Elite", country_name %in% latam_spanish) %>%
  summarise(n_countries = n_distinct(country_name), .groups = "drop") %>%
  pull(n_countries) %>%
  { if (length(.) == 0 || is.na(.)) 0 else . }  # safety if no rows

# --- Global totals + runtime-adjusted views (from GLOBAL_TOP_10) ---
elite_total <- GLOBAL_TOP_10 %>%
  mutate(show_title = coalesce(show_title, "")) %>%
  filter(show_title == "Elite") %>%
  summarise(
    `Total Weekly Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    Category                          = "TV (Non-English)",
    `Show Title`                      = "Elite",
    `Season Title`                    = "All Seasons (8)",
    `Avg Runtime (hrs)`               = elite_runtime,
    `Approx Global Views`             = round(`Total Weekly Hours Viewed` / elite_runtime),
    `Number of LATAM Countries Reached` = elite_latam_country_count,
    `Total Weekly Hours Viewed`       = comma(`Total Weekly Hours Viewed`),
    `Approx Global Views`             = comma(`Approx Global Views`)
  ) %>%
  select(
    Category, `Show Title`, `Season Title`,
    `Total Weekly Hours Viewed`, `Avg Runtime (hrs)`, `Approx Global Views`,
    `Number of LATAM Countries Reached`
  )

# --- Render ---
datatable(
  elite_total,
  caption = "Global Hours & Runtime-Adjusted Approximate Views (Cross-referenced from TSVs)",
  options = list(searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
) %>%
  formatRound("Avg Runtime (hrs)", digits = 2)

```

<br>


*[TVMaze's Average Episode Runtime for Elite](https://www.tvmaze.com/shows/37854/elite?utm_source=chatgpt.com)*
