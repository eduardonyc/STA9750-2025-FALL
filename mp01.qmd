---
title: "STA 9750 Mini-Project #01: Netflix Analysis"
author: "Eduardo Alarcon"
format: 
  html:
    code-fold: true
    code-summary: "Show code"
execute:
  message: false
  warning: false
---

```{r setup}
library(dplyr)
library(lubridate)
library(readr)
library(scales)
library(tidyverse)
library(knitr)
library(ggplot2)
library(tibble)
library(htmltools)
library(janitor)
```

<br>

## Tasks 1,2, and 3

Work for these tasks can be found directly in the mp01.qmd document. Feel free to click on the link below to see the necessary code needed to interact with the datasets. ADD LINK!

```{r}

```

<br>

```{r}
#| include: false 

if(!dir.exists(file.path("data", "mp01"))){ dir.create(file.path("data", "mp01"), showWarnings=FALSE, recursive=TRUE) }
GLOBAL_TOP_10_FILENAME <- file.path("data", "mp01", "global_top10_alltime.csv")
if(!file.exists(GLOBAL_TOP_10_FILENAME)){ download.file("https://www.netflix.com/tudum/top10/data/all-weeks-global.tsv", destfile=GLOBAL_TOP_10_FILENAME) }
COUNTRY_TOP_10_FILENAME <- file.path("data", "mp01", "country_top10_alltime.csv")
if(!file.exists(COUNTRY_TOP_10_FILENAME)){ download.file("https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv", destfile=COUNTRY_TOP_10_FILENAME) }

if(!require("tidyverse")) install.packages("tidyverse")

GLOBAL_TOP_10 <- read_tsv(GLOBAL_TOP_10_FILENAME)
str(GLOBAL_TOP_10)
glimpse(GLOBAL_TOP_10)

GLOBAL_TOP_10 <- GLOBAL_TOP_10 %>%
  mutate(season_title = if_else(season_title == "N/A", NA, season_title))
glimpse(GLOBAL_TOP_10)

COUNTRY_TOP_10 <- read_tsv(COUNTRY_TOP_10_FILENAME, na = "N/A")
glimpse(COUNTRY_TOP_10)
str(COUNTRY_TOP_10)

n_distinct(COUNTRY_TOP_10$country_name)

GLOBAL_TOP_10 %>%
filter(category == "Films (Non-English)") %>%
group_by(show_title) %>%
summarise(max_cumulweeks = max(cumulative_weeks_in_top_10, na.rm = TRUE)) %>%
arrange(desc(max_cumulweeks)) %>%
slice(1)

library(stringr)
library(DT)

format_titles <- function(df){
    colnames(df) <- str_replace_all(colnames(df), "_", " ") |> str_to_title()
    df
}

GLOBAL_TOP_10 |> 
head(n=20) |>
datatable(options=list(searching=FALSE, info=FALSE))

GLOBAL_TOP_10 |> 
format_titles() |>
head(n=20) |>
datatable(options=list(searching=FALSE, info=FALSE)) |>
formatRound(c('Weekly Hours Viewed', 'Weekly Views'))

```

## Task 4

The following questions address Task 4. Please click on the "Show Code" for an detailed approach on how I obtained my results.

<br>

1. How many different countries does Netflix operate in? (You can use the viewing history as a proxy for countries in which Netflix operates.)

```{r}
#| output: false
n_distinct(COUNTRY_TOP_10$country_name)
``` 
**Answer:** Netflix operates in ```r n_distinct(COUNTRY_TOP_10$country_name)``` different countries based on the viewing history data.

<br>

2. Which non-English-language film has spent the most cumulative weeks in the global top 10? How many weeks did it spend?

```{r}
Q2_RESULT <- GLOBAL_TOP_10 %>%
filter(category == "Films (Non-English)") %>%
group_by(show_title) %>%
summarise(`Maximum Cumulative Weeks` = max(cumulative_weeks_in_top_10, na.rm = TRUE)) %>%
arrange(desc(`Maximum Cumulative Weeks`)) %>%
slice(1)

film_name_2 <- Q2_RESULT$show_title
weeks_count_2 <- Q2_RESULT[[2]]

Q2_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The non-English-language film `r film_name_2` spent the most cumulative weeks in the Global Top 10, with `r weeks_count_2` weeks.

<br>

3.	What is the longest film (English or non-English) to have ever appeared in the Netflix global Top 10? How long is it in minutes?
```{r}
Q3_RESULT <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "Films (English)")) %>%
  filter(!is.na(runtime)) %>%   
  group_by(show_title) %>%
  summarise(max_runtime = max(runtime)) %>%   
  arrange(desc(max_runtime)) %>%
  slice(1) %>%
  mutate(max_runtime_minutes = round(60 * max_runtime))

film_name_3 <- Q3_RESULT$show_title
run_time_3 <- Q3_RESULT[[3]]

Q3_RESULT %>%
select(-max_runtime) %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The longest English or non-English film to have ever topped in the Netflix Global Top 10 is `r film_name_3`, with a length of `r run_time_3` minutes.

<br>

4. For each of the four categories, what program has the most total hours of global viewership?

```{r}
Q4_RESULT <- GLOBAL_TOP_10 %>%
group_by(category, show_title) %>%
summarise(total_hours_global_viewership = sum(weekly_hours_viewed, na.rm = TRUE), .groups = "drop") %>%
group_by(category) %>%
slice_max(total_hours_global_viewership, n = 1) %>%
arrange(desc(total_hours_global_viewership)) %>%
mutate(total_hours_global_viewership = comma(total_hours_global_viewership))

Q4_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** The above table highlights calculations that sum all seasons together (i.e.,franchise-level data). In other words, Stranger Things and Squid Game reflect the combined global viewership across all of their respective seasons.

<br>

5.	Which TV show had the longest run in a countryâ€™s Top 10? How long was this run and in what country did it occur?

```{r}

Q5_RESULT <- COUNTRY_TOP_10 %>%
filter(category == "TV") %>%
filter(!is.na(season_title)) %>%
group_by(country_name, show_title) %>%
summarise(max_cumulative_weeks = max(cumulative_weeks_in_top_10), .groups = "drop") %>%
arrange(desc(max_cumulative_weeks)) %>%
slice(1)

Q5_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Money Heist had the longest run in Pakistan, with 127 weeks in Netflix's Country Top 10 list. 

<br>

6. Netflix provides over 200 weeks of service history for all but one country in our data set. Which country is this and when did Netflix cease operations in that country?

```{r}

Q6_RESULT <- COUNTRY_TOP_10 %>%
group_by(country_name) %>%
summarise(total_weeks_of_data = n_distinct(week),final_week = max(week, na.rm = TRUE)) %>%
filter(total_weeks_of_data < 200) %>%
arrange(total_weeks_of_data)

Q6_RESULT %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** Netflix could not provide over 200 weeks of service for Russia, as it ceased operations during the week of February 27, 2022, resulting in 35 weeks of data in the Country Top 10 list.

<br>

7. What is the total viewership of the TV show Squid Game? Note that there are three seasons total and we are looking for the total number of hours watched across all seasons.

```{r}
Q7_RESULT_SEASONS <- GLOBAL_TOP_10 %>%
filter(show_title == "Squid Game") %>%
filter(!is.na(season_title)) %>%
group_by(season_title) %>%
summarise(sum_hours = sum(weekly_hours_viewed, na.rm = TRUE)) %>%
mutate(hours_watched = comma(sum_hours))

Q7_RESULT_SEASONS_SUM <- Q7_RESULT_SEASONS %>%
summarise(
season_title = "Total Hours Watched Across All Seasons",
sum_hours_1 = sum(sum_hours),
hours_watched = comma(sum_hours_1))

Q7_RESULT_FINAL <- bind_rows(Q7_RESULT_SEASONS, Q7_RESULT_SEASONS_SUM) %>%
select(season_title, hours_watched)

Q7_RESULT_FINAL %>%
format_titles() %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Across all three seasons, Squid Game had a total of 5,048,300,000 hours of global viewership. 

<br>

8. The movie Red Notice has a runtime of 1 hour and 58 minutes. Approximately how many views did it receive in 2021?

```{r}
Q8_ROWS <- GLOBAL_TOP_10 %>%
  mutate(week = as.Date(week)) %>%
  filter(show_title == "Red Notice", year(week) == 2021)

if (nrow(Q8_ROWS) == 0) {
  Q8_RESULT <- tibble(
    `Total Hours Viewed (2021)` = "N/A",
    `Approximate Views` = "N/A"
  )
} else {
Q8_RESULT <- Q8_ROWS %>%
summarise(
total_hours_2021 = sum(weekly_hours_viewed, na.rm = TRUE),
runtime_hours = 1 + 58/60,  # 1h 58m
approximate_views = total_hours_2021 / runtime_hours) %>%
mutate(`Total Hours Viewed (2021)` = comma(total_hours_2021), `Approximate Views` = comma(round(approximate_views))) %>%
select(`Total Hours Viewed (2021)`, `Approximate Views`)
}

Q8_RESULT %>%
datatable(options = list( searching = FALSE, info = FALSE, paging = FALSE,
columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** Based on the total number of hours viewed in 2021, Red Notice has approximately, 201,732,203 global views.

<br>

9. Part A: How many Films reached Number 1 in the US but did not originally debut there? 


```{r}

COUNTRY_TOP_10_US_ONLY <- COUNTRY_TOP_10 %>%
  filter(country_iso2 == "US", category == "Films") %>%
  mutate(week = as.Date(week))

US_FILMS_REACH1 <- COUNTRY_TOP_10_US_ONLY %>%
  group_by(show_title) %>%
  summarise(best_rank = min(weekly_rank, na.rm = TRUE), .groups = "drop") %>%
  filter(best_rank == 1)

US_DEBUT <- COUNTRY_TOP_10_US_ONLY %>%
  group_by(show_title) %>%
  arrange(week, .by_group = TRUE) %>%    
  slice(1L) %>%                         
  ungroup() %>%
  transmute(show_title, debut_week = week, debut_rank = weekly_rank)

Q9_RESULT_PT1 <- US_FILMS_REACH1 %>%
  inner_join(US_DEBUT, by = "show_title") %>%
  filter(debut_rank > 1) %>%
  summarise(number_of_films = n())

```

<br>

**Answer:** A total of ```r Q9_RESULT_PT1``` films in the US reached to Number 1 after debuting at a lower ranking. 

<br>

9. Part B: What is the most recent film to pull this off?

```{r}

Q9_RESULT_PT2 <- COUNTRY_TOP_10 %>%
filter(country_iso2 == "US", category == "Films") %>%
mutate(week = as.Date(week)) %>%
group_by(show_title) %>%
summarise(
debut_week = min(week),
debut_rank = weekly_rank[which.min(week)],
best_rank  = min(weekly_rank, na.rm = TRUE),
.groups = "drop") %>%
filter(best_rank == 1, debut_rank > 1) %>%
inner_join(COUNTRY_TOP_10 %>%
filter(country_iso2 == "US", category == "Films") %>%
mutate(week = as.Date(week)) %>%
select(show_title, week, weekly_rank), by = "show_title") %>%
filter(weekly_rank == 1) %>%
slice_max(order_by = week, n = 1, with_ties = FALSE) %>%
transmute(`Most Recent Film` = show_title, `Date Reached #1` = week)


Q9_RESULT_PT2 %>%
datatable(
  options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

```

<br>

**Answer:** The most recent film to accomplish this was KPop Demon Hunters, which reached Number 1 during the week of September 14, 2025. 

<br>

10. Which TV show/season hit the top 10 in the most countries in its debut week? In how many countries did it chart?

```{r}

COUNTRY_TOP_10_DEBUT <- COUNTRY_TOP_10 %>%
filter(category == "TV") %>%
group_by(show_title, season_title, country_name) %>%
summarise(
debut_week = min(week, na.rm = TRUE),
debut_rank = weekly_rank[which.min(week)][1],
.groups = "drop"
) %>%
arrange(debut_week)

Q10_RESULT <- COUNTRY_TOP_10_DEBUT %>% 
group_by(show_title, season_title, debut_week) %>% 
summarise(country_appearance = n_distinct(country_name), .groups = "drop") %>% 
arrange(desc(country_appearance)) %>% 
slice(1) %>%
rename(`Show Title` = show_title, `Season Title` = season_title, `Debut Week` = debut_week, `Number of Countries Charted` = country_appearance)

Q10_RESULT %>%
datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))
```

<br>

**Answer:** Emily in Paris (Season 2) charted in 94 countries during its debut week in December 26, 2021. 

<br>

## Task 5: 
## Press Release 1: Nine Years Later: 93 Countries Await Stranger Things' Epic Finale


Netflix will release the fifth and final season of Stranger Things in late November 2025, concluding a global phenomenon that has generated nearly 3 billion viewing hours across 93 countries since its 2016 debut.

Across four seasons, Stranger Things has accumulated 2.97 billion global viewing hours, reaching an estimated 2.49 billion viewers worldwide. The series has spent an average of 13.4 weeks in Netflixâ€™s Country Top 10 charts, with Pakistan and Ukraine leading at 24 weeks each, demonstrating sustained engagement well beyond initial release windows.

Season 4 delivered an unprecedented performance, accounting for 1.89 billion viewing hours, which represents 64% of the series' total. The season maintained a 19-week presence in Netflix's Global Top 10, including seven consecutive weeks at #1, cementing Stranger Things as Netflix's most-watched English-language genre series by total hours viewed.

Among Netflix's English-language sci-fi, fantasy, and supernatural genre originals, Stranger Things leads in cumulative viewing hours. Wednesday (2.84 billion hours across 2 seasons) demonstrates strong per-season averages, while The Witcher (1.12 billion hours, 3 seasons) and The Sandman (571 million hours, 2 seasons) round out the genre's top performers. Stranger Things maintains its position as the platform's premier franchise in the genre by total global hours.

Season 5 is poised to be one of 2025's most anticipated series finales, with a global fan base that has invested nine years in waiting to see how Eleven and the Upside Downâ€™s story concludes. 

<br>

```{r}

# ============================================
# TABLE 1: Season-by-Season Breakdown
# ============================================

# Average episode minutes by season
episode_minutes <- tibble(
  season_num = 1:4,
  avg_minutes = c(47, 60, 60, 87)
)

# Get global metrics by season
ST_GLOBAL <- GLOBAL_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  mutate(season_num = parse_number(coalesce(season_title, "1"))) %>%
  filter(season_num %in% 1:4) %>%
  group_by(season_num) %>%
  summarise(
    `Total Global Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    `Global Weeks in Top 10` = n_distinct(week),
    `Global Weeks at #1` = sum(weekly_rank == 1, na.rm = TRUE),
    .groups = "drop"
  )

# Get country metrics by season
ST_COUNTRY <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  mutate(season_num = parse_number(coalesce(season_title, "1"))) %>%
  filter(season_num %in% 1:4) %>%
  group_by(season_num) %>%
  summarise(
    `Countries Reached` = n_distinct(country_name),
    `Country-Weeks in Top 10` = n(),
    .groups = "drop"
  )

# Combine all metrics
ST_IMPACT <- ST_GLOBAL %>%
  left_join(ST_COUNTRY, by = "season_num") %>%
  left_join(episode_minutes, by = "season_num") %>%
  mutate(
    Season = paste0("Stranger Things: S", season_num),
    `Approx. Viewership` = `Total Global Hours Viewed` / (avg_minutes / 60)
  ) %>%
  select(
    Season,
    `Total Global Hours Viewed`,
    `Approx. Viewership`,
    `*Average Episode Minutes` = avg_minutes,
    `Global Weeks in Top 10`,
    `Global Weeks at #1`,
    `Countries Reached`,
    `Country-Weeks in Top 10`
  )

# Add totals row
totals <- ST_IMPACT %>%
  summarise(
    Season = "Totals",
    `Total Global Hours Viewed` = sum(`Total Global Hours Viewed`),
    `Approx. Viewership` = sum(`Approx. Viewership`),
    `*Average Episode Minutes` = 0,
    `Global Weeks in Top 10` = sum(`Global Weeks in Top 10`),
    `Global Weeks at #1` = sum(`Global Weeks at #1`),
    `Countries Reached` = max(`Countries Reached`),
    `Country-Weeks in Top 10` = sum(`Country-Weeks in Top 10`)
  )

ST_IMPACT_FINAL <- bind_rows(ST_IMPACT, totals) %>%
  mutate(
    `Total Global Hours Viewed` = comma(`Total Global Hours Viewed`),
    `Approx. Viewership` = comma(round(`Approx. Viewership`)),
    `Global Weeks in Top 10` = comma(`Global Weeks in Top 10`),
    `Global Weeks at #1` = comma(`Global Weeks at #1`),
    `Countries Reached` = comma(`Countries Reached`),
    `Country-Weeks in Top 10` = comma(`Country-Weeks in Top 10`)
  )

datatable(
  ST_IMPACT_FINAL,
  caption = "Stranger Things â€” Combined Global Impact by Season (Scale â€¢ Longevity â€¢ Multinational Reach â€¢ #1 Weeks)",
  options = list(
    searching = FALSE, paging = FALSE, info = FALSE,
    columnDefs = list(list(className = 'dt-left', targets = "_all"))
  ),
  rownames = FALSE
)

```

<br>

*Average minutes derived from the following sources:

*[Wikipedia's List of Stranger Things Episodes](https://en.wikipedia.org/wiki/List_of_Stranger_Things_episodes)*

*[Netflix's Official Tudum Blog](https://www.netflix.com/tudum/articles/stranger-things-season-4-episode-length)*

<br>

```{r}

# ============================================
# TABLE 2: Top Countries by Weeks
# ============================================

# Summary stats for caption
summary_artifact <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  group_by(country_name) %>%
  summarise(total_weeks_in_top_10 = n_distinct(week), .groups = "drop") %>%
  summarise(
    total_countries = n(),
    avg_weeks = round(mean(total_weeks_in_top_10), 1)
  )

# Top 20 countries leaderboard
ST_TOP_COUNTRIES_WEEKS <- COUNTRY_TOP_10 %>%
  filter(show_title == "Stranger Things") %>%
  group_by(country_name) %>%
  summarise(`Weeks in Top 10` = n_distinct(week), .groups = "drop") %>%
  arrange(desc(`Weeks in Top 10`)) %>%
  slice_head(n = 20) %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Country = country_name, `Weeks in Top 10`)

top3 <- ST_TOP_COUNTRIES_WEEKS$Country[ST_TOP_COUNTRIES_WEEKS$Rank <= 3]

# Bottom caption
cap_bottom <- htmltools::tags$caption(
  style = "caption-side: bottom; text-align:center; color:#666; font-size:0.9em; padding-top:6px;",
  htmltools::HTML(sprintf(
    "Global reach: <b>%s</b> countries &nbsp;&middot;&nbsp; Avg per-country Top-10 weeks: <b>%s</b>",
    summary_artifact$total_countries, summary_artifact$avg_weeks
  ))
)

# Display table
datatable(
  ST_TOP_COUNTRIES_WEEKS,
  caption = cap_bottom,
  escape = FALSE,
  rownames = FALSE,
  options = list(
    pageLength = 5,
    lengthMenu = list(c(5,10,15,20), c('Top 5','Top 10','Top 15','Top 20')),
    searching = TRUE,
    info = FALSE,
    order = list(list(0, 'asc')),
    columnDefs = list(list(className = 'dt-left', targets = "_all"))
  )
) %>%
  formatStyle('Country', fontWeight = styleEqual(top3, rep('bold', length(top3))))

```
<br>

```{r}

# ============================================
# TABLE 3: Comparison to Other Shows
# ============================================

# Average episode runtimes (minutes)
RUNTIME_REF <- tribble(
  ~show_title,        ~num_seasons, ~avg_episode_minutes,
  "Stranger Things",  4,            63.5,
  "Wednesday",        2,            45,
  "The Witcher",      3,            60,
  "The Sandman",      2,            51,
  "Locke & Key",      3,            50,
  "Shadow and Bone",  2,            60
)

# Summarize global performance
SHOW_SUMMARY <- GLOBAL_TOP_10 %>%
  filter(
    category == "TV (English)",
    show_title %in% RUNTIME_REF$show_title
  ) %>%
  group_by(show_title) %>%
  summarise(`Total Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE), .groups = "drop") %>%
  left_join(RUNTIME_REF, by = "show_title") %>%
  mutate(`Approximate Viewership` = round(`Total Hours Viewed` / (avg_episode_minutes / 60))) %>%
  arrange(desc(`Total Hours Viewed`)) %>%
  mutate(
    `Total Hours Viewed` = comma(`Total Hours Viewed`),
    `Approximate Viewership` = comma(`Approximate Viewership`)
  ) %>%
  select(
    `Show Title` = show_title,
    `Number of Seasons` = num_seasons,
    `Total Hours Viewed`,
    `*Average Episode Minutes` = avg_episode_minutes,
    `Approximate Viewership`
  )

datatable(
  SHOW_SUMMARY,
  caption = "Global Performance of Selected English Netflix Originals (Sci-Fi/Fantasy/Supernatural, All Seasons)",
  options = list(
    pageLength = 10,
    searching = FALSE,
    paging = FALSE,
    info = FALSE,
    columnDefs = list(list(className = 'dt-left', targets = "_all"))
  ),
  rownames = FALSE
) %>%
  formatRound("*Average Episode Minutes", digits = 1)

```

<br>

*Note, Stranger Things average runtime caculated from the values presented in an earlier table.

The following links contain sources justifying these average per episode runtimes.

*[Wednesday Average Runtime](https://addamsfamily.fandom.com/wiki/Wednesday_(series))*

*[The Witcher Average Runtime](https://epguides.com/Witcher/)*

*[The Sandman](https://www.tvmaze.com/shows/42827/the-sandman)*

*[Locke & Key Average Runtime](https://lockekey.fandom.com/wiki/Season_One)*

*[Shadow and Bone](https://epguides.com/ShadowandBone/)*

<br>

## Task 6: Press Release 2
## Hindi Hits Go Global: 2 Million Netflix Subscribers, 463 Million Viewing Hours

Netflix is demonstrating growing global demand for its Hindi-language programming, with a portfolio of titles generating over 463 million hours of streamed content worldwide. These programs have established Netflix as a premier destination for Hindi entertainment, catering to audiences across India and beyond.

Standout titles such as Heeramandi: The Diamond Bazaar, Animal, and The Great Indian Kapil Show have collectively drawn substantial views from global audiences, highlighting their success on global Top 10 weekly charts. Among its broader catalog, Netflix offers 363 India-focused titles that did not appear in the US market yet achieved global Top 10 status. These titles represent nearly 50% of India's unique content offerings, demonstrating the international appeal of region-specific programming.

Based on viewing patterns and global engagement data, Netflix estimates approximately 2 million subscribers actively engage with Hindi content, representing India's significant presence in Hindi programming consumption. This figure encompasses viewers who regularly consume top-performing Hindi titles that have achieved worldwide recognition.

Beyond India, the broader South Asian streaming market exhibits dynamic growth patterns since 2021, with Pakistan leading regional expansion at 10.3% year-over-year growth in unique Top 10 programming. While Bangladesh and Sri Lanka exhibit positive trends, India has maintained steady engagement, achieving 1.5% growth. Collectively, these four markets offer over 1,400 programs, indicating a well-established, regional presence.

Given the global appeal of South Asian content, Netflix is well-positioned to expand its cross-border offerings through Urdu-language programming, leveraging the language's widespread use across India and Pakistan. This strategic approach aims to serve Urdu-speaking viewers across the region while fostering opportunities for cultural inclusion through shared storytelling.

Netflix's established presence across South Asia, including its strong performance in Hindi content and expanding regional offerings, positions the platform to seize the momentum in streaming growth while continuing to engage its global audiences with rich, South Asian storytelling.

<br>

```{r}

requested_titles <- c(
  "Haseen Dillruba",
  "Sooryavanshi",
  "Animal",
  "Laapataa Ladies",
  "Mimi",
  "Bhool Bhulaiyaa 2",
  "The Railway Men - The Untold Story Of Bhopal 1984",
  "Khakee: The Bihar Chapter",
  "Maamla Legal Hai",
  "The Great Indian Kapil Show",
  "Heeramandi: The Diamond Bazaar",
  "Tribhuvan Mishra CA Topper",
  "IC 814: The Kandahar Hijack",
  "Mismatched",
  "Dabba Cartel"
)

# ---- Create a table for manually provided runtimes ----
manual_runtimes <- tibble::tribble(
  ~show_title,                   ~manual_runtime_hr,
  "Haseen Dillruba",             136 / 60,
  "Sooryavanshi",                145 / 60,
  "Mimi",                        132 / 60,
  "Bhool Bhulaiyaa 2",           143 / 60,
  "Khakee: The Bihar Chapter",   357 / 60
)

# ---- Data Processing ----

# All of the following calculations are still required to create the summary table
india_titles <- COUNTRY_TOP_10 %>%
  filter(country_name == "India") %>%
  distinct(show_title, category)

us_titles <- COUNTRY_TOP_10 %>%
  filter(country_name == "United States") %>%
  distinct(show_title)

india_not_us <- india_titles %>%
  anti_join(us_titles, by = "show_title")

charted_globally <- GLOBAL_TOP_10 %>% distinct(show_title)

target_pool <- india_not_us %>%
  semi_join(charted_globally, by = "show_title") %>%
  filter(show_title %in% requested_titles)

season_counts <- bind_rows(
  COUNTRY_TOP_10 %>% select(show_title, season_title),
  GLOBAL_TOP_10  %>% select(show_title, season_title)
) %>%
  filter(show_title %in% target_pool$show_title) %>%
  mutate(
    season_title = trimws(season_title),
    season_title = dplyr::na_if(season_title, "")
  ) %>%
  group_by(show_title) %>%
  summarise(distinct_seasons = dplyr::n_distinct(season_title, na.rm = TRUE), .groups = "drop")

india_metric <- COUNTRY_TOP_10 %>%
  filter(country_name == "India", show_title %in% target_pool$show_title) %>%
  group_by(show_title) %>%
  summarise(
    india_max_cum_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE),
    category_mode = {
      cats <- na.omit(category)
      if (length(cats) == 0) NA_character_ else names(sort(table(cats), decreasing = TRUE))[1]
    },
    .groups = "drop"
  )

global_metrics <- GLOBAL_TOP_10 %>%
  filter(show_title %in% target_pool$show_title) %>%
  left_join(manual_runtimes, by = "show_title") %>%
  mutate(
    runtime = coalesce(runtime, manual_runtime_hr)
  ) %>%
  group_by(show_title) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    total_weekly_views = sum(weekly_views, na.rm = TRUE),
    avg_runtime        = mean(runtime, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    total_views_est = case_when(
      !is.na(total_weekly_views) & total_weekly_views > 0 ~ total_weekly_views,
      is.finite(avg_runtime) & !is.na(avg_runtime) & avg_runtime > 0 ~ total_hours_viewed / avg_runtime,
      TRUE ~ NA_real_
    )
  )

final_raw <- india_metric %>%
  left_join(global_metrics, by = "show_title") %>%
  left_join(season_counts,  by = "show_title") %>%
  mutate(
    content_type = case_when(
      str_detect(ifelse(is.na(category_mode), "", category_mode), regex("^TV",   ignore_case = TRUE)) ~ "TV Show",
      str_detect(ifelse(is.na(category_mode), "", category_mode), regex("^Film", ignore_case = TRUE)) ~ "Film",
      TRUE ~ ifelse(is.na(category_mode), "Unknown", category_mode)
    ),
    distinct_seasons = ifelse(is.na(distinct_seasons), 0L, distinct_seasons),
    avg_runtime_min  = ifelse(!is.na(avg_runtime) & is.finite(avg_runtime), round(avg_runtime * 60, 0), NA_real_)
  )

# ---- The detailed table is no longer displayed ----
# print("--- Detailed Analysis Table ---")
# datatable(
#   final_tbl %>%
#     mutate(
#       `Global: Total Hours Viewed` = ifelse(!is.na(`Global: Total Hours Viewed`), comma(round(`Global: Total Hours Viewed`, -4)), "N/A"),
#       `Global: Total Views (Est.)` = ifelse(!is.na(`Global: Total Views (Est.)`),  comma(round(`Global: Total Views (Est.)`, -4)),  "N/A")
#     ),
#   options = list(
#     searching = FALSE,
#     paging = TRUE,
#     info = TRUE,
#     pageLength = 3,
#     columnDefs = list(
#       list(className = 'dt-left',   targets = 0),
#       list(className = 'dt-center', targets = 1:6)
#     )
#   ),
#   caption = "Requested Titles - India-not-US, but Global Top 10"
# )


# ===================================================================
# Part 2: Summary Table (Final Output)
# ===================================================================

# ---- Create the summary table using the 'final_raw' object ----
summary_tbl <- final_raw %>%
  filter(content_type %in% c("Film", "TV Show")) %>%
  group_by(content_type) %>%
  summarise(
    total_hours_viewed = sum(total_hours_viewed, na.rm = TRUE),
    total_views_est = sum(total_views_est, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  adorn_totals("row") %>%
  rename(
    `Content Type` = content_type,
    `Global: Total Hours Viewed` = total_hours_viewed,
    `Global: Total Views (Est.)` = total_views_est
  )

# ---- Display the final summary table ----
datatable(
  summary_tbl %>%
    mutate(
      `Global: Total Hours Viewed` = ifelse(!is.na(`Global: Total Hours Viewed`), comma(round(`Global: Total Hours Viewed`, -4)), "N/A"),
      `Global: Total Views (Est.)` = ifelse(!is.na(`Global: Total Views (Est.)`),  comma(round(`Global: Total Views (Est.)`, -4)),  "N/A")
    ),
  options = list(
    searching = FALSE,
    paging = FALSE,
    info = FALSE
  ),
  caption = "Summary by Total Hours Viewed and Estimated Total Views, Hindi-Only Programs"
)

```

<br>

```{r}

# ---- Requested titles only ----
requested_titles <- c(
  "Haseen Dillruba",
  "Sooryavanshi",
  "Animal",
  "Laapataa Ladies",
  "Mimi",
  "Bhool Bhulaiyaa 2",
  "The Railway Men - The Untold Story Of Bhopal 1984",
  "Khakee: The Bihar Chapter",
  "Maamla Legal Hai",
  "The Great Indian Kapil Show",
  "Heeramandi: The Diamond Bazaar",
  "Tribhuvan Mishra CA Topper",
  "IC 814: The Kandahar Hijack",
  "Mismatched",
  "Dabba Cartel"
)

# ---- Create a table for manually provided runtimes ----
# Runtimes are converted from minutes to hours (as required for the calculation)
manual_runtimes <- tibble::tribble(
  ~show_title,                   ~manual_runtime_hr,
  "Haseen Dillruba",             136 / 60,
  "Sooryavanshi",                145 / 60,
  "Mimi",                        132 / 60,
  "Bhool Bhulaiyaa 2",           143 / 60,
  "Khakee: The Bihar Chapter",   357 / 60
)

# ---- Data Processing ----

# 1. Get titles that appeared in India but NOT in the US
india_titles <- COUNTRY_TOP_10 %>%
  filter(country_name == "India") %>%
  distinct(show_title, category)

us_titles <- COUNTRY_TOP_10 %>%
  filter(country_name == "United States") %>%
  distinct(show_title)

india_not_us <- india_titles %>%
  anti_join(us_titles, by = "show_title")

# 2. Filter for titles that also charted globally from the requested list
charted_globally <- GLOBAL_TOP_10 %>% distinct(show_title)

target_pool <- india_not_us %>%
  semi_join(charted_globally, by = "show_title") %>%
  filter(show_title %in% requested_titles)

# 3. Get distinct season counts for the target shows
season_counts <- bind_rows(
  COUNTRY_TOP_10 %>% select(show_title, season_title),
  GLOBAL_TOP_10  %>% select(show_title, season_title)
) %>%
  filter(show_title %in% target_pool$show_title) %>%
  mutate(
    season_title = trimws(season_title),
    season_title = dplyr::na_if(season_title, "")
  ) %>%
  group_by(show_title) %>%
  summarise(distinct_seasons = dplyr::n_distinct(season_title, na.rm = TRUE), .groups = "drop")

# 4. Get India-specific metrics
india_metric <- COUNTRY_TOP_10 %>%
  filter(country_name == "India", show_title %in% target_pool$show_title) %>%
  group_by(show_title) %>%
  summarise(
    india_max_cum_weeks = max(cumulative_weeks_in_top_10, na.rm = TRUE),
    category_mode = {
      cats <- na.omit(category)
      if (length(cats) == 0) NA_character_ else names(sort(table(cats), decreasing = TRUE))[1]
    },
    .groups = "drop"
  )

# 5. Global metrics
global_metrics <- GLOBAL_TOP_10 %>%
  filter(show_title %in% target_pool$show_title) %>%
  left_join(manual_runtimes, by = "show_title") %>%
  mutate(
    runtime = coalesce(runtime, manual_runtime_hr)
  ) %>%
  group_by(show_title) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    total_weekly_views = sum(weekly_views, na.rm = TRUE),
    avg_runtime        = mean(runtime, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    total_views_est = case_when(
      !is.na(total_weekly_views) & total_weekly_views > 0 ~ total_weekly_views,
      is.finite(avg_runtime) & !is.na(avg_runtime) & avg_runtime > 0 ~ total_hours_viewed / avg_runtime,
      TRUE ~ NA_real_
    )
  )

# 6. Combine all metrics into a final raw table
final_raw <- india_metric %>%
  left_join(global_metrics, by = "show_title") %>%
  left_join(season_counts,  by = "show_title") %>%
  mutate(
    content_type = case_when(
      str_detect(ifelse(is.na(category_mode), "", category_mode), regex("^TV",   ignore_case = TRUE)) ~ "TV Show",
      str_detect(ifelse(is.na(category_mode), "", category_mode), regex("^Film", ignore_case = TRUE)) ~ "Film",
      TRUE ~ ifelse(is.na(category_mode), "Unknown", category_mode)
    ),
    distinct_seasons = ifelse(is.na(distinct_seasons), 0L, distinct_seasons),
    avg_runtime_min  = ifelse(!is.na(avg_runtime) & is.finite(avg_runtime), round(avg_runtime * 60, 0), NA_real_)
  )

# 7. Final selection, renaming, and sorting
final_tbl <- final_raw %>%
  arrange(desc(total_hours_viewed), desc(total_views_est), desc(india_max_cum_weeks)) %>%
  select(
    `Show Title` = show_title,
    `Content Type` = content_type,
    `Distinct Seasons` = distinct_seasons,
    `India: Max Cumulative Weeks` = india_max_cum_weeks,
    `Global: Total Hours Viewed` = total_hours_viewed,
    `Global: Total Views (Est.)` = total_views_est,
    `Global: Avg Runtime (min)` = avg_runtime_min
  )

# ---- Display the final table (MODIFIED SECTION) ----
datatable(
  final_tbl %>%
    mutate(
      `Global: Total Hours Viewed` = ifelse(!is.na(`Global: Total Hours Viewed`), comma(round(`Global: Total Hours Viewed`, -4)), "N/A"),
      `Global: Total Views (Est.)` = ifelse(!is.na(`Global: Total Views (Est.)`),  comma(round(`Global: Total Views (Est.)`, -4)),  "N/A")
    ),
  options = list(
    # --- THESE OPTIONS HAVE BEEN CHANGED ---
    searching = FALSE,
    paging = TRUE,      # Enable paging
    info = TRUE,        # Show the "Showing X of Y" text
    pageLength = 3,     # Set the initial page length to 3
    # ---
    columnDefs = list(
      list(className = 'dt-left',   targets = 0),
      list(className = 'dt-center', targets = 1:6)
    )
  ),
  caption = "Selected Programs, India-Only (Not US), in Global Top 10"
)

```

<br>

```{r}

india_exclusive_from_us <- COUNTRY_TOP_10 %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE)

india_only_list <- COUNTRY_TOP_10 %>%
  filter(country_name == "India") %>%
  semi_join(india_exclusive_from_us, by = c("show_title", "season_title")) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil")) %>%
  distinct(show_title, season_title, category) %>%
  mutate(content_type = case_when(
    str_detect(category, "Films") ~ "Films",
    str_detect(category, "TV") ~ "TV Shows",
    TRUE ~ "Other"
  )) %>%
  arrange(content_type, show_title, season_title)

india_only_breakdown <- india_only_list %>%
  count(content_type, name = "distinct_shows") %>%
  mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

india_only_breakdown %>%
  rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

total_india_only <- sum(india_only_breakdown$distinct_shows)
cat("Total distinct viewing options in India that do NOT 
  appear in US (excluding Telugu/Tamil language viewing options):", total_india_only)

```

<br>

```{r}

# ============================================
# EXISTING CODE (unchanged)
# ============================================

india_exclusive_combinations <- COUNTRY_TOP_10 %>%
  group_by(show_title, season_title) %>%
  summarise(
    appears_in_india = any(country_name == "India"),
    appears_in_us = any(country_name == "United States"),
    .groups = "drop"
  ) %>%
  filter(appears_in_india == TRUE & appears_in_us == FALSE) %>%
  filter(!str_detect(tolower(show_title), "telugu|tamil"))

global_appearing_breakdown <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  distinct(show_title, season_title, category) %>%
  mutate(content_type = case_when(
    str_detect(category, "Films") ~ "Films",
    str_detect(category, "TV") ~ "TV Shows",
    TRUE ~ "Other"
  )) %>%
  count(content_type, name = "distinct_shows") %>%
  mutate(percentage = round(distinct_shows / sum(distinct_shows) * 100, 1))

films_metrics <- GLOBAL_TOP_10 %>%
  filter(category == "Films (Non-English)") %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))

tv_metrics <- GLOBAL_TOP_10 %>%
  filter(category == "TV (Non-English)") %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(total_hours = sum(weekly_hours_viewed, na.rm = TRUE))

shows_in_global_count <- sum(global_appearing_breakdown$distinct_shows)
total_combinations <- nrow(india_exclusive_combinations)
global_penetration <- round((shows_in_global_count / total_combinations) * 100, 1)

INDIA_EXCLUSIVE_SUMMARY <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  summarise(
    total_hours_viewed = sum(weekly_hours_viewed, na.rm = TRUE),
    avg_weeks_in_top_10 = mean(cumulative_weeks_in_top_10, na.rm = TRUE),
    max_weeks_in_top_10 = max(cumulative_weeks_in_top_10, na.rm = TRUE)
  ) %>%
  mutate(
    total_hours_formatted = comma(total_hours_viewed),
    avg_weeks_formatted = round(avg_weeks_in_top_10, 1)
  )

# ============================================
# NEW CODE: SUBSCRIBER ESTIMATION
# ============================================

# Step 1: Calculate runtime and views
runtime_and_views <- GLOBAL_TOP_10 %>%
  filter(category %in% c("Films (Non-English)", "TV (Non-English)")) %>%
  semi_join(india_exclusive_combinations, by = c("show_title", "season_title")) %>%
  group_by(category) %>%
  summarise(
    total_hours = sum(weekly_hours_viewed, na.rm = TRUE),
    avg_runtime = mean(runtime, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    total_views = total_hours / avg_runtime
  )

# Step 2: Get number of weeks in dataset
num_weeks <- GLOBAL_TOP_10 %>% distinct(week) %>% nrow()

# Step 3: Calculate total views and views per week
total_views <- sum(runtime_and_views$total_views)
views_per_week_global <- total_views / num_weeks

# Step 4: KEY ASSUMPTIONS - Document these clearly!
INDIA_SHARE_OF_GLOBAL <- 0.25  # 25% of global Non-English views come from India
VIEWS_PER_SUBSCRIBER_PER_WEEK <- 2.0  # Hindi top 10 shows per subscriber per week

# Rationale for assumptions:
# - India share: Based on India's population, Netflix penetration, and content engagement
# - Views per subscriber: These are GLOBAL hit shows, higher than typical Hindi content
#   (Industry avg: 3-4 top 10 shows/week total; Hindi ~28% of catalog; but these are hits)

# Step 5: Calculate estimated subscribers
india_views_per_week <- views_per_week_global * INDIA_SHARE_OF_GLOBAL
estimated_hindi_subscribers <- india_views_per_week / VIEWS_PER_SUBSCRIBER_PER_WEEK

# Step 6: Create sensitivity scenarios
sensitivity_scenarios <- data.frame(
  Scenario = c("Conservative", "Moderate", "Aggressive"),
  India_Share = c(0.20, 0.25, 0.30),
  Views_Per_Sub = c(1.5, 2.0, 2.5)
) %>%
  mutate(
    India_Views_Per_Week = views_per_week_global * India_Share,
    Estimated_Subscribers = India_Views_Per_Week / Views_Per_Sub,
    Formatted_Subscribers = comma(round(Estimated_Subscribers))
  )

# ============================================
# UPDATED SUMMARY TABLE WITH SUBSCRIBER ROW
# ============================================

GLOBAL_REACH_SUMMARY <- data.frame(
  Metric = c(
    "Total Show and Season Combinations", 
    "Total Hours Viewed - Non-English Films", 
    "Total Hours Viewed - Non-English TV",
    "Combined Hours Viewed (Non-English)", 
    "Average Weeks in Global Top 10", 
    "Maximum Weeks in Global Top 10", 
    "Non-English Combinations in Global Charts", 
    "Non-English Global Chart Penetration Rate",
    "Estimated Hindi-Engaged Subscribers",
    "  Assumption: India Share of Global Views",
    "  Assumption: Views per Subscriber per Week"
  ),
  Value = c(
    total_combinations,
    comma(films_metrics$total_hours), 
    comma(tv_metrics$total_hours),
    INDIA_EXCLUSIVE_SUMMARY$total_hours_formatted,
    paste0(INDIA_EXCLUSIVE_SUMMARY$avg_weeks_formatted, " weeks"),
    paste0(INDIA_EXCLUSIVE_SUMMARY$max_weeks_in_top_10, " weeks"),
    paste0(shows_in_global_count, " of ", total_combinations, " combinations"),
    paste0(global_penetration, "%"),
    comma(round(estimated_hindi_subscribers)),
    paste0(INDIA_SHARE_OF_GLOBAL * 100, "%"),
    paste0(VIEWS_PER_SUBSCRIBER_PER_WEEK, " shows")
  )
)

# ============================================
# DISPLAY RESULTS
# ============================================

cat("India-exclusive NON-ENGLISH, (proxy for Hindi; excludes Telugu/Tamil) 
    that achieved global top 10 status:\n\n")

global_appearing_breakdown %>%
  rename(`Content Type` = content_type, `Number of Shows` = distinct_shows, `Percentage` = percentage) %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE, columnDefs = list(list(className = 'dt-left', targets = "_all"))))

cat("\nTotal NON-ENGLISH (proxy for Hindi; excludes Telugu/Tamil) 
program offerings appearing in global charts:", shows_in_global_count, "of", total_combinations, "\n\n")

GLOBAL_REACH_SUMMARY %>%
  datatable(options = list(searching = FALSE, info = FALSE, paging = FALSE))

```

<br>

```{r}

# Define South Asian countries
south_asian_countries <- c("India", "Pakistan", "Bangladesh", "Sri Lanka")

# Calculate unique programs by year for each country
yearly_unique_programs <- COUNTRY_TOP_10 %>%
  filter(country_name %in% south_asian_countries) %>%
  mutate(
    year_period = case_when(
      week >= as.Date("2021-07-04") & week < as.Date("2022-07-04") ~ "2021-2022",
      week >= as.Date("2022-07-04") & week < as.Date("2023-07-04") ~ "2022-2023", 
      week >= as.Date("2023-07-04") & week < as.Date("2024-07-04") ~ "2023-2024",
      week >= as.Date("2024-07-04") & week <= as.Date("2025-07-05") ~ "2024-2025",
      TRUE ~ "Outside Period"
    )
  ) %>%
  filter(year_period != "Outside Period") %>%
  mutate(unique_program = paste(show_title, ifelse(is.na(season_title), "NA_SEASON", season_title), sep = " || ")) %>%
  group_by(country_name, year_period) %>%
  summarise(unique_programs_count = n_distinct(unique_program), .groups = "drop") %>%
  arrange(country_name, year_period)

# Calculate total growth (first year to last year)
growth_summary <- yearly_unique_programs %>%
  group_by(country_name) %>%
  arrange(year_period) %>%
  summarise(
    first_year = first(unique_programs_count),
    last_year = last(unique_programs_count),
    total_growth = round(((last_year - first_year) / first_year) * 100, 1),
    .groups = "drop"
  ) %>%
  mutate(total_growth_formatted = paste0(ifelse(total_growth > 0, "+", ""), total_growth, "%"))

# Create the presentation table
SOUTH_ASIA_GROWTH_TABLE <- yearly_unique_programs %>%
  select(country_name, year_period, unique_programs_count) %>%
  pivot_wider(
    names_from = year_period,
    values_from = unique_programs_count
  ) %>%
  left_join(growth_summary %>% select(country_name, total_growth_formatted), by = "country_name") %>%
  rename(
    Country = country_name,
    `2021-22` = `2021-2022`,
    `2022-23` = `2022-2023`,
    `2023-24` = `2023-2024`,
    `2024-25` = `2024-2025`,
    `Total Growth` = total_growth_formatted
  )

# Display only the interactive table
SOUTH_ASIA_GROWTH_TABLE %>%
  datatable(
    options = list(
      searching = FALSE, 
      info = FALSE, 
      paging = FALSE,
      columnDefs = list(
        list(className = 'dt-center', targets = 1:5),
        list(className = 'dt-left', targets = 0)
      )
    ),
    caption = "Netflix Top 10 Program Growth in South Asia (2021-2025)"
  )

```

<br>

## Task 7: Press Release 3 
## Billion-Hour Nostalgia: Telenovelas Dominate Netflix

<br>

Four classic telenovelas have collectively generated 1.2 billion global viewing hours on Netflix, demonstrating the enduring power of Spanish-language storytelling across Latin America and beyond.

CafÃ© con Aroma de Mujer, which debuted in 1994, leads with 813 million viewing hours, while Yo soy Betty, La Fea (1999) has amassed 297 million hours. Released in 2012, Pablo Escobar, el PatrÃ³n del Mal demonstrates exceptional longevity, maintaining 102 cumulative weeks in the top 10 across Colombia, El Salvador, Honduras, Nicaragua, and Venezuela, highlighting the cross-border appeal of Spanish-language content. These telenovelas demonstrate how archival content continues to captivate new audiences in the streaming era, appealing to viewers' nostalgia while introducing these stories to younger generations.

Netflix's content portfolio strikes a balance between classic content and original programming. Elite, a Netflix Original series launched in 2018, has generated 568 million hours across eight seasons, reaching all 17 Latin American markets, a feat also accomplished by Pablo Escobar. Through this dual content strategy, subscribers have options that cater to their preferences, with Netflix leveraging proven classics while developing contemporary series.

With 670 million Spanish speakers across Latin America, Netflix's combination of archival and original content positions the platform to serve diverse generational tastes while expanding its regional subscriber base.

<br>

```{r}

SPANISH_LATAMER <- c(
  "Argentina","Bolivia","Chile","Colombia","Costa Rica","Dominican Republic",
  "Ecuador","El Salvador","Guatemala","Honduras","Mexico","Nicaragua",
  "Panama","Paraguay","Peru","Uruguay","Venezuela"
)

COUNTRY_TOP_10 <- COUNTRY_TOP_10 %>%
  mutate(
    show_title = coalesce(show_title, "N/A"),
    season_title = coalesce(season_title, "N/A"))

LATAMER_TOP <- COUNTRY_TOP_10 %>%
  filter(country_name %in% SPANISH_LATAMER) %>%
  group_by(country_name, show_title, season_title) %>%
  summarise(max_cumulative = max(cumulative_weeks_in_top_10, na.rm = TRUE), .groups = "drop") %>%
  group_by(country_name) %>%
  slice_max(order_by = max_cumulative, n = 1, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(country_name) %>%
  rename(
    Country = country_name,
    `Show Title` = show_title,
    `Season Title` = season_title,
    `Cumulative Weeks in Top 10` = max_cumulative
  )

datatable(
LATAMER_TOP,
caption = "Spanish-speaking Latin American Countries: Top Show/Season by Cumulative Weeks in Top 10",
  options = list(pageLength = 20, searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
)

```

<br>

```{r}

TOP_PROGRAMS <- tribble(
  ~show_title,                         ~season_title,                              ~avg_runtime_hrs,
  "CafÃ© con aroma de mujer",           "CafÃ© con aroma de mujer: Season 1",          43/60,  
  "Pablo Escobar, el patrÃ³n del mal",  "Pablo Escobar, el patrÃ³n del mal: Season 1", 45/60, 
  "PasiÃ³n de Gavilanes",               "PasiÃ³n de Gavilanes: Season 1",              44/60,  
  "Yo soy Betty, la fea",              "Yo soy Betty, la fea: Season 1",             30/60   
)

GLOBAL_CLEAN <- GLOBAL_TOP_10 %>%
  mutate(
    show_title   = coalesce(show_title, ""),
    season_title = coalesce(season_title, "")
  )

TOTALS_GLOBAL <- GLOBAL_CLEAN %>%
  inner_join(TOP_PROGRAMS, by = c("show_title", "season_title")) %>%
  group_by(category, show_title, season_title, avg_runtime_hrs) %>%
  summarise(
    `Total Weekly Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    `Approx Global Views` = round(`Total Weekly Hours Viewed` / avg_runtime_hrs)
  ) %>%
  transmute(
    Category        = category,
    `Show Title`    = show_title,
    `Season Title`  = season_title,
    `Total Weekly Hours Viewed`,
    `Avg Runtime (hrs)` = avg_runtime_hrs,
    `Approx Global Views`
  )

tot_row <- tibble(
  Category               = "TOTAL",
  `Show Title`           = "â€”",
  `Season Title`         = "â€”",
  `Total Weekly Hours Viewed` = sum(TOTALS_GLOBAL$`Total Weekly Hours Viewed`, na.rm = TRUE),
  `Avg Runtime (hrs)`    = NA_real_,
  `Approx Global Views`  = sum(TOTALS_GLOBAL$`Approx Global Views`, na.rm = TRUE)
)

final_tbl <- bind_rows(TOTALS_GLOBAL, tot_row)

datatable(
  final_tbl,
  caption = "Global Hours & Runtime-Adjusted Approximate Views (Cross-referenced from TSVs)",
  options = list(pageLength = 10, searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
) %>%
  formatCurrency(
    c("Total Weekly Hours Viewed", "Approx Global Views"),
    currency = "", digits = 0, mark = ","
  ) %>%
  formatRound("Avg Runtime (hrs)", digits = 2)

grand_total_hours <- sum(TOTALS_GLOBAL$`Total Weekly Hours Viewed`, na.rm = TRUE)
grand_total_views <- sum(TOTALS_GLOBAL$`Approx Global Views`, na.rm = TRUE)

cat("Grand Total Weekly Hours Viewed:", comma(grand_total_hours), "\n")
cat("Grand Total Approx Global Views:", comma(grand_total_views), "\n")
```

Hours are global for the listed titles as the country TSV does not contain this information.

<br>

*Note, average runtime values are approximations. The sources below provide details highlighting program runtime across episodes and seasons.

*[Netflixâ€™s Average Episode Runtime for Pablo Escobar: El PatrÃ³n del Mal](https://www.netflix.com/title/80035684?utm_source=chatgpt.com)*

*[Wikipediaâ€™s Average Episode Runtime for PasiÃ³n de Gavilanes](https://en.wikipedia.org/wiki/Pasi%C3%B3n_de_Gavilanes?utm_source=chatgpt.com)*

*[tvdbâ€™s Average Episode Runtime for CafÃ© con Aroma de Mujer](https://thetvdb.com/series/cafe-con-aroma-de-mujer-2021#general)*

*[IMDBâ€™s Average Episode Runtime for Yo Soy Betty, La Fea](https://www.imdb.com/title/tt0233127/?utm_source=chatgpt.com)*

<br>

```{r}

# --- Config: runtime assumption for Elite (TVMaze avg ~50 min) ---
elite_runtime <- 50/60  # hours

# --- Spanish-speaking LATAM (exclude Brazil) ---
latam_spanish <- c(
  "Argentina","Bolivia","Chile","Colombia","Costa Rica","Dominican Republic",
  "Ecuador","El Salvador","Guatemala","Honduras","Mexico","Nicaragua",
  "Panama","Paraguay","Peru","Uruguay","Venezuela"
)

# --- Count distinct LATAM countries where Elite charted (from COUNTRY_TOP_10) ---
elite_latam_country_count <- COUNTRY_TOP_10 %>%
  mutate(show_title = coalesce(show_title, "")) %>%
  filter(show_title == "Elite", country_name %in% latam_spanish) %>%
  summarise(n_countries = n_distinct(country_name), .groups = "drop") %>%
  pull(n_countries) %>%
  { if (length(.) == 0 || is.na(.)) 0 else . }  # safety if no rows

# --- Global totals + runtime-adjusted views (from GLOBAL_TOP_10) ---
elite_total <- GLOBAL_TOP_10 %>%
  mutate(show_title = coalesce(show_title, "")) %>%
  filter(show_title == "Elite") %>%
  summarise(
    `Total Weekly Hours Viewed` = sum(weekly_hours_viewed, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    Category                          = "TV (Non-English)",
    `Show Title`                      = "Elite",
    `Season Title`                    = "All Seasons (8)",
    `Avg Runtime (hrs)`               = elite_runtime,
    `Approx Global Views`             = round(`Total Weekly Hours Viewed` / elite_runtime),
    `Number of LATAM Countries Reached` = elite_latam_country_count,
    `Total Weekly Hours Viewed`       = comma(`Total Weekly Hours Viewed`),
    `Approx Global Views`             = comma(`Approx Global Views`)
  ) %>%
  select(
    Category, `Show Title`, `Season Title`,
    `Total Weekly Hours Viewed`, `Avg Runtime (hrs)`, `Approx Global Views`,
    `Number of LATAM Countries Reached`
  )

# --- Render ---
datatable(
  elite_total,
  caption = "Global Hours & Runtime-Adjusted Approximate Views (Cross-referenced from TSVs)",
  options = list(searching = FALSE, paging = FALSE, info = FALSE),
  rownames = FALSE
) %>%
  formatRound("Avg Runtime (hrs)", digits = 2)

```

<br>


*[TVMaze's Average Episode Runtime for Elite](https://www.tvmaze.com/shows/37854/elite?utm_source=chatgpt.com)*
