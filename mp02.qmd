---
title: "STA 9750 Mini-Project #02: Making Backyards Affordable for All"
author: "Eduardo Alarcon"
format: 
  html:
    code-fold: true
    code-summary: "Show code"
execute:
  message: false
  warning: false
---

<style>
strong, b {
  font-weight: bold !important;
}
</style>


```{r}
#| label: setup
#| message: false
#| warning: false

# Load all required packages
library(tidyverse)   # includes dplyr, purrr, ggplot2, readr, etc.
library(glue)
library(readxl)
library(tidycensus)
library(httr2)
library(rvest)
library(DiagrammeR)
library(kableExtra)

```

# Test Section

This is regular text. **This should be bold.** This is regular again.

## Another Test

More text with **bold words** in the middle.

## Data Acquisition

### Task 1: Data Import
```{r}
if(!dir.exists(file.path("data", "mp02"))){
    dir.create(file.path("data", "mp02"), showWarnings=FALSE, recursive=TRUE)
}

library <- function(pkg){
    ## Mask base::library() to automatically install packages if needed
    ## Masking is important here so downlit picks up packages and links
    ## to documentation
    pkg <- as.character(substitute(pkg))
    options(repos = c(CRAN = "https://cloud.r-project.org"))
    if(!require(pkg, character.only=TRUE, quietly=TRUE)) install.packages(pkg)
    stopifnot(require(pkg, character.only=TRUE, quietly=TRUE))
}

library(tidyverse)
library(glue)
library(readxl)
library(tidycensus)

get_acs_all_years <- function(variable, geography="cbsa",
                              start_year=2009, end_year=2023){
    fname <- glue("{variable}_{geography}_{start_year}_{end_year}.csv")
    fname <- file.path("data", "mp02", fname)
    
    if(!file.exists(fname)){
        YEARS <- seq(start_year, end_year)
        YEARS <- YEARS[YEARS != 2020] # Drop 2020 - No survey (covid)
        
        ALL_DATA <- map(YEARS, function(yy){
            tidycensus::get_acs(geography, variable, year=yy, survey="acs1") |>
                mutate(year=yy) |>
                select(-moe, -variable) |>
                rename(!!variable := estimate)
        }) |> bind_rows()
        
        write_csv(ALL_DATA, fname)
    }
    
    read_csv(fname, show_col_types=FALSE)
}

# Household income (12 month)
INCOME <- get_acs_all_years("B19013_001") |>
    rename(household_income = B19013_001)

# Monthly rent
RENT <- get_acs_all_years("B25064_001") |>
    rename(monthly_rent = B25064_001)

# Total population
POPULATION <- get_acs_all_years("B01003_001") |>
    rename(population = B01003_001)

# Total number of households
HOUSEHOLDS <- get_acs_all_years("B11001_001") |>
    rename(households = B11001_001)
```


```{r}
get_building_permits <- function(start_year = 2009, end_year = 2023){
    fname <- glue("housing_units_{start_year}_{end_year}.csv")
    fname <- file.path("data", "mp02", fname)
    
    if(!file.exists(fname)){
        HISTORICAL_YEARS <- seq(start_year, 2018)
        
        HISTORICAL_DATA <- map(HISTORICAL_YEARS, function(yy){
            historical_url <- glue("https://www.census.gov/construction/bps/txt/tb3u{yy}.txt")
                
            LINES <- readLines(historical_url)[-c(1:11)]

            CBSA_LINES <- str_detect(LINES, "^[[:digit:]]")
            CBSA <- as.integer(str_sub(LINES[CBSA_LINES], 5, 10))

            PERMIT_LINES <- str_detect(str_sub(LINES, 48, 53), "[[:digit:]]")
            PERMITS <- as.integer(str_sub(LINES[PERMIT_LINES], 48, 53))
            
            data_frame(CBSA = CBSA,
                       new_housing_units_permitted = PERMITS, 
                       year = yy)
        }) |> bind_rows()
        
        CURRENT_YEARS <- seq(2019, end_year)
        
        CURRENT_DATA <- map(CURRENT_YEARS, function(yy){
            current_url <- glue("https://www.census.gov/construction/bps/xls/msaannual_{yy}99.xls")
            
            temp <- tempfile()
            
            download.file(current_url, destfile = temp, mode="wb")
            
            fallback <- function(.f1, .f2){
                function(...){
                    tryCatch(.f1(...), 
                             error=function(e) .f2(...))
                }
            }
            
            reader <- fallback(read_xlsx, read_xls)
            
            reader(temp, skip=5) |>
                na.omit() |>
                select(CBSA, Total) |>
                mutate(year = yy) |>
                rename(new_housing_units_permitted = Total)
        }) |> bind_rows()
        
        ALL_DATA <- rbind(HISTORICAL_DATA, CURRENT_DATA)
        
        write_csv(ALL_DATA, fname)
        
    }
    
    read_csv(fname, show_col_types=FALSE)
}

PERMITS <- get_building_permits()
```


```{r}
library(httr2)
library(rvest)
get_bls_industry_codes <- function(){
    fname <- fname <- file.path("data", "mp02", "bls_industry_codes.csv")
    
    if(!file.exists(fname)){
    
        resp <- request("https://www.bls.gov") |> 
            req_url_path("cew", "classifications", "industry", "industry-titles.htm") |>
            req_headers(`User-Agent` = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0") |> 
            req_error(is_error = \(resp) FALSE) |>
            req_perform()
        
        resp_check_status(resp)
        
        naics_table <- resp_body_html(resp) |>
            html_element("#naics_titles") |> 
            html_table() |>
            mutate(title = str_trim(str_remove(str_remove(`Industry Title`, Code), "NAICS"))) |>
            select(-`Industry Title`) |>
            mutate(depth = if_else(nchar(Code) <= 5, nchar(Code) - 1, NA)) |>
            filter(!is.na(depth))
        
        naics_table <- naics_table |> 
            filter(depth == 4) |> 
            rename(level4_title=title) |> 
            mutate(level1_code = str_sub(Code, end=2), 
                   level2_code = str_sub(Code, end=3), 
                   level3_code = str_sub(Code, end=4)) |>
            left_join(naics_table, join_by(level1_code == Code)) |>
            rename(level1_title=title) |>
            left_join(naics_table, join_by(level2_code == Code)) |>
            rename(level2_title=title) |>
            left_join(naics_table, join_by(level3_code == Code)) |>
            rename(level3_title=title) |>
            select(-starts_with("depth")) |>
            rename(level4_code = Code) |>
            select(level1_title, level2_title, level3_title, level4_title, 
                   level1_code,  level2_code,  level3_code,  level4_code)
    
        write_csv(naics_table, fname)
    }
    
    read_csv(fname, show_col_types=FALSE)
    
}

INDUSTRY_CODES <- get_bls_industry_codes()
```


```{r}
library(httr2)
library(rvest)
library(glue)
get_bls_qcew_annual_averages <- function(start_year=2009, end_year=2023){
    fname <- glue("bls_qcew_{start_year}_{end_year}.csv.gz")
    fname <- file.path("data", "mp02", fname)
    
    YEARS <- seq(start_year, end_year)
    YEARS <- YEARS[YEARS != 2020] # Drop Covid year to match ACS
    
    if(!file.exists(fname)){
        ALL_DATA <- map(YEARS, .progress=TRUE, possibly(function(yy){
            fname_inner <- file.path("data", "mp02", glue("{yy}_qcew_annual_singlefile.zip"))
            
            if(!file.exists(fname_inner)){
                request("https://www.bls.gov") |> 
                    req_url_path("cew", "data", "files", yy, "csv",
                                 glue("{yy}_annual_singlefile.zip")) |>
                    req_headers(`User-Agent` = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:143.0) Gecko/20100101 Firefox/143.0") |> 
                    req_retry(max_tries=5) |>
                    req_perform(fname_inner)
            }
            
            if(file.info(fname_inner)$size < 755e5){
                warning(sQuote(fname_inner), "appears corrupted. Please delete and retry this step.")
            }
            
            read_csv(fname_inner, 
                     show_col_types=FALSE) |> 
                mutate(YEAR = yy) |>
                select(area_fips, 
                       industry_code, 
                       annual_avg_emplvl, 
                       total_annual_wages, 
                       YEAR) |>
                filter(nchar(industry_code) <= 5, 
                       str_starts(area_fips, "C")) |>
                filter(str_detect(industry_code, "-", negate=TRUE)) |>
                mutate(FIPS = area_fips, 
                       INDUSTRY = as.integer(industry_code), 
                       EMPLOYMENT = as.integer(annual_avg_emplvl), 
                       TOTAL_WAGES = total_annual_wages) |>
                select(-area_fips, 
                       -industry_code, 
                       -annual_avg_emplvl, 
                       -total_annual_wages) |>
                # 10 is a special value: "all industries" , so omit
                filter(INDUSTRY != 10) |> 
                mutate(AVG_WAGE = TOTAL_WAGES / EMPLOYMENT)
        })) |> bind_rows()
        
        write_csv(ALL_DATA, fname)
    }
    
    ALL_DATA <- read_csv(fname, show_col_types=FALSE)
    
    ALL_DATA_YEARS <- unique(ALL_DATA$YEAR)
    
    YEARS_DIFF <- setdiff(YEARS, ALL_DATA_YEARS)
    
    if(length(YEARS_DIFF) > 0){
        stop("Download failed for the following years: ", YEARS_DIFF, 
             ". Please delete intermediate files and try again.")
    }
    
    ALL_DATA
}

WAGES <- get_bls_qcew_annual_averages()
```

## Data Integration Structure

This analysis integrates data from three federal agencies—the Census Bureau's American Community Survey (ACS), the Census Building Permits database, and the Bureau of Labor Statistics (BLS)—each employing distinct identification systems for Core-Based Statistical Areas (CBSAs). 

The primary analytical challenge lies in reconciling three incompatible geographic identification formats across these authoritative data sources.

```{r}

#| label: fig-relationship-diagram
#| fig-cap: "Data Integration Architecture: Entity Relationships & Transformation Logic Across Federal Data Sources"
#| out-width: "100%"
#| results: 'asis'

library(DiagrammeR)
grViz("
digraph MP02_ERD {
  
  graph [rankdir=TB, fontname=Arial, bgcolor=white, splines=polyline, nodesep=2, ranksep=3.5, margin='1.5,0.5',
         label='Data Integration Architecture:\\nEntity Relationships & Transformation Logic Across Federal Data Sources', 
         labelloc='t', 
         fontsize=50]
  node [shape=box, style='rounded,filled', fontname=Arial, fontsize=28, margin=0.7, width=7, height=2.5]
  edge [fontname=Arial, fontsize=22, labelfloat=true, labeldistance=4]
  
  INCOME [label='INCOME\\n\\nGEOID (PK)\\nNAME\\nyear (PK)\\n\\nhousehold_income', fillcolor='lightblue']
  RENT [label='RENT\\n\\nGEOID (PK)\\nNAME\\nyear (PK)\\n\\nmonthly_rent', fillcolor='lightblue']
  POPULATION [label='POPULATION\\n\\nGEOID (PK)\\nNAME\\nyear (PK)\\n\\npopulation', fillcolor='lightblue']
  HOUSEHOLDS [label='HOUSEHOLDS\\n\\nGEOID (PK)\\nNAME\\nyear (PK)\\n\\nhouseholds', fillcolor='lightblue']
  PERMITS [label='PERMITS\\n\\nCBSA (PK)\\nyear (PK)\\n\\nnew_housing_units_permitted', fillcolor='#90EE90', width=8]
  WAGES [label='WAGES\\n\\nFIPS (PK)\\nINDUSTRY (PK, FK)\\nYEAR (PK)\\n\\nEMPLOYMENT\\nTOTAL_WAGES\\nAVG_WAGE', fillcolor='lightcoral', width=8, height=3]
  INDUSTRY [label='INDUSTRY_CODES\\n\\nlevel4_code (PK)\\n\\nlevel4_title\\nlevel3_code/title\\nlevel2_code/title\\nlevel1_code/title', fillcolor='lightcoral', width=8, height=3]
  
  INCOME -> RENT [label='      GEOID + year      ', color=blue, penwidth=5, fontcolor=blue, fontsize=22]
  RENT -> POPULATION [label='      GEOID + year      ', color=blue, penwidth=5, fontcolor=blue, fontsize=22]
  POPULATION -> HOUSEHOLDS [label='      GEOID + year      ', color=blue, penwidth=5, fontcolor=blue, fontsize=22]
  POPULATION -> PERMITS [label='      Extract CBSA      \\n      from GEOID      ', color=orange, penwidth=5, style=dashed, fontcolor='#CC5500', fontsize=22]
  PERMITS -> WAGES [label='      Format CBSA      \\n      to FIPS      ', color=orange, penwidth=5, style=dashed, fontcolor='#CC5500', fontsize=22]
  WAGES -> INDUSTRY [label='      INDUSTRY to      \\n      level4_code      ', color=red, penwidth=5, fontcolor=red, fontsize=22]
  
  {rank=same; HOUSEHOLDS; PERMITS}
}
", height = "1200px", width = "100%")

```

### Geographic Identification Challenges

As illustrated in Figure 1, each data source employs a different convention for identifying the same geographic units:

- **Census ACS Tables** use alphanumeric `GEOID` strings (e.g., "CBSA35620" for New York City)
- **Census Building Permits** use integer `CBSA` codes (e.g., 35620)
- **BLS Wage Data** use formatted `FIPS` strings with "C" prefix and zero-padding (e.g., "C35620")

These seemingly minor differences represent significant data engineering challenges. A naive join would fail to match any records across these sources, despite all three referring to identical geographic areas.

### Data Integration Methodology

The four ACS tables (INCOME, RENT, POPULATION, HOUSEHOLDS) share identical composite primary keys consisting of GEOID and year, enabling straightforward joins using standard `left_join()` operations. These tables form the analytical foundation, providing essential household economic and demographic metrics at the CBSA-year level.

Connecting ACS data to the Building Permits database requires the first transformation: extracting the numeric CBSA code from the GEOID string. This is accomplished using:
```r
mutate(CBSA = as.integer(str_extract(GEOID, "[0-9]+")))
```

The second transformation bridges Building Permits to BLS wage data by formatting the integer CBSA code into the BLS-specific FIPS string format:
```r
mutate(FIPS = paste0("C", str_pad(CBSA, 5, pad = "0")))
```

Additionally, an important naming convention difference exists: ACS and Census tables use lowercase `year`, while BLS tables use uppercase `YEAR`. Join operations must explicitly map these columns:
```r
left_join(WAGES, by = c("FIPS", "year" = "YEAR"))
```

Finally, the INDUSTRY_CODES lookup table provides hierarchical NAICS classifications that enable occupational analysis. This requires converting the integer INDUSTRY column to character type for matching against level4_code.

### Implications for Analysis Reproducibility

Understanding these transformation requirements is essential for three reasons. First, they ensure **geographic accuracy**—incorrect joining would produce meaningless results or silent errors where CBSAs fail to match. Second, they enable **reproducibility**—future analysts can replicate this work by following the documented transformation logic. Third, they demonstrate **data quality awareness**—recognizing that real-world data integration often requires careful attention to formatting conventions across institutional boundaries.

The relationship diagram serves as both documentation and validation, providing visual confirmation that the analysis correctly handles the complexity of multi-agency federal data integration.

### Question 1: Largest Housing Permits (2010-2019)

Which CBSA (by name) permitted the largest number of new housing units in the decade from 2010 to 2019 (inclusive)?

```{r}
# Step 1: Filter PERMITS for 2010-2019 and sum by CBSA
permits_2010_2019 <- PERMITS |>
  filter(year >= 2010 & year <= 2019) |>
  group_by(CBSA) |>
  summarize(total_new_units = sum(new_housing_units_permitted, na.rm = TRUE)) |>
  arrange(desc(total_new_units))

# Step 2: Join with POPULATION to get CBSA names
# (We only need one year to get the name, so filter for 2019)
cbsa_names <- POPULATION |>
  filter(year == 2019) |>
  mutate(CBSA = as.integer(str_extract(GEOID, "[0-9]+"))) |>
  select(CBSA, NAME)

# Step 3: Join and find the top CBSA
answer_q1 <- permits_2010_2019 |>
  left_join(cbsa_names, by = "CBSA") |>
  slice(1)  # Get the top row

# Show top 5 CBSAs
top_5_permits <- permits_2010_2019 |>
  left_join(cbsa_names, by = "CBSA") |>
  head(5) |>
  select(NAME, total_new_units)

knitr::kable(top_5_permits, 
             col.names = c("Metro Area", "Total New Units Permitted (2010-2019)"),
             format.args = list(big.mark = ","))
```

**Answer:** The CBSA that permitted the largest number of new housing units from 2010 to 2019 was **`r answer_q1$NAME`** with **`r format(answer_q1$total_new_units, big.mark = ",")`** new units permitted.

### Question 2: Albuquerque Peak Year

In what year did Albuquerque, NM (CBSA Number 10740) permit the most new housing units?

```{r}
# Filter for Albuquerque and find top years
albuquerque_permits <- PERMITS |>
  filter(CBSA == 10740) |>
  arrange(desc(new_housing_units_permitted))

# Get the peak year
peak_year <- albuquerque_permits |>
  slice(1) |>
  pull(year)

# Show top 5 years in a nice table
top_5_years <- albuquerque_permits |>
  head(5) |>
  select(year, new_housing_units_permitted)

knitr::kable(top_5_years, 
             col.names = c("Year", "New Housing Units Permitted"),
             format.args = list(big.mark = ","),
             caption = "Top 5 Years for Housing Permits in Albuquerque, NM (CBSA 10740)")

# Improved plot with better label positioning
ggplot(albuquerque_permits, aes(x = year, y = new_housing_units_permitted)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(size = 3, color = "steelblue") +
  geom_point(data = albuquerque_permits |> filter(year == 2020), 
             aes(x = year, y = new_housing_units_permitted),
             color = "red", size = 4) +
  geom_point(data = albuquerque_permits |> filter(year == 2021), 
             aes(x = year, y = new_housing_units_permitted),
             color = "darkgreen", size = 4) +
  annotate("text", x = 2020, 
           y = albuquerque_permits$new_housing_units_permitted[albuquerque_permits$year == 2020], 
           label = "COVID Dip", color = "red", hjust = 1.2, vjust = 1.1) +
  annotate("text", x = 2021, 
           y = albuquerque_permits$new_housing_units_permitted[albuquerque_permits$year == 2021], 
           label = "Peak", color = "darkgreen", hjust = 0.5, vjust = -1.7) +
  labs(title = "Housing Permits in Albuquerque, NM (CBSA 10740)",
       subtitle = "Note the 2020 COVID dip and 2021 rebound",
       x = "Year",
       y = "New Housing Units Permitted") +
  theme_minimal() +
  scale_y_continuous(labels = scales::comma,
                     expand = expansion(mult = c(0.05, 0.15))) +  # Add more space at top
  coord_cartesian(clip = "off")  # Prevent labels from being cut off

```

**Answer:** Albuquerque, NM (CBSA 10740) permitted the most new housing units in **`r peak_year`** with **`r format(albuquerque_permits$new_housing_units_permitted[1], big.mark = ",")`** units.

**COVID-19 Artifact Note:** The 2021 peak represents a "catch-up" effect following severe disruption to construction permitting in 2020 due to COVID-19 lockdowns. As shown in the table above, 2021, 2022, and 2023 all show elevated permit levels compared to the pre-pandemic decade, suggesting sustained post-COVID housing development activity rather than a temporary spike.

### Question 3: Highest Average Individual Income by State (2015)

Which state (not CBSA) had the highest average individual income in 2015?

```{r}
# Step 1: Join the three tables for 2015
income_2015 <- INCOME |>
  filter(year == 2015) |>
  left_join(HOUSEHOLDS |> filter(year == 2015), by = c("GEOID", "NAME", "year")) |>
  left_join(POPULATION |> filter(year == 2015), by = c("GEOID", "NAME", "year"))

# Step 2: Calculate total income per CBSA and extract state
cbsa_income <- income_2015 |>
  mutate(
    total_income = household_income * households,
    state = str_extract(NAME, ", (.{2})", group = 1)
  ) |>
  select(GEOID, NAME, state, total_income, population)

# Step 3: Sum by state
state_income <- cbsa_income |>
  group_by(state) |>
  summarize(
    total_state_income = sum(total_income, na.rm = TRUE),
    total_state_population = sum(population, na.rm = TRUE)
  ) |>
  mutate(avg_individual_income = total_state_income / total_state_population) |>
  arrange(desc(avg_individual_income))

# Step 4: Get the top state
top_state_abb <- state_income |>
  slice(1) |>
  pull(state)

top_state_income <- state_income |>
  slice(1) |>
  pull(avg_individual_income)

# Step 5: Convert abbreviation to full state name
state_df <- data.frame(
  abb  = c(state.abb, "DC", "PR"),
  name = c(state.name, "District of Columbia", "Puerto Rico")
)

top_state_name <- state_df |>
  filter(abb == top_state_abb) |>
  pull(name)

# Show top 10 to give better context
top_10_states <- state_income |>
  head(10) |>
  left_join(state_df, by = c("state" = "abb")) |>
  select(name, state, avg_individual_income, total_state_population) |>
  mutate(
    multistate_flag = ifelse(state == "DC", "⚠️ 100% Multi-State", 
                            ifelse(state %in% c("NY", "MD", "VA"), "Contains Multi-State CBSAs", ""))
  )

knitr::kable(top_10_states, 
             col.names = c("State", "Abbr", "Avg Individual Income", 
                          "Total Population", "Note"),
             format.args = list(big.mark = ","),
             caption = "Top 10 States by Average Individual Income (2015)")
```

**Answer:** Based on CBSA-level data, the **District of Columbia** had the highest average individual income at **$33,232.88** per person in 2015.

**Critical Methodological Limitations:**

1. **Multi-State CBSA Bias:** DC's result is derived entirely from the Washington-Arlington-Alexandria metropolitan area, which spans DC, Virginia, Maryland, and West Virginia. This methodology attributes income from wealthy Virginia and Maryland suburbs to DC, inflating DC's apparent income level. DC represents 100% of a multi-state metro area rather than a standalone state economy.

2. **CBSA Coverage Limitation:** This analysis only includes Core-Based Statistical Areas (metropolitan areas) and excludes rural populations. States with large rural populations are systematically undercounted:
   - Alaska: Only 499,421 of ~737,000 residents included (~68%)
   - Vermont: Only 216,661 of ~626,000 residents included (~35%)
   - In contrast, DC, Massachusetts, and Connecticut are nearly 100% metropolitan
   
   This creates an urban-rural bias where highly urbanized states appear to have higher incomes, partially because rural (typically lower-income) populations are excluded from the analysis.

3. **Most Accurate Interpretation:** Among states with primarily single-state CBSAs and high metro coverage, **Massachusetts** ($27,620.62) and **Connecticut** ($27,194.05) represent the most reliable results, as they include most of their state populations and don't have the multi-state attribution problem affecting DC.

### Question 4: Data Scientists by CBSA Over Time

What is the last year in which the NYC CBSA had the most data scientists in the country? In recent, the San Francisco CBSA has had the most data scientists.

```{r}

# Prepare data
data_scientists <- WAGES |>
  filter(INDUSTRY == 51821) |>
  rename(std_cbsa = FIPS, year = YEAR)

cbsa_names <- POPULATION |>
  filter(year == 2019) |>
  mutate(
    CBSA = as.integer(str_extract(GEOID, "[0-9]+")),
    std_cbsa = paste0("C", str_sub(as.character(CBSA), 1, 4))
  ) |>
  select(std_cbsa, NAME)

# Calculate last NYC year properly
last_nyc_year <- data_scientists |>
  group_by(std_cbsa, year) |>
  summarize(total_employment = sum(EMPLOYMENT, na.rm = TRUE), .groups = "drop") |>
  left_join(cbsa_names, by = "std_cbsa") |>
  group_by(year) |>
  slice_max(total_employment, n = 1, with_ties = FALSE) |>
  ungroup() |>
  filter(str_detect(NAME, "New York")) |>
  pull(year) |>
  max()

# Focus on the transition period: 2014-2017
transition_years <- data_scientists |>
  filter(year %in% c(2014, 2015, 2016, 2017)) |>
  group_by(std_cbsa, year) |>
  summarize(total_employment = sum(EMPLOYMENT, na.rm = TRUE), .groups = "drop") |>
  left_join(cbsa_names, by = "std_cbsa") |>
  group_by(year) |>
  slice_max(total_employment, n = 3, with_ties = FALSE) |>
  ungroup() |>
  arrange(year, desc(total_employment)) |>
  group_by(year) |>
  mutate(rank = row_number()) |>
  ungroup() |>
  mutate(year = as.character(year)) |>
  select(year, rank, NAME, total_employment)

knitr::kable(transition_years,
             col.names = c("Year", "Rank", "CBSA", "Employment"),
             align = "llll",
             format.args = list(big.mark = ","),
             caption = "The NYC-to-San Francisco Transition (2014-2017)")

```

**Answer:** The last year in which the New York City CBSA had the most data scientists and business analysts (NAICS 51821) in the country was **`r last_nyc_year`**. As shown in the table above, San Francisco has led the nation since then, reflecting the tech industry's concentration in Silicon Valley.
